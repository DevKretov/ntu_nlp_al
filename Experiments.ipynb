{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07370b95-6e73-445c-a863-6ba987287af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe2661-d395-40e2-8923-9bb0c308682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN IF IN COLAB\n",
    "\n",
    "# # torch==1.10.2\n",
    "# !pip install transformers==4.16.2 datasets==1.17.0 tokenizers==0.11.6 wandb==0.12.14\n",
    "\n",
    "# !git clone -b kretov/small_addons https://github.com/DevKretov/ntu_nlp_al\n",
    "# %cd ntu_nlp_al/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb2c3bb7-84a8-4c8e-99e8-0a1e1afd2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import get_scheduler\n",
    "from datasets import list_metrics, load_metric\n",
    "\n",
    "from active_learning_trainer import ALTrainer\n",
    "from transformers import AutoTokenizer\n",
    "from dataset import Dataset\n",
    "from model import Model\n",
    "from transformers import BertForSequenceClassification\n",
    "from strategies import RandomStrategy\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2b5752c-95cf-4931-939b-a619d5142eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict()\n",
    "parameters['use_gpu'] = True\n",
    "\n",
    "parameters['weights_and_biases_on'] = False\n",
    "parameters['weights_and_biases_key'] = '5e5e00356042a33b5cb271399b8d05c9c9d6ded8'\n",
    "parameters['weights_and_biases_run_name'] = 'run_2'\n",
    "# TODO: implement it\n",
    "parameters['weights_and_biases_save_predictions'] = False\n",
    "\n",
    "parameters['pretrained_model_name'] = 'prajjwal1/bert-tiny' #'distilbert-base-uncased'\n",
    "\n",
    "\n",
    "# parameters['train_dataset_file_path'] = 'data/imdb/train_IMDB.csv'\n",
    "# parameters['val_dataset_file_path'] = 'data/imdb/test_IMDB.csv'\n",
    "# parameters['test_dataset_file_path'] = 'data/imdb/test_IMDB.csv'\n",
    "\n",
    "parameters['train_dataset_file_path'] = 'data/news/train.csv'\n",
    "parameters['val_dataset_file_path'] = 'data/news/val.csv'\n",
    "parameters['test_dataset_file_path'] = 'data/news/test.csv'\n",
    "parameters['dataset_file_delimiter'] = ','\n",
    "\n",
    "parameters['dataset_text_column_name'] = 'text_cleaned' #'text'\n",
    "parameters['dataset_label_column_name'] = 'label_reduced'#'airline_sentiment'\n",
    "\n",
    "# TODO: implement this with CrossEntropyLoss\n",
    "parameters['loss'] = 'cross_entropy'\n",
    "parameters['loss_weighted'] = False\n",
    "\n",
    "parameters['class_imbalance_reweight'] = True\n",
    "parameters['train_batch_size'] = 32\n",
    "parameters['val_batch_size'] = 64\n",
    "parameters['test_batch_size'] = 64\n",
    "parameters['epochs'] = 5\n",
    "parameters['finetuned_model_type'] = 'classification'\n",
    "\n",
    "parameters['al_iterations'] = 100\n",
    "parameters['init_dataset_size'] = 32\n",
    "parameters['add_dataset_size'] = 32\n",
    "parameters['al_strategy'] = 'least_confidence' #'least_confidence'\n",
    "parameters['full_train'] = False\n",
    "parameters['debug'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33256405-974a-48d8-9db6-d8eedaa04e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parameters['weights_and_biases_on']:\n",
    "    wandb.login(key='5e5e00356042a33b5cb271399b8d05c9c9d6ded8')\n",
    "    wandb.init(\n",
    "        name=parameters['weights_and_biases_run_name'],\n",
    "        project='ntu_al',\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    wandb.config.update(parameters)\n",
    "\n",
    "device = 'cpu'\n",
    "if parameters['use_gpu']:\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Device set to {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4eda5d2-1018-4d91-8338-a392aa1ee9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 1.899296794618879: 100%|██████████| 14/14 [31:38<00:00, 135.61s/it]\n",
      "Eval mean loss: 1.9060639824186052:  44%|████▍     | 7/16 [31:34<40:35, 270.59s/it]\n",
      "AL evaluation iteration. Batch   246/295:  83%|████████▎ | 246/295 [09:07<01:49,  2.23s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e159e2f034d47ce8\n",
      "Reusing dataset csv (/Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n",
      "100%|██████████| 3/3 [00:00<00:00, 544.95it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(parameters['pretrained_model_name'])\n",
    "\n",
    "dataset_obj = Dataset(tokenizer)\n",
    "\n",
    "data_files = {\n",
    "    'train': [parameters['train_dataset_file_path']],\n",
    "    'val': [parameters['val_dataset_file_path']],\n",
    "    'test': [parameters['test_dataset_file_path']]\n",
    "}\n",
    "\n",
    "dataset_obj.load_csv_dataset(\n",
    "    data_files,\n",
    "    delimiter=parameters['dataset_file_delimiter']\n",
    ")\n",
    "\n",
    "dataset_obj.truncate_dataset('train', 10000)\n",
    "dataset_obj.truncate_dataset('val', 1000)\n",
    "dataset_obj.truncate_dataset('test', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95987d1e-df03-49d8-8883-205ff1532c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-ac32778fd5425486.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-6799fe5e1a63afb8.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-6853f82358e53875.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-d7b79c90d7fbe0d7.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-3fc21e3349900825.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-4e4cbb53aba9736b.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-19a7b19d37d0c403.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-00966c08ee6c4666.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-ecacc337cd82f97d.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-ab4783eba81cf9e2.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-8c90c63422917077.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-9ae4ae5063e818a2.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-dcf92b143d50a2ef.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-c86fe28451fe0824.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_obj.prepare_labels(parameters['dataset_label_column_name'])\n",
    "dataset_obj.encode_dataset(parameters['dataset_text_column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e0425ca-faf6-44c0-9ff4-942a539ab10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: {'alt': 0, 'comp': 1, 'misc': 2, 'rec': 3, 'sci': 4, 'soc': 5, 'talk': 6}\n"
     ]
    }
   ],
   "source": [
    "print(f'Categories: {dataset_obj.get_all_categories()}')\n",
    "num_labels = dataset_obj.get_num_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de0a2b29-2e21-4045-ae88-083a8b52f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    parameters['pretrained_model_name'],\n",
    "    model_type=parameters['finetuned_model_type'],\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8483f62-fd4b-4267-b276-3caf2d055b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ALTrainer(\n",
    "    wandb_on=parameters['weights_and_biases_on'],\n",
    "    imbalanced_training=parameters['class_imbalance_reweight']\n",
    ")\n",
    "trainer.set_model(model)\n",
    "\n",
    "# TODO: add strategy\n",
    "trainer.set_strategy(None)\n",
    "trainer.set_dataset(dataset_obj)\n",
    "trainer.prepare_dataloaders(\n",
    "    train_batch_size=parameters['train_batch_size'],\n",
    "    val_batch_size=parameters['val_batch_size'],\n",
    "    test_batch_size=parameters['test_batch_size'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2c1f144-6eea-4e71-b916-8c97d578682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.model.parameters(), lr=5e-5)\n",
    "trainer.set_optimizer(optimizer)\n",
    "\n",
    "num_training_steps = parameters['epochs'] * trainer.get_training_steps_num()\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "trainer.set_lr_scheduler(lr_scheduler)\n",
    "trainer.set_device(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c263c-046c-41da-82af-7a91456dee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_evaluation_metric(load_metric('accuracy'))\n",
    "trainer.add_evaluation_metric(load_metric('f1'))\n",
    "trainer.add_evaluation_metric(load_metric('precision'))\n",
    "trainer.add_evaluation_metric(load_metric('recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71ac9df6-f479-4d75-9810-d14ca7a78461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-9bd4ab3a27a7fb3a.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-264ab8efe04d123a.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-fd085d63684e4b7c.arrow\n",
      "Loading cached processed dataset at /Users/antonkretov/.cache/huggingface/datasets/csv/default-e159e2f034d47ce8/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-078a83154302888e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initialized!\n",
      "AL train dataset length: 32, rest dataset length: 9968\n",
      "Training is run on 1 batches!\n",
      "Evaluation is run on 16 batches!\n",
      "Testing is run on 16 batches!\n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL BADGE strategy applied!\n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9942021369934082: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.935079112648964:  94%|█████████▍| 15/16 [00:02<00:00,  7.10it/s] \n",
      "Eval mean loss: 1.935079112648964: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9942021369934082: 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "Training mean loss: 1.969994306564331: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9267708659172058:  94%|█████████▍| 15/16 [00:02<00:00,  7.23it/s]\n",
      "Eval mean loss: 1.9267708659172058: 100%|██████████| 16/16 [00:02<00:00,  7.46it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.969994306564331: 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "Training mean loss: 1.9879329204559326: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9196368902921677:  94%|█████████▍| 15/16 [00:02<00:00,  5.75it/s]\n",
      "Eval mean loss: 1.9196368902921677: 100%|██████████| 16/16 [00:02<00:00,  5.76it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.9879329204559326: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "Training mean loss: 1.9227190017700195: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9123196750879288:  94%|█████████▍| 15/16 [00:02<00:00,  6.57it/s]\n",
      "Eval mean loss: 1.9123196750879288: 100%|██████████| 16/16 [00:02<00:00,  6.70it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.9227190017700195: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n",
      "Training mean loss: 1.950924277305603: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9064743369817734: 100%|██████████| 16/16 [00:02<00:00,  6.44it/s]\n",
      "Eval mean loss: 1.9064743369817734: 100%|██████████| 16/16 [00:02<00:00,  6.42it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.9064743369817734:  94%|█████████▍| 15/16 [00:02<00:00,  6.86it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   4   1   8  37   1   0]\n",
      " [  0  40   2  62 149   2   0]\n",
      " [  0  11   1   5  21   1   0]\n",
      " [  0  35   1  79  90   7   3]\n",
      " [  0  61   1  43 114   3   0]\n",
      " [  0   3   0   9  40   0   0]\n",
      " [  0  35   0  39  91   1   0]]\n",
      "{'accuracy': 0.22566666666666665}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.1830307460471592}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.16815120387939117}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.23779416930101863}\n",
      "\n",
      "Test mean loss: 1.9064743369817734: 100%|██████████| 16/16 [00:02<00:00,  6.92it/s]\n",
      "Training mean loss: 1.950924277305603: 100%|██████████| 1/1 [00:05<00:00,  5.06s/it]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   312/312: 100%|██████████| 312/312 [00:24<00:00, 12.94it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 32, unlabelled size = 9968, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.87ba/s]\n",
      "100%|██████████| 9936/9936 [00:03<00:00, 3183.28ex/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 3129.24ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 64, unlabelled size = 9936, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9718313217163086: 100%|██████████| 2/2 [00:00<00:00,  3.98it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8992066755890846: 100%|██████████| 16/16 [00:02<00:00,  7.01it/s]\n",
      "Eval mean loss: 1.8992066755890846: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9718313217163086: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]\n",
      "Training mean loss: 1.9352800250053406: 100%|██████████| 2/2 [00:00<00:00,  3.71it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8962380439043045: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n",
      "Eval mean loss: 1.8962380439043045: 100%|██████████| 16/16 [00:02<00:00,  7.05it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9352800250053406: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]\n",
      "Training mean loss: 1.9230751991271973: 100%|██████████| 2/2 [00:00<00:00,  3.92it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8959406539797783:  94%|█████████▍| 15/16 [00:02<00:00,  6.81it/s]\n",
      "Eval mean loss: 1.8959406539797783: 100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.9230751991271973: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]\n",
      "Training mean loss: 1.9129754304885864: 100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8963380604982376:  94%|█████████▍| 15/16 [00:02<00:00,  6.83it/s]\n",
      "Eval mean loss: 1.8963380604982376: 100%|██████████| 16/16 [00:02<00:00,  7.01it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.9129754304885864: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n",
      "Training mean loss: 1.9404149651527405: 100%|██████████| 2/2 [00:00<00:00,  3.98it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8972660079598427:  94%|█████████▍| 15/16 [00:02<00:00,  6.63it/s]\n",
      "Eval mean loss: 1.8972660079598427: 100%|██████████| 16/16 [00:02<00:00,  6.84it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8972660079598427:  94%|█████████▍| 15/16 [00:02<00:00,  6.70it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   0   4   0  47]\n",
      " [  0   8   0   0  20   0 227]\n",
      " [  0   3   0   0   4   0  32]\n",
      " [  2   7   0   0  13   0 193]\n",
      " [  2   6   0   0  13   0 201]\n",
      " [  0   0   0   0   7   3  42]\n",
      " [  1   2   0   0  13   8 142]]\n",
      "{'accuracy': 0.17}\n",
      "There is label not found in predictions: {'rec', 'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.13003274971860132}\n",
      "There is label not found in predictions: {'rec', 'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.2178710352826293}\n",
      "There is label not found in predictions: {'rec', 'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.2276586237712243}\n",
      "\n",
      "Test mean loss: 1.8972660079598427: 100%|██████████| 16/16 [00:02<00:00,  6.77it/s]\n",
      "Training mean loss: 1.9404149651527405: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   311/311: 100%|██████████| 311/311 [00:23<00:00, 12.99it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 64, unlabelled size = 9936, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.68ba/s]\n",
      "100%|██████████| 9904/9904 [00:03<00:00, 3110.85ex/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 3122.48ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 96, unlabelled size = 9904, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9621433814366658: 100%|██████████| 3/3 [00:00<00:00,  4.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8992003723978996: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n",
      "Eval mean loss: 1.8992003723978996: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9621433814366658: 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "Training mean loss: 1.9631332556406658: 100%|██████████| 3/3 [00:00<00:00,  3.92it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8962132707238197:  94%|█████████▍| 15/16 [00:02<00:00,  6.70it/s]\n",
      "Eval mean loss: 1.8962132707238197: 100%|██████████| 16/16 [00:02<00:00,  6.89it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9631332556406658: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training mean loss: 1.9245431025822957: 100%|██████████| 3/3 [00:00<00:00,  4.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8930928781628609:  94%|█████████▍| 15/16 [00:02<00:00,  6.61it/s]\n",
      "Eval mean loss: 1.8930928781628609: 100%|██████████| 16/16 [00:02<00:00,  6.82it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.9245431025822957: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training mean loss: 1.9102754195531209: 100%|██████████| 3/3 [00:00<00:00,  3.97it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8876078501343727:  94%|█████████▍| 15/16 [00:02<00:00,  6.81it/s]\n",
      "Eval mean loss: 1.8876078501343727: 100%|██████████| 16/16 [00:02<00:00,  6.94it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.9102754195531209: 100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n",
      "Training mean loss: 1.8862592776616414: 100%|██████████| 3/3 [00:00<00:00,  3.82it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.88803730905056: 100%|██████████| 16/16 [00:02<00:00,  6.89it/s]  \n",
      "Eval mean loss: 1.88803730905056: 100%|██████████| 16/16 [00:02<00:00,  6.79it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.88803730905056:  94%|█████████▍| 15/16 [00:02<00:00,  6.78it/s]  \n",
      "Metrics, confusion matrix\n",
      "[[  1   1   0  41   1   0   7]\n",
      " [  1  83   0 137  12   6  16]\n",
      " [  1  16   0  19   1   0   2]\n",
      " [  0  28   0 159  11   0  17]\n",
      " [  0  25   0 124  12  12  49]\n",
      " [  1   1   0  42   2   0   6]\n",
      " [  6   6   0 123   2   0  29]]\n",
      "{'accuracy': 0.283}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.25133289099617134}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.2654628415490749}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.29448491155046824}\n",
      "\n",
      "Test mean loss: 1.88803730905056: 100%|██████████| 16/16 [00:02<00:00,  6.79it/s]\n",
      "Training mean loss: 1.8862592776616414: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   310/310: 100%|██████████| 310/310 [00:24<00:00, 12.65it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 96, unlabelled size = 9904, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.63ba/s]\n",
      "100%|██████████| 9872/9872 [00:03<00:00, 3081.89ex/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 3387.33ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 128, unlabelled size = 9872, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.957252949476242: 100%|██████████| 4/4 [00:00<00:00,  4.08it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.924219585955143:  94%|█████████▍| 15/16 [00:02<00:00,  6.99it/s] \n",
      "Eval mean loss: 1.924219585955143: 100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.957252949476242: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "Training mean loss: 1.90103080868721: 100%|██████████| 4/4 [00:01<00:00,  3.88it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.922018401324749:  94%|█████████▍| 15/16 [00:02<00:00,  6.80it/s] \n",
      "Eval mean loss: 1.922018401324749: 100%|██████████| 16/16 [00:02<00:00,  6.99it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.90103080868721: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]\n",
      "Training mean loss: 1.9102621376514435: 100%|██████████| 4/4 [00:01<00:00,  3.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9159388020634651:  94%|█████████▍| 15/16 [00:02<00:00,  6.77it/s]\n",
      "Eval mean loss: 1.9159388020634651: 100%|██████████| 16/16 [00:02<00:00,  6.91it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.9102621376514435: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]\n",
      "Training mean loss: 1.8841823935508728: 100%|██████████| 4/4 [00:01<00:00,  3.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9077172577381134:  94%|█████████▍| 15/16 [00:02<00:00,  6.67it/s]\n",
      "Eval mean loss: 1.9077172577381134: 100%|██████████| 16/16 [00:02<00:00,  6.78it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8841823935508728: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n",
      "Training mean loss: 1.8571862280368805: 100%|██████████| 4/4 [00:01<00:00,  3.81it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9014164432883263:  94%|█████████▍| 15/16 [00:02<00:00,  6.64it/s]\n",
      "Eval mean loss: 1.9014164432883263: 100%|██████████| 16/16 [00:02<00:00,  6.81it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.9014164432883263: 100%|██████████| 16/16 [00:02<00:00,  6.80it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  3   1   0   0  32  15   0]\n",
      " [  7  88   0   0 118  18  24]\n",
      " [  0  21   0   0  14   2   2]\n",
      " [  1 102   0   0  88  12  12]\n",
      " [  8  24   0   0 156  20  14]\n",
      " [  1   1   0   0  39  11   0]\n",
      " [  9   5   0   0 114  36   2]]\n",
      "{'accuracy': 0.20466666666666666}\n",
      "There is label not found in predictions: {'rec', 'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.21139834111880584}\n",
      "There is label not found in predictions: {'rec', 'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.19735125793572675}\n",
      "There is label not found in predictions: {'rec', 'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.27368185880250223}\n",
      "\n",
      "Test mean loss: 1.9014164432883263: 100%|██████████| 16/16 [00:02<00:00,  6.63it/s]\n",
      "Training mean loss: 1.8571862280368805: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   309/309: 100%|██████████| 309/309 [00:24<00:00, 12.53it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 128, unlabelled size = 9872, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.68ba/s]\n",
      "100%|██████████| 9840/9840 [00:03<00:00, 2905.32ex/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 3231.86ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 160, unlabelled size = 9840, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9160380125045777: 100%|██████████| 5/5 [00:01<00:00,  3.95it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9310956597328186:  94%|█████████▍| 15/16 [00:02<00:00,  6.85it/s]\n",
      "Eval mean loss: 1.9310956597328186: 100%|██████████| 16/16 [00:02<00:00,  7.01it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9160380125045777: 100%|██████████| 5/5 [00:03<00:00,  1.41it/s]\n",
      "Training mean loss: 1.872106909751892: 100%|██████████| 5/5 [00:01<00:00,  3.92it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9311582371592522:  94%|█████████▍| 15/16 [00:02<00:00,  6.70it/s]\n",
      "Eval mean loss: 1.9311582371592522: 100%|██████████| 16/16 [00:02<00:00,  6.83it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.872106909751892: 100%|██████████| 5/5 [00:03<00:00,  1.38it/s]\n",
      "Training mean loss: 1.8538269996643066: 100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9295155853033066:  94%|█████████▍| 15/16 [00:02<00:00,  6.69it/s]\n",
      "Eval mean loss: 1.9295155853033066: 100%|██████████| 16/16 [00:02<00:00,  6.88it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8538269996643066: 100%|██████████| 5/5 [00:03<00:00,  1.36it/s]\n",
      "Training mean loss: 1.8311939001083375: 100%|██████████| 5/5 [00:01<00:00,  3.93it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9130221903324127:  94%|█████████▍| 15/16 [00:02<00:00,  6.61it/s]\n",
      "Eval mean loss: 1.9130221903324127: 100%|██████████| 16/16 [00:02<00:00,  6.75it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8311939001083375: 100%|██████████| 5/5 [00:03<00:00,  1.37it/s]\n",
      "Training mean loss: 1.8225472688674926: 100%|██████████| 5/5 [00:01<00:00,  3.85it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9020118936896324: 100%|██████████| 16/16 [00:02<00:00,  6.64it/s]\n",
      "Eval mean loss: 1.9020118936896324: 100%|██████████| 16/16 [00:02<00:00,  6.64it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.9020118936896324: 100%|██████████| 16/16 [00:02<00:00,  6.78it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   1   1  49   0]\n",
      " [  0   3   0   1  59 192   0]\n",
      " [  0   1   0   0  14  24   0]\n",
      " [  0   1   0  28  96  90   0]\n",
      " [  0   1   0   5  34 182   0]\n",
      " [  0   0   0   0   2  50   0]\n",
      " [  0   0   0   0  17 147   2]]\n",
      "{'accuracy': 0.10983333333333334}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.09710615911315931}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.4640730447364876}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.1206959706959707}\n",
      "\n",
      "Test mean loss: 1.9020118936896324: 100%|██████████| 16/16 [00:02<00:00,  6.62it/s]\n",
      "Training mean loss: 1.8225472688674926: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   308/308: 100%|██████████| 308/308 [00:24<00:00, 12.63it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 160, unlabelled size = 9840, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.51ba/s]\n",
      "100%|██████████| 9808/9808 [00:03<00:00, 3070.68ex/s]\n",
      "100%|██████████| 192/192 [00:00<00:00, 3082.81ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 192, unlabelled size = 9808, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9212560057640076: 100%|██████████| 6/6 [00:01<00:00,  3.97it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9188627004623413:  94%|█████████▍| 15/16 [00:02<00:00,  6.81it/s]\n",
      "Eval mean loss: 1.9188627004623413: 100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9212560057640076: 100%|██████████| 6/6 [00:03<00:00,  1.58it/s]\n",
      "Training mean loss: 1.8921994765599568: 100%|██████████| 6/6 [00:01<00:00,  3.91it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.903777375817299: 100%|██████████| 16/16 [00:02<00:00,  6.92it/s] \n",
      "Eval mean loss: 1.903777375817299: 100%|██████████| 16/16 [00:02<00:00,  6.87it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8921994765599568: 100%|██████████| 6/6 [00:03<00:00,  1.55it/s]\n",
      "Training mean loss: 1.872847318649292: 100%|██████████| 6/6 [00:01<00:00,  3.91it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8902902901172638:  94%|█████████▍| 15/16 [00:02<00:00,  6.55it/s]\n",
      "Eval mean loss: 1.8902902901172638: 100%|██████████| 16/16 [00:02<00:00,  6.73it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.872847318649292: 100%|██████████| 6/6 [00:03<00:00,  1.53it/s]\n",
      "Training mean loss: 1.8387969930966694: 100%|██████████| 6/6 [00:01<00:00,  3.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.882532000541687: 100%|██████████| 16/16 [00:02<00:00,  6.76it/s] \n",
      "Eval mean loss: 1.882532000541687: 100%|██████████| 16/16 [00:02<00:00,  6.73it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8387969930966694: 100%|██████████| 6/6 [00:03<00:00,  1.52it/s]\n",
      "Training mean loss: 1.8002086281776428: 100%|██████████| 6/6 [00:01<00:00,  3.94it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8780691623687744:  94%|█████████▍| 15/16 [00:02<00:00,  6.39it/s]\n",
      "Eval mean loss: 1.8780691623687744: 100%|██████████| 16/16 [00:02<00:00,  6.53it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8780691623687744:  94%|█████████▍| 15/16 [00:02<00:00,  6.57it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  2   0   0   0   2  46   1]\n",
      " [  3  22   8  10 112  88  12]\n",
      " [  0   1   5   2  22   8   1]\n",
      " [  1   2   1  18  55 112  26]\n",
      " [  2   1   0   8  59 148   4]\n",
      " [  9   0   0   0   1  42   0]\n",
      " [ 34   0   1   3   3 119   6]]\n",
      "{'accuracy': 0.16216666666666665}\n",
      "{'f1': 0.17177957931309337}\n",
      "{'precision': 0.33408169937104293}\n",
      "{'recall': 0.16216666666666665}\n",
      "\n",
      "Test mean loss: 1.8780691623687744: 100%|██████████| 16/16 [00:02<00:00,  6.60it/s]\n",
      "Training mean loss: 1.8002086281776428: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   307/307: 100%|██████████| 307/307 [00:24<00:00, 12.56it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 192, unlabelled size = 9808, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.40ba/s]\n",
      "100%|██████████| 9776/9776 [00:03<00:00, 3005.06ex/s]\n",
      "100%|██████████| 224/224 [00:00<00:00, 3410.73ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 224, unlabelled size = 9776, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9177392039980208: 100%|██████████| 7/7 [00:01<00:00,  4.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9153546243906021: 100%|██████████| 16/16 [00:02<00:00,  6.84it/s]\n",
      "Eval mean loss: 1.9153546243906021: 100%|██████████| 16/16 [00:02<00:00,  6.83it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9177392039980208: 100%|██████████| 7/7 [00:04<00:00,  1.71it/s]\n",
      "Training mean loss: 1.8987752028873988: 100%|██████████| 7/7 [00:01<00:00,  3.74it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8959802389144897:  94%|█████████▍| 15/16 [00:02<00:00,  6.21it/s]\n",
      "Eval mean loss: 1.8959802389144897: 100%|██████████| 16/16 [00:02<00:00,  6.41it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8987752028873988: 100%|██████████| 7/7 [00:04<00:00,  1.60it/s]\n",
      "Training mean loss: 1.8822299923215593: 100%|██████████| 7/7 [00:01<00:00,  3.60it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8833326175808907:  94%|█████████▍| 15/16 [00:02<00:00,  6.22it/s]\n",
      "Eval mean loss: 1.8833326175808907: 100%|██████████| 16/16 [00:02<00:00,  6.42it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8822299923215593: 100%|██████████| 7/7 [00:04<00:00,  1.57it/s]\n",
      "Training mean loss: 1.8378181968416487: 100%|██████████| 7/7 [00:01<00:00,  3.82it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.872369036078453: 100%|██████████| 16/16 [00:02<00:00,  6.74it/s] \n",
      "Eval mean loss: 1.872369036078453: 100%|██████████| 16/16 [00:02<00:00,  6.68it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8378181968416487: 100%|██████████| 7/7 [00:04<00:00,  1.66it/s]\n",
      "Training mean loss: 1.8343007905142648: 100%|██████████| 7/7 [00:01<00:00,  3.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8357520252466202:  94%|█████████▍| 15/16 [00:02<00:00,  6.60it/s]\n",
      "Eval mean loss: 1.8357520252466202: 100%|██████████| 16/16 [00:02<00:00,  6.74it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8357520252466202:  94%|█████████▍| 15/16 [00:02<00:00,  6.60it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   1   0   0  10  31   9]\n",
      " [  0 140   0   1  82  10  22]\n",
      " [  0  21   0   0   9   0   9]\n",
      " [  0  38   0   2  95   8  72]\n",
      " [  0  32   0   0 117  42  31]\n",
      " [  0   0   0   0   0  42  10]\n",
      " [  1   4   0   0  37  62  62]]\n",
      "{'accuracy': 0.2675}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.24186660204341986}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.4553682185630528}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.27835587929240374}\n",
      "\n",
      "Test mean loss: 1.8357520252466202: 100%|██████████| 16/16 [00:02<00:00,  6.63it/s]\n",
      "Training mean loss: 1.8343007905142648: 100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   306/306: 100%|██████████| 306/306 [00:24<00:00, 12.38it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 224, unlabelled size = 9776, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.45ba/s]\n",
      "100%|██████████| 9744/9744 [00:03<00:00, 3009.40ex/s]\n",
      "100%|██████████| 256/256 [00:00<00:00, 3093.06ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 256, unlabelled size = 9744, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9464155435562134: 100%|██████████| 8/8 [00:02<00:00,  3.88it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9377797171473503: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.9377797171473503: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9464155435562134: 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\n",
      "Training mean loss: 1.9260640889406204: 100%|██████████| 8/8 [00:02<00:00,  3.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9144911468029022: 100%|██████████| 16/16 [00:02<00:00,  6.47it/s]\n",
      "Eval mean loss: 1.9144911468029022: 100%|██████████| 16/16 [00:02<00:00,  6.37it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9260640889406204: 100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\n",
      "Training mean loss: 1.8914835900068283: 100%|██████████| 8/8 [00:02<00:00,  3.90it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8947841227054596:  94%|█████████▍| 15/16 [00:02<00:00,  6.59it/s]\n",
      "Eval mean loss: 1.8947841227054596: 100%|██████████| 16/16 [00:02<00:00,  6.72it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8914835900068283: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "Training mean loss: 1.852511703968048: 100%|██████████| 8/8 [00:02<00:00,  3.85it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8812056705355644: 100%|██████████| 16/16 [00:02<00:00,  6.54it/s]\n",
      "Eval mean loss: 1.8812056705355644: 100%|██████████| 16/16 [00:02<00:00,  6.54it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.852511703968048: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "Training mean loss: 1.8168167918920517: 100%|██████████| 8/8 [00:02<00:00,  3.53it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8702176958322525: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "Eval mean loss: 1.8702176958322525: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8702176958322525:  94%|█████████▍| 15/16 [00:02<00:00,  6.42it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  1   0   0   0   0  48   2]\n",
      " [  2  50   0   0  68 134   1]\n",
      " [  0  10   1   0   8  20   0]\n",
      " [ 10  10   2   8  79 103   3]\n",
      " [  6  12   0   0  72 126   6]\n",
      " [  0   0   0   0   0  52   0]\n",
      " [  3   1   0   0   8 144  10]]\n",
      "{'accuracy': 0.1205}\n",
      "{'f1': 0.11415347342295239}\n",
      "{'precision': 0.48653762951195495}\n",
      "{'recall': 0.1205}\n",
      "\n",
      "Test mean loss: 1.8702176958322525: 100%|██████████| 16/16 [00:02<00:00,  6.46it/s]\n",
      "Training mean loss: 1.8168167918920517: 100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   305/305: 100%|██████████| 305/305 [00:24<00:00, 12.46it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 256, unlabelled size = 9744, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.14ba/s]\n",
      "100%|██████████| 9712/9712 [00:03<00:00, 3063.89ex/s]\n",
      "100%|██████████| 288/288 [00:00<00:00, 3111.66ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 288, unlabelled size = 9712, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration   9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9205819633271959: 100%|██████████| 9/9 [00:02<00:00,  3.91it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9188989400863647: 100%|██████████| 16/16 [00:02<00:00,  6.58it/s]\n",
      "Eval mean loss: 1.9188989400863647: 100%|██████████| 16/16 [00:02<00:00,  6.53it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9205819633271959: 100%|██████████| 9/9 [00:04<00:00,  1.90it/s]\n",
      "Training mean loss: 1.8879464202457004: 100%|██████████| 9/9 [00:02<00:00,  3.79it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9126798212528229: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "Eval mean loss: 1.9126798212528229: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8879464202457004: 100%|██████████| 9/9 [00:05<00:00,  1.66it/s]\n",
      "Training mean loss: 1.8625552654266357: 100%|██████████| 9/9 [00:02<00:00,  3.81it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8943944573402405: 100%|██████████| 16/16 [00:02<00:00,  6.77it/s]\n",
      "Eval mean loss: 1.8943944573402405: 100%|██████████| 16/16 [00:02<00:00,  6.70it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8625552654266357: 100%|██████████| 9/9 [00:04<00:00,  1.89it/s]\n",
      "Training mean loss: 1.8281724982791476: 100%|██████████| 9/9 [00:02<00:00,  3.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.85082495957613:  94%|█████████▍| 15/16 [00:02<00:00,  6.44it/s]  \n",
      "Eval mean loss: 1.85082495957613: 100%|██████████| 16/16 [00:02<00:00,  6.57it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8281724982791476: 100%|██████████| 9/9 [00:04<00:00,  1.88it/s]\n",
      "Training mean loss: 1.7729614045884874: 100%|██████████| 9/9 [00:02<00:00,  3.81it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8247432634234428:  94%|█████████▍| 15/16 [00:02<00:00,  6.52it/s]\n",
      "Eval mean loss: 1.8247432634234428: 100%|██████████| 16/16 [00:02<00:00,  6.67it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8247432634234428:  94%|█████████▍| 15/16 [00:02<00:00,  6.31it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 16   0   0   1   0   0  34]\n",
      " [  7   0   1  78  62   0 107]\n",
      " [  0   3   0  13  17   0   6]\n",
      " [  0   1   1  81   6   0 126]\n",
      " [ 37   0   0  27  14   0 144]\n",
      " [ 33   0   0   0   0   1  18]\n",
      " [ 39   0   0   5   1   0 121]]\n",
      "{'accuracy': 0.1865}\n",
      "{'f1': 0.1387320235543546}\n",
      "{'precision': 0.1547712057134976}\n",
      "{'recall': 0.1865}\n",
      "\n",
      "Test mean loss: 1.8247432634234428: 100%|██████████| 16/16 [00:02<00:00,  6.35it/s]\n",
      "Training mean loss: 1.7729614045884874: 100%|██████████| 9/9 [00:07<00:00,  1.23it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   304/304: 100%|██████████| 304/304 [00:24<00:00, 12.44it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 288, unlabelled size = 9712, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.55ba/s]\n",
      "100%|██████████| 9680/9680 [00:03<00:00, 3033.15ex/s]\n",
      "100%|██████████| 320/320 [00:00<00:00, 3431.46ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 320, unlabelled size = 9680, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9450373291969298: 100%|██████████| 10/10 [00:02<00:00,  4.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9204617366194725:  94%|█████████▍| 15/16 [00:02<00:00,  6.66it/s]\n",
      "Eval mean loss: 1.9204617366194725: 100%|██████████| 16/16 [00:02<00:00,  6.83it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9450373291969298: 100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n",
      "Training mean loss: 1.9100677728652955: 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9051586166024208:  94%|█████████▍| 15/16 [00:02<00:00,  6.62it/s]\n",
      "Eval mean loss: 1.9051586166024208: 100%|██████████| 16/16 [00:02<00:00,  6.79it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9100677728652955: 100%|██████████| 10/10 [00:04<00:00,  2.02it/s]\n",
      "Training mean loss: 1.8914218425750733: 100%|██████████| 10/10 [00:02<00:00,  3.87it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8744876980781555:  94%|█████████▍| 15/16 [00:02<00:00,  6.22it/s]\n",
      "Eval mean loss: 1.8744876980781555: 100%|██████████| 16/16 [00:02<00:00,  6.41it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8914218425750733: 100%|██████████| 10/10 [00:05<00:00,  1.97it/s]\n",
      "Training mean loss: 1.8447663545608521: 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.845492422580719:  94%|█████████▍| 15/16 [00:02<00:00,  6.54it/s] \n",
      "Eval mean loss: 1.845492422580719: 100%|██████████| 16/16 [00:02<00:00,  6.73it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8447663545608521: 100%|██████████| 10/10 [00:04<00:00,  2.00it/s]\n",
      "Training mean loss: 1.8033975839614869: 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8097461611032486:  94%|█████████▍| 15/16 [00:02<00:00,  6.50it/s]\n",
      "Eval mean loss: 1.8097461611032486: 100%|██████████| 16/16 [00:02<00:00,  6.67it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8097461611032486:  94%|█████████▍| 15/16 [00:02<00:00,  6.46it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   2   4   0  45]\n",
      " [  2  40  44  33  76   1  59]\n",
      " [  0   1  15  11   6   0   6]\n",
      " [  0   4  12 144  16   0  39]\n",
      " [  1  15   3  27  78   0  98]\n",
      " [  0   0   0   0   2   0  50]\n",
      " [  1   1   0   7   7   2 148]]\n",
      "{'accuracy': 0.30183333333333334}\n",
      "{'f1': 0.25940760233909016}\n",
      "{'precision': 0.42745650883784675}\n",
      "{'recall': 0.30183333333333334}\n",
      "\n",
      "Test mean loss: 1.8097461611032486: 100%|██████████| 16/16 [00:02<00:00,  6.54it/s]\n",
      "Training mean loss: 1.8033975839614869: 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   303/303: 100%|██████████| 303/303 [00:25<00:00, 11.71it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 320, unlabelled size = 9680, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.47ba/s]\n",
      "100%|██████████| 9648/9648 [00:03<00:00, 3119.02ex/s]\n",
      "100%|██████████| 352/352 [00:00<00:00, 3451.05ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 352, unlabelled size = 9648, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9399024573239414: 100%|██████████| 11/11 [00:02<00:00,  4.08it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9531132727861404: 100%|██████████| 16/16 [00:02<00:00,  6.72it/s]\n",
      "Eval mean loss: 1.9531132727861404: 100%|██████████| 16/16 [00:02<00:00,  6.73it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9399024573239414: 100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n",
      "Training mean loss: 1.926098563454368: 100%|██████████| 11/11 [00:03<00:00,  3.64it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9412172511219978: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
      "Eval mean loss: 1.9412172511219978: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.926098563454368: 100%|██████████| 11/11 [00:05<00:00,  1.93it/s]\n",
      "Training mean loss: 1.8870601654052734: 100%|██████████| 11/11 [00:03<00:00,  3.49it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.926891103386879: 100%|██████████| 16/16 [00:02<00:00,  5.69it/s] \n",
      "Eval mean loss: 1.926891103386879: 100%|██████████| 16/16 [00:02<00:00,  5.66it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8870601654052734: 100%|██████████| 11/11 [00:05<00:00,  1.84it/s]\n",
      "Training mean loss: 1.8563191348856145: 100%|██████████| 11/11 [00:03<00:00,  3.46it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8977192044258118: 100%|██████████| 16/16 [00:02<00:00,  5.81it/s]\n",
      "Eval mean loss: 1.8977192044258118: 100%|██████████| 16/16 [00:02<00:00,  5.74it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8563191348856145: 100%|██████████| 11/11 [00:05<00:00,  1.84it/s]\n",
      "Training mean loss: 1.8258140845732256: 100%|██████████| 11/11 [00:03<00:00,  3.41it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8908448740839958: 100%|██████████| 16/16 [00:02<00:00,  5.75it/s]\n",
      "Eval mean loss: 1.8908448740839958: 100%|██████████| 16/16 [00:02<00:00,  5.73it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.8908448740839958: 100%|██████████| 16/16 [00:02<00:00,  5.60it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 50   0   0   0   0   1   0]\n",
      " [ 23  35  21   1  26   4 145]\n",
      " [  1   2   7   0   8   0  21]\n",
      " [ 77  28  18  17  10  15  50]\n",
      " [105  19   8   0  37   7  46]\n",
      " [ 51   0   0   0   0   1   0]\n",
      " [134   2   0   1   4  13  12]]\n",
      "{'accuracy': 0.14283333333333334}\n",
      "{'f1': 0.12657264014281555}\n",
      "{'precision': 0.4043661413816329}\n",
      "{'recall': 0.14283333333333334}\n",
      "\n",
      "Test mean loss: 1.8908448740839958: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "Training mean loss: 1.8258140845732256: 100%|██████████| 11/11 [00:08<00:00,  1.23it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   302/302: 100%|██████████| 302/302 [00:28<00:00, 10.71it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 352, unlabelled size = 9648, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.88ba/s]\n",
      "100%|██████████| 9616/9616 [00:02<00:00, 3241.79ex/s]\n",
      "100%|██████████| 384/384 [00:00<00:00, 3528.50ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 384, unlabelled size = 9616, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.956448604663213: 100%|██████████| 12/12 [00:02<00:00,  4.02it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.928953379392624: 100%|██████████| 16/16 [00:02<00:00,  6.42it/s] \n",
      "Eval mean loss: 1.928953379392624: 100%|██████████| 16/16 [00:02<00:00,  6.40it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.956448604663213: 100%|██████████| 12/12 [00:05<00:00,  2.19it/s]\n",
      "Training mean loss: 1.9117964903513591: 100%|██████████| 12/12 [00:03<00:00,  3.62it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8923099115490913: 100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
      "Eval mean loss: 1.8923099115490913: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9117964903513591: 100%|██████████| 12/12 [00:06<00:00,  1.99it/s]\n",
      "Training mean loss: 1.8461479445298512: 100%|██████████| 12/12 [00:03<00:00,  3.38it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8580212742090225: 100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n",
      "Eval mean loss: 1.8580212742090225: 100%|██████████| 16/16 [00:02<00:00,  5.89it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8461479445298512: 100%|██████████| 12/12 [00:06<00:00,  1.91it/s]\n",
      "Training mean loss: 1.8066249390443165: 100%|██████████| 12/12 [00:03<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8006751760840416: 100%|██████████| 16/16 [00:02<00:00,  5.89it/s]\n",
      "Eval mean loss: 1.8006751760840416: 100%|██████████| 16/16 [00:02<00:00,  5.85it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8066249390443165: 100%|██████████| 12/12 [00:06<00:00,  1.96it/s]\n",
      "Training mean loss: 1.7316936751206715: 100%|██████████| 12/12 [00:03<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7529238909482956: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "Eval mean loss: 1.7529238909482956: 100%|██████████| 16/16 [00:02<00:00,  5.79it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.7529238909482956: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  8   0   2   4   0   1  36]\n",
      " [  0  20 136  72  21   0   6]\n",
      " [  1   3  27   7   1   0   0]\n",
      " [  0   9  11 179   3   0  13]\n",
      " [  4   9  34 106  34   1  34]\n",
      " [ 26   0   1   1   0  11  13]\n",
      " [ 10   1   4  10  10   7 124]]\n",
      "{'accuracy': 0.31}\n",
      "{'f1': 0.31480425816057855}\n",
      "{'precision': 0.4041792297750861}\n",
      "{'recall': 0.31}\n",
      "\n",
      "Test mean loss: 1.7529238909482956: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]\n",
      "Training mean loss: 1.7316936751206715: 100%|██████████| 12/12 [00:08<00:00,  1.35it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   301/301: 100%|██████████| 301/301 [00:26<00:00, 11.30it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 384, unlabelled size = 9616, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.09ba/s]\n",
      "100%|██████████| 9584/9584 [00:02<00:00, 3199.20ex/s]\n",
      "100%|██████████| 416/416 [00:00<00:00, 3357.36ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 416, unlabelled size = 9584, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.929385863817655: 100%|██████████| 13/13 [00:03<00:00,  4.19it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9339825510978699:  94%|█████████▍| 15/16 [00:02<00:00,  6.50it/s]\n",
      "Eval mean loss: 1.9339825510978699: 100%|██████████| 16/16 [00:02<00:00,  6.69it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.929385863817655: 100%|██████████| 13/13 [00:05<00:00,  2.37it/s]\n",
      "Training mean loss: 1.893907537827125: 100%|██████████| 13/13 [00:03<00:00,  3.48it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8943746834993362: 100%|██████████| 16/16 [00:02<00:00,  6.33it/s]\n",
      "Eval mean loss: 1.8943746834993362: 100%|██████████| 16/16 [00:02<00:00,  6.24it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.893907537827125: 100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "Training mean loss: 1.8489335041779738: 100%|██████████| 13/13 [00:03<00:00,  3.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8300748616456985: 100%|██████████| 16/16 [00:02<00:00,  6.24it/s]\n",
      "Eval mean loss: 1.8300748616456985: 100%|██████████| 16/16 [00:02<00:00,  6.21it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8489335041779738: 100%|██████████| 13/13 [00:06<00:00,  2.11it/s]\n",
      "Training mean loss: 1.8057828774819007: 100%|██████████| 13/13 [00:03<00:00,  3.66it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7928581908345222: 100%|██████████| 16/16 [00:02<00:00,  6.23it/s]\n",
      "Eval mean loss: 1.7928581908345222: 100%|██████████| 16/16 [00:02<00:00,  6.17it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8057828774819007: 100%|██████████| 13/13 [00:06<00:00,  2.11it/s]\n",
      "Training mean loss: 1.7479556523836577: 100%|██████████| 13/13 [00:03<00:00,  3.56it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7498500496149063: 100%|██████████| 16/16 [00:02<00:00,  6.21it/s]\n",
      "Eval mean loss: 1.7498500496149063: 100%|██████████| 16/16 [00:02<00:00,  6.18it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.7498500496149063: 100%|██████████| 16/16 [00:02<00:00,  6.21it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   1   0   0   2  37  11]\n",
      " [  0 229   0   0   9   0  17]\n",
      " [  0  37   0   0   1   0   1]\n",
      " [  0  67   0  76  16   5  51]\n",
      " [  0  59   0   5  61  40  57]\n",
      " [  0   0   0   0   1  48   3]\n",
      " [  0   8   0   0   7  76  75]]\n",
      "{'accuracy': 0.37983333333333336}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.40747928200276046}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.5346173973378467}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.413003663003663}\n",
      "\n",
      "Test mean loss: 1.7498500496149063: 100%|██████████| 16/16 [00:02<00:00,  6.04it/s]\n",
      "Training mean loss: 1.7479556523836577: 100%|██████████| 13/13 [00:08<00:00,  1.46it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   300/300: 100%|██████████| 300/300 [00:26<00:00, 11.13it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 416, unlabelled size = 9584, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.16ba/s]\n",
      "100%|██████████| 9552/9552 [00:02<00:00, 3310.92ex/s]\n",
      "100%|██████████| 448/448 [00:00<00:00, 3421.37ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 448, unlabelled size = 9552, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.949265718460083: 100%|██████████| 14/14 [00:03<00:00,  4.18it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.976825788617134:  94%|█████████▍| 15/16 [00:02<00:00,  6.41it/s] \n",
      "Eval mean loss: 1.976825788617134: 100%|██████████| 16/16 [00:02<00:00,  6.60it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.949265718460083: 100%|██████████| 14/14 [00:05<00:00,  2.42it/s]\n",
      "Training mean loss: 1.903927709375109: 100%|██████████| 14/14 [00:03<00:00,  3.75it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.917906977236271: 100%|██████████| 16/16 [00:02<00:00,  5.72it/s] \n",
      "Eval mean loss: 1.917906977236271: 100%|██████████| 16/16 [00:02<00:00,  5.77it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.903927709375109: 100%|██████████| 14/14 [00:06<00:00,  2.15it/s]\n",
      "Training mean loss: 1.8537040267671858: 100%|██████████| 14/14 [00:04<00:00,  3.30it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8633534982800484: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Eval mean loss: 1.8633534982800484: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8537040267671858: 100%|██████████| 14/14 [00:07<00:00,  1.94it/s]\n",
      "Training mean loss: 1.8049708434513636: 100%|██████████| 14/14 [00:04<00:00,  3.41it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8152582347393036: 100%|██████████| 16/16 [00:02<00:00,  5.77it/s]\n",
      "Eval mean loss: 1.8152582347393036: 100%|██████████| 16/16 [00:02<00:00,  5.69it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.8049708434513636: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s]\n",
      "Training mean loss: 1.7389034628868103: 100%|██████████| 14/14 [00:04<00:00,  3.45it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7646089419722557: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Eval mean loss: 1.7646089419722557: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.7646089419722557: 100%|██████████| 16/16 [00:02<00:00,  5.75it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   0   0  24  27]\n",
      " [  2 187   8   9  15  21  13]\n",
      " [  0  27   1   2   7   1   1]\n",
      " [  9  28   5  48  32  16  77]\n",
      " [  1  61   4   8  40  47  61]\n",
      " [  0   0   0   0   0  41  11]\n",
      " [  1   3   1   2   1  44 114]]\n",
      "{'accuracy': 0.2748333333333333}\n",
      "{'f1': 0.288012976999202}\n",
      "{'precision': 0.458244693847347}\n",
      "{'recall': 0.2748333333333333}\n",
      "\n",
      "Test mean loss: 1.7646089419722557: 100%|██████████| 16/16 [00:02<00:00,  5.63it/s]\n",
      "Training mean loss: 1.7389034628868103: 100%|██████████| 14/14 [00:09<00:00,  1.45it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   299/299: 100%|██████████| 299/299 [00:30<00:00,  9.96it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 448, unlabelled size = 9552, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.60ba/s]\n",
      "100%|██████████| 9520/9520 [00:04<00:00, 2231.90ex/s]\n",
      "100%|██████████| 480/480 [00:00<00:00, 3127.24ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 480, unlabelled size = 9520, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9408115943272908: 100%|██████████| 15/15 [00:03<00:00,  3.85it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.927008517086506: 100%|██████████| 16/16 [00:02<00:00,  6.17it/s] \n",
      "Eval mean loss: 1.927008517086506: 100%|██████████| 16/16 [00:02<00:00,  6.12it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9408115943272908: 100%|██████████| 15/15 [00:06<00:00,  2.31it/s]\n",
      "Training mean loss: 1.8868653694788615: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8979755640029907: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "Eval mean loss: 1.8979755640029907: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8868653694788615: 100%|██████████| 15/15 [00:07<00:00,  2.13it/s]\n",
      "Training mean loss: 1.8443925301233928: 100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8708381429314613: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Eval mean loss: 1.8708381429314613: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8443925301233928: 100%|██████████| 15/15 [00:07<00:00,  2.13it/s]\n",
      "Training mean loss: 1.7855058431625366: 100%|██████████| 15/15 [00:04<00:00,  3.52it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8250935152173042: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]\n",
      "Eval mean loss: 1.8250935152173042: 100%|██████████| 16/16 [00:02<00:00,  5.69it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7855058431625366: 100%|██████████| 15/15 [00:07<00:00,  2.12it/s]\n",
      "Training mean loss: 1.7246520121892293: 100%|██████████| 15/15 [00:04<00:00,  3.53it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7701380997896194: 100%|██████████| 16/16 [00:02<00:00,  6.02it/s]\n",
      "Eval mean loss: 1.7701380997896194: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.7701380997896194: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 22   0   1   0   3   9  16]\n",
      " [  4  65  47   1 118   1  19]\n",
      " [  0   7  19   2  10   0   1]\n",
      " [  0   4  33   7  45   1 125]\n",
      " [  4  16  17   2  88   1  94]\n",
      " [ 29   0   1   0   1  14   7]\n",
      " [ 15   4   4   0   8   7 128]]\n",
      "{'accuracy': 0.248}\n",
      "{'f1': 0.21207351880766484}\n",
      "{'precision': 0.39970531893655675}\n",
      "{'recall': 0.248}\n",
      "\n",
      "Test mean loss: 1.7701380997896194: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]\n",
      "Training mean loss: 1.7246520121892293: 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   298/298: 100%|██████████| 298/298 [00:27<00:00, 10.96it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 480, unlabelled size = 9520, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.04ba/s]\n",
      "100%|██████████| 9488/9488 [00:02<00:00, 3347.13ex/s]\n",
      "100%|██████████| 512/512 [00:00<00:00, 3379.68ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 512, unlabelled size = 9488, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9366025775671005: 100%|██████████| 16/16 [00:04<00:00,  3.87it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.945161059498787: 100%|██████████| 16/16 [00:02<00:00,  6.16it/s] \n",
      "Eval mean loss: 1.945161059498787: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9366025775671005: 100%|██████████| 16/16 [00:06<00:00,  2.37it/s]\n",
      "Training mean loss: 1.8857799172401428: 100%|██████████| 16/16 [00:05<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.916857823729515: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s] \n",
      "Eval mean loss: 1.916857823729515: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8857799172401428: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n",
      "Training mean loss: 1.8406940922141075: 100%|██████████| 16/16 [00:04<00:00,  3.47it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8801416605710983: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "Eval mean loss: 1.8801416605710983: 100%|██████████| 16/16 [00:02<00:00,  5.89it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8406940922141075: 100%|██████████| 16/16 [00:07<00:00,  2.18it/s]\n",
      "Training mean loss: 1.7810638770461082: 100%|██████████| 16/16 [00:04<00:00,  3.38it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.813463255763054: 100%|██████████| 16/16 [00:02<00:00,  5.61it/s] \n",
      "Eval mean loss: 1.813463255763054: 100%|██████████| 16/16 [00:02<00:00,  5.59it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7810638770461082: 100%|██████████| 16/16 [00:07<00:00,  2.10it/s]\n",
      "Training mean loss: 1.721355825662613: 100%|██████████| 16/16 [00:05<00:00,  2.83it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7542250901460648: 100%|██████████| 16/16 [00:03<00:00,  5.43it/s]\n",
      "Eval mean loss: 1.7542250901460648: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.7542250901460648: 100%|██████████| 16/16 [00:02<00:00,  5.75it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  7   0   0   0   1  29  14]\n",
      " [  3   7  41   1 194   3   6]\n",
      " [  0   0  18   0  20   0   1]\n",
      " [  0   1  38  84  33   2  57]\n",
      " [ 14   3  11   3 120  39  32]\n",
      " [  5   0   0   0   1  44   2]\n",
      " [ 15   1   3   1  12  38  96]]\n",
      "{'accuracy': 0.2535}\n",
      "{'f1': 0.23029974040516257}\n",
      "{'precision': 0.46709450416309667}\n",
      "{'recall': 0.2535}\n",
      "\n",
      "Test mean loss: 1.7542250901460648: 100%|██████████| 16/16 [00:02<00:00,  5.57it/s]\n",
      "Training mean loss: 1.721355825662613: 100%|██████████| 16/16 [00:11<00:00,  1.37it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   297/297: 100%|██████████| 297/297 [00:26<00:00, 11.18it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 512, unlabelled size = 9488, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.09ba/s]\n",
      "100%|██████████| 9456/9456 [00:03<00:00, 3099.30ex/s]\n",
      "100%|██████████| 544/544 [00:00<00:00, 3369.55ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 544, unlabelled size = 9456, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9619506176780253: 100%|██████████| 17/17 [00:04<00:00,  4.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9049307256937027: 100%|██████████| 16/16 [00:02<00:00,  6.31it/s]\n",
      "Eval mean loss: 1.9049307256937027: 100%|██████████| 16/16 [00:02<00:00,  6.27it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9619506176780253: 100%|██████████| 17/17 [00:06<00:00,  2.51it/s]\n",
      "Training mean loss: 1.9016128568088306: 100%|██████████| 17/17 [00:04<00:00,  3.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.839160494506359: 100%|██████████| 16/16 [00:02<00:00,  6.10it/s] \n",
      "Eval mean loss: 1.839160494506359: 100%|██████████| 16/16 [00:02<00:00,  6.04it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9016128568088306: 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]\n",
      "Training mean loss: 1.856194306822384: 100%|██████████| 17/17 [00:04<00:00,  3.59it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7727563977241516: 100%|██████████| 16/16 [00:02<00:00,  5.85it/s]\n",
      "Eval mean loss: 1.7727563977241516: 100%|██████████| 16/16 [00:02<00:00,  5.84it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.856194306822384: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n",
      "Training mean loss: 1.7822633771335377: 100%|██████████| 17/17 [00:04<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6953092440962791: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "Eval mean loss: 1.6953092440962791: 100%|██████████| 16/16 [00:02<00:00,  6.02it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7822633771335377: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n",
      "Training mean loss: 1.701049671453588: 100%|██████████| 17/17 [00:04<00:00,  3.56it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.643875002861023: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s] \n",
      "Eval mean loss: 1.643875002861023: 100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.643875002861023: 100%|██████████| 16/16 [00:02<00:00,  5.91it/s] \n",
      "Metrics, confusion matrix\n",
      "[[  0   4   0   5   1  17  24]\n",
      " [  0 243   0  12   0   0   0]\n",
      " [  0  38   0   1   0   0   0]\n",
      " [  0 119   0  78  13   1   4]\n",
      " [  0 103   0  28  74   3  14]\n",
      " [  0   2   0   0   0  38  12]\n",
      " [  0  13   0  10  27  15 101]]\n",
      "{'accuracy': 0.4186666666666667}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.4182200051157863}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.4603085768128719}\n",
      "There is label not found in predictions: {'alt', 'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.45714285714285713}\n",
      "\n",
      "Test mean loss: 1.643875002861023: 100%|██████████| 16/16 [00:02<00:00,  5.73it/s]\n",
      "Training mean loss: 1.701049671453588: 100%|██████████| 17/17 [00:10<00:00,  1.65it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   296/296: 100%|██████████| 296/296 [00:26<00:00, 11.30it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 544, unlabelled size = 9456, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.12ba/s]\n",
      "100%|██████████| 9424/9424 [00:02<00:00, 3333.86ex/s]\n",
      "100%|██████████| 576/576 [00:00<00:00, 3575.87ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 576, unlabelled size = 9424, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9521409670511882: 100%|██████████| 18/18 [00:04<00:00,  4.02it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8994583040475845: 100%|██████████| 16/16 [00:02<00:00,  6.46it/s]\n",
      "Eval mean loss: 1.8994583040475845: 100%|██████████| 16/16 [00:02<00:00,  6.42it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9521409670511882: 100%|██████████| 18/18 [00:06<00:00,  2.59it/s]\n",
      "Training mean loss: 1.9058416220876906: 100%|██████████| 18/18 [00:04<00:00,  3.60it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.890235498547554: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s] \n",
      "Eval mean loss: 1.890235498547554: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.9058416220876906: 100%|██████████| 18/18 [00:07<00:00,  2.35it/s]\n",
      "Training mean loss: 1.8616016970740423: 100%|██████████| 18/18 [00:05<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8538156524300575: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "Eval mean loss: 1.8538156524300575: 100%|██████████| 16/16 [00:02<00:00,  6.06it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8616016970740423: 100%|██████████| 18/18 [00:07<00:00,  2.35it/s]\n",
      "Training mean loss: 1.7933875454796686: 100%|██████████| 18/18 [00:05<00:00,  3.57it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7996277436614037: 100%|██████████| 16/16 [00:02<00:00,  5.89it/s]\n",
      "Eval mean loss: 1.7996277436614037: 100%|██████████| 16/16 [00:02<00:00,  5.86it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7933875454796686: 100%|██████████| 18/18 [00:07<00:00,  2.32it/s]\n",
      "Training mean loss: 1.7311587863498263: 100%|██████████| 18/18 [00:05<00:00,  3.59it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.729435533285141: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s] \n",
      "Eval mean loss: 1.729435533285141: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.729435533285141: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s] \n",
      "Metrics, confusion matrix\n",
      "[[  6   0   0   8   3  34   0]\n",
      " [  0   5   0  32 218   0   0]\n",
      " [  0   0   0   6  33   0   0]\n",
      " [  1   0   0 183  30   1   0]\n",
      " [  2   1   0  44 162   8   5]\n",
      " [  3   0   0   0   1  48   0]\n",
      " [ 10   0   0  59  28  51  18]]\n",
      "{'accuracy': 0.3495}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.2627391614221196}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.5193294237754884}\n",
      "There is label not found in predictions: {'misc'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.3636836628511967}\n",
      "\n",
      "Test mean loss: 1.729435533285141: 100%|██████████| 16/16 [00:02<00:00,  5.83it/s]\n",
      "Training mean loss: 1.7311587863498263: 100%|██████████| 18/18 [00:10<00:00,  1.73it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   295/295: 100%|██████████| 295/295 [00:26<00:00, 11.20it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 576, unlabelled size = 9424, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.00ba/s]\n",
      "100%|██████████| 9392/9392 [00:02<00:00, 3361.94ex/s]\n",
      "100%|██████████| 608/608 [00:00<00:00, 3540.36ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 608, unlabelled size = 9392, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9406635196585404: 100%|██████████| 19/19 [00:04<00:00,  3.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.919901229441166: 100%|██████████| 16/16 [00:02<00:00,  6.39it/s] \n",
      "Eval mean loss: 1.919901229441166: 100%|██████████| 16/16 [00:02<00:00,  6.36it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9406635196585404: 100%|██████████| 19/19 [00:07<00:00,  2.57it/s]\n",
      "Training mean loss: 1.8944886609127647: 100%|██████████| 19/19 [00:05<00:00,  3.59it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8790254592895508: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Eval mean loss: 1.8790254592895508: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8944886609127647: 100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n",
      "Training mean loss: 1.842972291143317: 100%|██████████| 19/19 [00:05<00:00,  3.54it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.844304196536541: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s] \n",
      "Eval mean loss: 1.844304196536541: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.842972291143317: 100%|██████████| 19/19 [00:08<00:00,  2.37it/s]\n",
      "Training mean loss: 1.7821971115313078: 100%|██████████| 19/19 [00:05<00:00,  3.56it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7878857180476189: 100%|██████████| 16/16 [00:02<00:00,  6.02it/s]\n",
      "Eval mean loss: 1.7878857180476189: 100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7821971115313078: 100%|██████████| 19/19 [00:08<00:00,  2.37it/s]\n",
      "Training mean loss: 1.7176862264934338: 100%|██████████| 19/19 [00:05<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7323065921664238: 100%|██████████| 16/16 [00:02<00:00,  6.02it/s]\n",
      "Eval mean loss: 1.7323065921664238: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.7323065921664238: 100%|██████████| 16/16 [00:02<00:00,  5.60it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   1   0   2   0  30  18]\n",
      " [  0 165  44  18   2   1  25]\n",
      " [  0  18  17   3   0   0   1]\n",
      " [  0  33  33 115   0   1  33]\n",
      " [  0  37  30  16   2  13 124]\n",
      " [  0   0   0   0   0  43   9]\n",
      " [  0   3   5   9   0  24 125]]\n",
      "{'accuracy': 0.3641666666666667}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.3635899375785414}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.41428052867356546}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.38198103266596417}\n",
      "\n",
      "Test mean loss: 1.7323065921664238: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Training mean loss: 1.7176862264934338: 100%|██████████| 19/19 [00:11<00:00,  1.72it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   294/294: 100%|██████████| 294/294 [00:27<00:00, 10.78it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 608, unlabelled size = 9392, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.82ba/s]\n",
      "100%|██████████| 9360/9360 [00:02<00:00, 3294.87ex/s]\n",
      "100%|██████████| 640/640 [00:00<00:00, 3463.54ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 640, unlabelled size = 9360, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.919357216358185: 100%|██████████| 20/20 [00:05<00:00,  3.71it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8953564018011093: 100%|██████████| 16/16 [00:02<00:00,  5.87it/s]\n",
      "Eval mean loss: 1.8953564018011093: 100%|██████████| 16/16 [00:02<00:00,  5.84it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.919357216358185: 100%|██████████| 20/20 [00:08<00:00,  2.48it/s]\n",
      "Training mean loss: 1.8543145060539246: 100%|██████████| 20/20 [00:05<00:00,  3.41it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8418582081794739: 100%|██████████| 16/16 [00:02<00:00,  5.64it/s]\n",
      "Eval mean loss: 1.8418582081794739: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8543145060539246: 100%|██████████| 20/20 [00:08<00:00,  2.28it/s]\n",
      "Training mean loss: 1.7964115202426911: 100%|██████████| 20/20 [00:06<00:00,  3.26it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7894717454910278: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "Eval mean loss: 1.7894717454910278: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7964115202426911: 100%|██████████| 20/20 [00:09<00:00,  2.22it/s]\n",
      "Training mean loss: 1.7076299488544464: 100%|██████████| 20/20 [00:06<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.722316898405552: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s] \n",
      "Eval mean loss: 1.722316898405552: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7076299488544464: 100%|██████████| 20/20 [00:09<00:00,  2.20it/s]\n",
      "Training mean loss: 1.6532433748245239: 100%|██████████| 20/20 [00:06<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6421039626002312: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "Eval mean loss: 1.6421039626002312: 100%|██████████| 16/16 [00:02<00:00,  5.51it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.6421039626002312: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  2   1   0   1   0  28  19]\n",
      " [  0 190  38   9  11   3   4]\n",
      " [  0  17  19   2   1   0   0]\n",
      " [  0  16  24 151   8   0  16]\n",
      " [  0  57  14   8  70  19  54]\n",
      " [  0   0   0   1   1  42   8]\n",
      " [  0   2   3   3   7  17 134]]\n",
      "{'accuracy': 0.5095}\n",
      "{'f1': 0.49868300533988347}\n",
      "{'precision': 0.5981307122971008}\n",
      "{'recall': 0.5095}\n",
      "\n",
      "Test mean loss: 1.6421039626002312: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "Training mean loss: 1.6532433748245239: 100%|██████████| 20/20 [00:12<00:00,  1.66it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   293/293: 100%|██████████| 293/293 [00:29<00:00, 10.02it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 640, unlabelled size = 9360, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.61ba/s]\n",
      "100%|██████████| 9328/9328 [00:03<00:00, 2681.22ex/s]\n",
      "100%|██████████| 672/672 [00:00<00:00, 3123.64ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 672, unlabelled size = 9328, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9239700862339564: 100%|██████████| 21/21 [00:07<00:00,  2.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8987674415111542: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]\n",
      "Eval mean loss: 1.8987674415111542: 100%|██████████| 16/16 [00:03<00:00,  4.69it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9239700862339564: 100%|██████████| 21/21 [00:11<00:00,  1.88it/s]\n",
      "Training mean loss: 1.8817743460337322: 100%|██████████| 21/21 [00:07<00:00,  2.95it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8513756692409515: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "Eval mean loss: 1.8513756692409515: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8817743460337322: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n",
      "Training mean loss: 1.807324312982105: 100%|██████████| 21/21 [00:08<00:00,  2.51it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8097990304231644: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]\n",
      "Eval mean loss: 1.8097990304231644: 100%|██████████| 16/16 [00:03<00:00,  4.75it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.807324312982105: 100%|██████████| 21/21 [00:11<00:00,  1.77it/s]\n",
      "Training mean loss: 1.7364206143787928: 100%|██████████| 21/21 [00:08<00:00,  2.37it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7372671142220497: 100%|██████████| 16/16 [00:03<00:00,  4.68it/s]\n",
      "Eval mean loss: 1.7372671142220497: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7364206143787928: 100%|██████████| 21/21 [00:12<00:00,  1.70it/s]\n",
      "Training mean loss: 1.651557967776344: 100%|██████████| 21/21 [00:06<00:00,  3.03it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6421672105789185: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n",
      "Eval mean loss: 1.6421672105789185: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.6421672105789185: 100%|██████████| 16/16 [00:03<00:00,  4.82it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   4   5  30  12]\n",
      " [  0 140  23  13  74   4   1]\n",
      " [  0  17   7   6   9   0   0]\n",
      " [  0   8  12 151  35   1   8]\n",
      " [  0  19   6  14 164  10   9]\n",
      " [  0   0   1   1   2  46   2]\n",
      " [  0   5   1  12  38  28  82]]\n",
      "{'accuracy': 0.45266666666666666}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.46037515184799827}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.5251186039628731}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.4768177028451001}\n",
      "\n",
      "Test mean loss: 1.6421672105789185: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Training mean loss: 1.651557967776344: 100%|██████████| 21/21 [00:13<00:00,  1.55it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   292/292: 100%|██████████| 292/292 [00:35<00:00,  8.22it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 672, unlabelled size = 9328, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.47ba/s]\n",
      "100%|██████████| 9296/9296 [00:03<00:00, 2963.34ex/s]\n",
      "100%|██████████| 704/704 [00:00<00:00, 3021.39ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 704, unlabelled size = 9296, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9215812520547346: 100%|██████████| 22/22 [00:06<00:00,  3.43it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9064511731266975: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "Eval mean loss: 1.9064511731266975: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9215812520547346: 100%|██████████| 22/22 [00:09<00:00,  2.31it/s]\n",
      "Training mean loss: 1.8563367399302395: 100%|██████████| 22/22 [00:08<00:00,  2.78it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8742096424102783: 100%|██████████| 16/16 [00:03<00:00,  5.12it/s]\n",
      "Eval mean loss: 1.8742096424102783: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8563367399302395: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n",
      "Training mean loss: 1.7861398566852917: 100%|██████████| 22/22 [00:07<00:00,  2.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7957545071840286: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "Eval mean loss: 1.7957545071840286: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7861398566852917: 100%|██████████| 22/22 [00:10<00:00,  2.07it/s]\n",
      "Training mean loss: 1.7100946794856677: 100%|██████████| 22/22 [00:07<00:00,  3.07it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7476347088813782: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n",
      "Eval mean loss: 1.7476347088813782: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7100946794856677: 100%|██████████| 22/22 [00:10<00:00,  2.10it/s]\n",
      "Training mean loss: 1.6502703374082393: 100%|██████████| 22/22 [00:07<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6486606821417809: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "Eval mean loss: 1.6486606821417809: 100%|██████████| 16/16 [00:03<00:00,  5.05it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.6486606821417809: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 18   0   0   1   4  12  16]\n",
      " [  0  25   3  31 192   3   1]\n",
      " [  0   2   5   5  27   0   0]\n",
      " [  4   0   3 157  49   0   2]\n",
      " [  5   1   1   9 196   1   9]\n",
      " [ 20   0   0   1   5  21   5]\n",
      " [ 25   0   2   1  44  11  83]]\n",
      "{'accuracy': 0.4055}\n",
      "{'f1': 0.37157580239002186}\n",
      "{'precision': 0.5343464014920478}\n",
      "{'recall': 0.4055}\n",
      "\n",
      "Test mean loss: 1.6486606821417809: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n",
      "Training mean loss: 1.6502703374082393: 100%|██████████| 22/22 [00:13<00:00,  1.61it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   291/291: 100%|██████████| 291/291 [00:31<00:00,  9.10it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 704, unlabelled size = 9296, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.40ba/s]\n",
      "100%|██████████| 9264/9264 [00:03<00:00, 2937.10ex/s]\n",
      "100%|██████████| 736/736 [00:00<00:00, 3163.71ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 736, unlabelled size = 9264, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9099978312202122: 100%|██████████| 23/23 [00:06<00:00,  3.48it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8951840475201607: 100%|██████████| 16/16 [00:03<00:00,  4.54it/s]\n",
      "Eval mean loss: 1.8951840475201607: 100%|██████████| 16/16 [00:03<00:00,  4.63it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9099978312202122: 100%|██████████| 23/23 [00:09<00:00,  2.31it/s]\n",
      "Training mean loss: 1.8225088378657466: 100%|██████████| 23/23 [00:08<00:00,  2.69it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.808168038725853: 100%|██████████| 16/16 [00:03<00:00,  5.08it/s] \n",
      "Eval mean loss: 1.808168038725853: 100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8225088378657466: 100%|██████████| 23/23 [00:12<00:00,  1.91it/s]\n",
      "Training mean loss: 1.742727429970451: 100%|██████████| 23/23 [00:07<00:00,  3.03it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7332441434264183: 100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n",
      "Eval mean loss: 1.7332441434264183: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.742727429970451: 100%|██████████| 23/23 [00:10<00:00,  2.13it/s]\n",
      "Training mean loss: 1.6522993574971738: 100%|██████████| 23/23 [00:07<00:00,  3.08it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6525497362017632: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
      "Eval mean loss: 1.6525497362017632: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.6522993574971738: 100%|██████████| 23/23 [00:10<00:00,  2.15it/s]\n",
      "Training mean loss: 1.5690566715986833: 100%|██████████| 23/23 [00:07<00:00,  3.05it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5979848951101303: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "Eval mean loss: 1.5979848951101303: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.5979848951101303: 100%|██████████| 16/16 [00:03<00:00,  4.74it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  6   0   0   1   1  36   7]\n",
      " [  5  54  80   9 100   0   7]\n",
      " [  0   1  24   7   6   0   1]\n",
      " [  0   0  19 127  43   2  24]\n",
      " [ 12   5  17   3 129   6  50]\n",
      " [  2   0   0   0   0  49   1]\n",
      " [  6   1   1   3   8  53  94]]\n",
      "{'accuracy': 0.4098333333333333}\n",
      "{'f1': 0.4226465151678541}\n",
      "{'precision': 0.5531363193085782}\n",
      "{'recall': 0.4098333333333333}\n",
      "\n",
      "Test mean loss: 1.5979848951101303: 100%|██████████| 16/16 [00:03<00:00,  4.64it/s]\n",
      "Training mean loss: 1.5690566715986833: 100%|██████████| 23/23 [00:14<00:00,  1.63it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   290/290: 100%|██████████| 290/290 [00:29<00:00,  9.73it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 736, unlabelled size = 9264, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.30ba/s]\n",
      "100%|██████████| 9232/9232 [00:02<00:00, 3089.66ex/s]\n",
      "100%|██████████| 768/768 [00:00<00:00, 3246.10ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 768, unlabelled size = 9232, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9058224856853485: 100%|██████████| 24/24 [00:06<00:00,  3.37it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.877868391573429: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s] \n",
      "Eval mean loss: 1.877868391573429: 100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9058224856853485: 100%|██████████| 24/24 [00:10<00:00,  2.37it/s]\n",
      "Training mean loss: 1.8264886736869812: 100%|██████████| 24/24 [00:07<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8102940320968628: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "Eval mean loss: 1.8102940320968628: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8264886736869812: 100%|██████████| 24/24 [00:10<00:00,  2.21it/s]\n",
      "Training mean loss: 1.7336094031731288: 100%|██████████| 24/24 [00:07<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.717605896294117: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s] \n",
      "Eval mean loss: 1.717605896294117: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7336094031731288: 100%|██████████| 24/24 [00:11<00:00,  2.17it/s]\n",
      "Training mean loss: 1.6504568060239155: 100%|██████████| 24/24 [00:07<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6255024448037148: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n",
      "Eval mean loss: 1.6255024448037148: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.6504568060239155: 100%|██████████| 24/24 [00:11<00:00,  2.18it/s]\n",
      "Training mean loss: 1.5454640587170918: 100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.550258845090866: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s] \n",
      "Eval mean loss: 1.550258845090866: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.550258845090866: 100%|██████████| 16/16 [00:03<00:00,  4.83it/s] \n",
      "Metrics, confusion matrix\n",
      "[[  0   0   1   2   0  30  18]\n",
      " [  0 143  33  24  48   2   5]\n",
      " [  0  17  15   4   2   0   1]\n",
      " [  0   8  13 159  17   0  18]\n",
      " [  1  24  14  15  95   5  68]\n",
      " [  0   1   0   1   0  47   3]\n",
      " [  2   2   1   7   2  21 131]]\n",
      "{'accuracy': 0.5093333333333333}\n",
      "{'f1': 0.5103728502182071}\n",
      "{'precision': 0.5635850534105907}\n",
      "{'recall': 0.5093333333333333}\n",
      "\n",
      "Test mean loss: 1.550258845090866: 100%|██████████| 16/16 [00:03<00:00,  4.76it/s]\n",
      "Training mean loss: 1.5454640587170918: 100%|██████████| 24/24 [00:14<00:00,  1.70it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   289/289: 100%|██████████| 289/289 [00:30<00:00,  9.48it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 768, unlabelled size = 9232, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.28ba/s]\n",
      "100%|██████████| 9200/9200 [00:03<00:00, 2848.70ex/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 3183.31ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 800, unlabelled size = 9200, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9203940105438233: 100%|██████████| 25/25 [00:07<00:00,  3.40it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8658234626054764: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "Eval mean loss: 1.8658234626054764: 100%|██████████| 16/16 [00:03<00:00,  4.98it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9203940105438233: 100%|██████████| 25/25 [00:10<00:00,  2.40it/s]\n",
      "Training mean loss: 1.8339196348190308: 100%|██████████| 25/25 [00:08<00:00,  2.86it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8221522197127342: 100%|██████████| 16/16 [00:03<00:00,  4.58it/s]\n",
      "Eval mean loss: 1.8221522197127342: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8339196348190308: 100%|██████████| 25/25 [00:12<00:00,  2.06it/s]\n",
      "Training mean loss: 1.7641521549224854: 100%|██████████| 25/25 [00:08<00:00,  2.87it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7504692524671555: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]\n",
      "Eval mean loss: 1.7504692524671555: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7641521549224854: 100%|██████████| 25/25 [00:12<00:00,  2.05it/s]\n",
      "Training mean loss: 1.6706887435913087: 100%|██████████| 25/25 [00:08<00:00,  3.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6716357469558716: 100%|██████████| 16/16 [00:03<00:00,  5.05it/s]\n",
      "Eval mean loss: 1.6716357469558716: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.6706887435913087: 100%|██████████| 25/25 [00:11<00:00,  2.17it/s]\n",
      "Training mean loss: 1.5633047533035278: 100%|██████████| 25/25 [00:08<00:00,  3.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.584543913602829: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s] \n",
      "Eval mean loss: 1.584543913602829: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.584543913602829: 100%|██████████| 16/16 [00:03<00:00,  5.25it/s] \n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   2   0  36  13]\n",
      " [  0 103 119  16   6   2   9]\n",
      " [  0   3  33   2   0   0   1]\n",
      " [  0   1  32 165   4   1  12]\n",
      " [  0  30  45  16  46  29  56]\n",
      " [  0   0   0   0   0  50   2]\n",
      " [  1   2   4   7   2  31 119]]\n",
      "{'accuracy': 0.4205}\n",
      "{'f1': 0.41880924584787105}\n",
      "{'precision': 0.5394348584758297}\n",
      "{'recall': 0.4205}\n",
      "\n",
      "Test mean loss: 1.584543913602829: 100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n",
      "Training mean loss: 1.5633047533035278: 100%|██████████| 25/25 [00:14<00:00,  1.71it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   288/288: 100%|██████████| 288/288 [00:33<00:00,  8.61it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 800, unlabelled size = 9200, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.55ba/s]\n",
      "100%|██████████| 9168/9168 [00:03<00:00, 2967.97ex/s]\n",
      "100%|██████████| 832/832 [00:00<00:00, 2997.76ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 832, unlabelled size = 9168, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9038928701327398: 100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9181133136153221: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s]\n",
      "Eval mean loss: 1.9181133136153221: 100%|██████████| 16/16 [00:03<00:00,  5.18it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9038928701327398: 100%|██████████| 26/26 [00:10<00:00,  2.43it/s]\n",
      "Training mean loss: 1.8347325508411114: 100%|██████████| 26/26 [00:08<00:00,  2.97it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8315921872854233: 100%|██████████| 16/16 [00:03<00:00,  3.96it/s]\n",
      "Eval mean loss: 1.8315921872854233: 100%|██████████| 16/16 [00:03<00:00,  4.12it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8347325508411114: 100%|██████████| 26/26 [00:12<00:00,  2.08it/s]\n",
      "Training mean loss: 1.752861357652224: 100%|██████████| 26/26 [00:09<00:00,  2.88it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7520547360181808: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n",
      "Eval mean loss: 1.7520547360181808: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.752861357652224: 100%|██████████| 26/26 [00:12<00:00,  2.07it/s]\n",
      "Training mean loss: 1.650048920741448: 100%|██████████| 26/26 [00:08<00:00,  2.92it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6586164757609367: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n",
      "Eval mean loss: 1.6586164757609367: 100%|██████████| 16/16 [00:03<00:00,  4.58it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.650048920741448: 100%|██████████| 26/26 [00:12<00:00,  2.09it/s]\n",
      "Training mean loss: 1.542621841797462: 100%|██████████| 26/26 [00:10<00:00,  2.45it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5873006731271744: 100%|██████████| 16/16 [00:03<00:00,  4.61it/s]\n",
      "Eval mean loss: 1.5873006731271744: 100%|██████████| 16/16 [00:03<00:00,  4.44it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.5873006731271744: 100%|██████████| 16/16 [00:03<00:00,  4.76it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  3   0   0   2   5  39   2]\n",
      " [  0 149  76   0  27   1   2]\n",
      " [  0   8  30   0   1   0   0]\n",
      " [  0   9  58 119  18   4   7]\n",
      " [  6  18  44   2 104  28  20]\n",
      " [  1   0   0   0   1  50   0]\n",
      " [  4   1   9   2  16  58  76]]\n",
      "{'accuracy': 0.423}\n",
      "{'f1': 0.46595698590747936}\n",
      "{'precision': 0.6361392148348313}\n",
      "{'recall': 0.423}\n",
      "\n",
      "Test mean loss: 1.5873006731271744: 100%|██████████| 16/16 [00:03<00:00,  4.70it/s]\n",
      "Training mean loss: 1.542621841797462: 100%|██████████| 26/26 [00:17<00:00,  1.48it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   287/287: 100%|██████████| 287/287 [00:37<00:00,  7.58it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 832, unlabelled size = 9168, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.10ba/s]\n",
      "100%|██████████| 9136/9136 [00:04<00:00, 2220.81ex/s]\n",
      "100%|██████████| 864/864 [00:00<00:00, 2201.17ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 864, unlabelled size = 9136, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9339228603574965: 100%|██████████| 27/27 [00:11<00:00,  2.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8872238993644714: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "Eval mean loss: 1.8872238993644714: 100%|██████████| 16/16 [00:03<00:00,  4.19it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9339228603574965: 100%|██████████| 27/27 [00:14<00:00,  1.82it/s]\n",
      "Training mean loss: 1.8837562490392614: 100%|██████████| 27/27 [00:09<00:00,  2.94it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8538880422711372: 100%|██████████| 16/16 [00:03<00:00,  4.44it/s]\n",
      "Eval mean loss: 1.8538880422711372: 100%|██████████| 16/16 [00:03<00:00,  4.39it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8837562490392614: 100%|██████████| 27/27 [00:12<00:00,  2.10it/s]\n",
      "Training mean loss: 1.8031203923402008: 100%|██████████| 27/27 [00:09<00:00,  2.97it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7754152938723564: 100%|██████████| 16/16 [00:03<00:00,  4.76it/s]\n",
      "Eval mean loss: 1.7754152938723564: 100%|██████████| 16/16 [00:03<00:00,  4.75it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.8031203923402008: 100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n",
      "Training mean loss: 1.7071894098211218: 100%|██████████| 27/27 [00:09<00:00,  2.90it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6703092157840729: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "Eval mean loss: 1.6703092157840729: 100%|██████████| 16/16 [00:03<00:00,  4.83it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.7071894098211218: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n",
      "Training mean loss: 1.5987648654867102: 100%|██████████| 27/27 [00:09<00:00,  2.98it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5876336768269539: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "Eval mean loss: 1.5876336768269539: 100%|██████████| 16/16 [00:03<00:00,  5.25it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.5876336768269539: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   1   3   0   1  30  16]\n",
      " [  1 115 113  11  15   0   0]\n",
      " [  0   4  33   2   0   0   0]\n",
      " [  0   3  62 133   8   0   9]\n",
      " [  1  26  43  17  97   4  34]\n",
      " [  1   1   0   0   0  42   8]\n",
      " [  2   3   9   7   9  21 115]]\n",
      "{'accuracy': 0.405}\n",
      "{'f1': 0.39815243313507276}\n",
      "{'precision': 0.5504818507044912}\n",
      "{'recall': 0.405}\n",
      "\n",
      "Test mean loss: 1.5876336768269539: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
      "Training mean loss: 1.5987648654867102: 100%|██████████| 27/27 [00:15<00:00,  1.77it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   286/286: 100%|██████████| 286/286 [00:30<00:00,  9.38it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 864, unlabelled size = 9136, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.40ba/s]\n",
      "100%|██████████| 9104/9104 [00:03<00:00, 3008.78ex/s]\n",
      "100%|██████████| 896/896 [00:00<00:00, 3264.70ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 896, unlabelled size = 9104, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.915033791746412: 100%|██████████| 28/28 [00:08<00:00,  3.42it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8476508036255836: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.8476508036255836: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.915033791746412: 100%|██████████| 28/28 [00:10<00:00,  2.55it/s]\n",
      "Training mean loss: 1.839085659810475: 100%|██████████| 28/28 [00:08<00:00,  3.20it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.785171516239643: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s] \n",
      "Eval mean loss: 1.785171516239643: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.839085659810475: 100%|██████████| 28/28 [00:11<00:00,  2.36it/s]\n",
      "Training mean loss: 1.7355124865259444: 100%|██████████| 28/28 [00:08<00:00,  3.24it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7263654991984367: 100%|██████████| 16/16 [00:03<00:00,  5.37it/s]\n",
      "Eval mean loss: 1.7263654991984367: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7355124865259444: 100%|██████████| 28/28 [00:11<00:00,  2.40it/s]\n",
      "Training mean loss: 1.622963662658419: 100%|██████████| 28/28 [00:08<00:00,  3.19it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.63413405418396: 100%|██████████| 16/16 [00:03<00:00,  5.36it/s]  \n",
      "Eval mean loss: 1.63413405418396: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.622963662658419: 100%|██████████| 28/28 [00:11<00:00,  2.36it/s]\n",
      "Training mean loss: 1.5307160062449319: 100%|██████████| 28/28 [00:10<00:00,  2.61it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5509610995650291: 100%|██████████| 16/16 [00:04<00:00,  3.23it/s]\n",
      "Eval mean loss: 1.5509610995650291: 100%|██████████| 16/16 [00:04<00:00,  3.21it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.5509610995650291: 100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  4   2   0   5   0  22  18]\n",
      " [  0  13 236   3   2   1   0]\n",
      " [  0   0  39   0   0   0   0]\n",
      " [  0   0  89 119   0   1   6]\n",
      " [  0  11 113  18  52   1  27]\n",
      " [  0   0   1   0   1  40  10]\n",
      " [  1   1  15  17  14  16 102]]\n",
      "{'accuracy': 0.38133333333333336}\n",
      "{'f1': 0.40427001263411805}\n",
      "{'precision': 0.55417280807299}\n",
      "{'recall': 0.38133333333333336}\n",
      "\n",
      "Test mean loss: 1.5509610995650291: 100%|██████████| 16/16 [00:04<00:00,  3.56it/s]\n",
      "Training mean loss: 1.5307160062449319: 100%|██████████| 28/28 [00:19<00:00,  1.43it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   285/285: 100%|██████████| 285/285 [00:36<00:00,  7.73it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 896, unlabelled size = 9104, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.93ba/s]\n",
      "100%|██████████| 9072/9072 [00:03<00:00, 2824.60ex/s]\n",
      "100%|██████████| 928/928 [00:00<00:00, 3004.54ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 928, unlabelled size = 9072, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9285580413094883: 100%|██████████| 29/29 [00:09<00:00,  2.80it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8787869289517403: 100%|██████████| 16/16 [00:04<00:00,  3.11it/s]\n",
      "Eval mean loss: 1.8787869289517403: 100%|██████████| 16/16 [00:04<00:00,  3.25it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9285580413094883: 100%|██████████| 29/29 [00:14<00:00,  1.95it/s]\n",
      "Training mean loss: 1.8430202870533383: 100%|██████████| 29/29 [00:10<00:00,  2.67it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8217025324702263: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n",
      "Eval mean loss: 1.8217025324702263: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8430202870533383: 100%|██████████| 29/29 [00:14<00:00,  2.05it/s]\n",
      "Training mean loss: 1.742256102890804: 100%|██████████| 29/29 [00:11<00:00,  2.51it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7225824669003487: 100%|██████████| 16/16 [00:03<00:00,  5.20it/s]\n",
      "Eval mean loss: 1.7225824669003487: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.742256102890804: 100%|██████████| 29/29 [00:14<00:00,  2.02it/s]\n",
      "Training mean loss: 1.6255887294637745: 100%|██████████| 29/29 [00:09<00:00,  3.08it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6257488504052162: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]\n",
      "Eval mean loss: 1.6257488504052162: 100%|██████████| 16/16 [00:03<00:00,  4.73it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.6255887294637745: 100%|██████████| 29/29 [00:12<00:00,  2.26it/s]\n",
      "Training mean loss: 1.5075149042852993: 100%|██████████| 29/29 [00:09<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5383015051484108: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
      "Eval mean loss: 1.5383015051484108: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.5383015051484108: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 25   0   0   2   0  16   8]\n",
      " [  1  91 125  12  19   0   7]\n",
      " [  0   1  37   0   1   0   0]\n",
      " [  5   5  43 143   7   0  12]\n",
      " [  7  24  39  11  85   8  48]\n",
      " [  7   0   0   0   1  41   3]\n",
      " [ 54   1   3   6   6  23  73]]\n",
      "{'accuracy': 0.4156666666666667}\n",
      "{'f1': 0.41923172146589166}\n",
      "{'precision': 0.5401605610869648}\n",
      "{'recall': 0.4156666666666667}\n",
      "\n",
      "Test mean loss: 1.5383015051484108: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n",
      "Training mean loss: 1.5075149042852993: 100%|██████████| 29/29 [00:15<00:00,  1.85it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   284/284: 100%|██████████| 284/284 [00:29<00:00,  9.68it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 928, unlabelled size = 9072, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.73ba/s]\n",
      "100%|██████████| 9040/9040 [00:02<00:00, 3041.44ex/s]\n",
      "100%|██████████| 960/960 [00:00<00:00, 3265.52ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 960, unlabelled size = 9040, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.919098138809204: 100%|██████████| 30/30 [00:09<00:00,  3.27it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8502372279763222: 100%|██████████| 16/16 [00:03<00:00,  5.20it/s]\n",
      "Eval mean loss: 1.8502372279763222: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.919098138809204: 100%|██████████| 30/30 [00:12<00:00,  2.46it/s]\n",
      "Training mean loss: 1.8277937332789103: 100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7802342772483826: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "Eval mean loss: 1.7802342772483826: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8277937332789103: 100%|██████████| 30/30 [00:12<00:00,  2.39it/s]\n",
      "Training mean loss: 1.7315956910451253: 100%|██████████| 30/30 [00:09<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.685584656894207: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s] \n",
      "Eval mean loss: 1.685584656894207: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7315956910451253: 100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n",
      "Training mean loss: 1.6120094339052835: 100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5732316002249718: 100%|██████████| 16/16 [00:03<00:00,  5.36it/s]\n",
      "Eval mean loss: 1.5732316002249718: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.6120094339052835: 100%|██████████| 30/30 [00:12<00:00,  2.38it/s]\n",
      "Training mean loss: 1.497639548778534: 100%|██████████| 30/30 [00:09<00:00,  3.09it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.495347760617733: 100%|██████████| 16/16 [00:03<00:00,  5.37it/s] \n",
      "Eval mean loss: 1.495347760617733: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.495347760617733: 100%|██████████| 16/16 [00:03<00:00,  4.38it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 22   0   0   1   0  22   6]\n",
      " [  1 217   5   4  23   1   4]\n",
      " [  0  30   7   0   2   0   0]\n",
      " [  1  18   8 149  20   1  18]\n",
      " [  6  53  10   4 102  12  35]\n",
      " [  7   1   0   0   0  44   0]\n",
      " [ 53   2   2   2   3  29  75]]\n",
      "{'accuracy': 0.534}\n",
      "{'f1': 0.5416327898346567}\n",
      "{'precision': 0.5747931239102929}\n",
      "{'recall': 0.534}\n",
      "\n",
      "Test mean loss: 1.495347760617733: 100%|██████████| 16/16 [00:03<00:00,  4.36it/s]\n",
      "Training mean loss: 1.497639548778534: 100%|██████████| 30/30 [00:16<00:00,  1.83it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   283/283: 100%|██████████| 283/283 [00:28<00:00,  9.93it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 960, unlabelled size = 9040, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.71ba/s]\n",
      "100%|██████████| 9008/9008 [00:02<00:00, 3101.46ex/s]\n",
      "100%|██████████| 992/992 [00:00<00:00, 3317.76ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 992, unlabelled size = 9008, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9197309940092024: 100%|██████████| 31/31 [00:08<00:00,  3.48it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9472358152270317: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.9472358152270317: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9197309940092024: 100%|██████████| 31/31 [00:11<00:00,  2.65it/s]\n",
      "Training mean loss: 1.846867818986216: 100%|██████████| 31/31 [00:09<00:00,  3.27it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8358825668692589: 100%|██████████| 16/16 [00:02<00:00,  5.49it/s]\n",
      "Eval mean loss: 1.8358825668692589: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.846867818986216: 100%|██████████| 31/31 [00:12<00:00,  2.50it/s]\n",
      "Training mean loss: 1.7451713585084485: 100%|██████████| 31/31 [00:09<00:00,  3.22it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.742672361433506: 100%|██████████| 16/16 [00:02<00:00,  5.51it/s] \n",
      "Eval mean loss: 1.742672361433506: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7451713585084485: 100%|██████████| 31/31 [00:12<00:00,  2.48it/s]\n",
      "Training mean loss: 1.6385077507265153: 100%|██████████| 31/31 [00:09<00:00,  3.23it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6193868294358253: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "Eval mean loss: 1.6193868294358253: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.6385077507265153: 100%|██████████| 31/31 [00:12<00:00,  2.46it/s]\n",
      "Training mean loss: 1.5355549973826255: 100%|██████████| 31/31 [00:09<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.524630181491375: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s] \n",
      "Eval mean loss: 1.524630181491375: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.524630181491375: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 13   0   1   2   1  28   6]\n",
      " [  1 139  42  44  24   2   3]\n",
      " [  0   6  20  12   1   0   0]\n",
      " [  0   5   3 183  12   2  10]\n",
      " [  4  28  11  26 104  24  25]\n",
      " [  3   0   0   0   2  47   0]\n",
      " [ 14   1   4   8   6  25 108]]\n",
      "{'accuracy': 0.455}\n",
      "{'f1': 0.44829279371943004}\n",
      "{'precision': 0.5640654692402775}\n",
      "{'recall': 0.455}\n",
      "\n",
      "Test mean loss: 1.524630181491375: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "Training mean loss: 1.5355549973826255: 100%|██████████| 31/31 [00:15<00:00,  2.01it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   282/282: 100%|██████████| 282/282 [00:27<00:00, 10.25it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 992, unlabelled size = 9008, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.88ba/s]\n",
      "100%|██████████| 8976/8976 [00:02<00:00, 3008.93ex/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3212.67ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1024, unlabelled size = 8976, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.941043883562088: 100%|██████████| 32/32 [00:08<00:00,  3.50it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9438636228442192: 100%|██████████| 16/16 [00:02<00:00,  5.51it/s]\n",
      "Eval mean loss: 1.9438636228442192: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.941043883562088: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]\n",
      "Training mean loss: 1.8748849220573902: 100%|██████████| 32/32 [00:09<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8763578161597252: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "Eval mean loss: 1.8763578161597252: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8748849220573902: 100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
      "Training mean loss: 1.7787422947585583: 100%|██████████| 32/32 [00:09<00:00,  3.24it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7776872590184212: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "Eval mean loss: 1.7776872590184212: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7787422947585583: 100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
      "Training mean loss: 1.669726487249136: 100%|██████████| 32/32 [00:09<00:00,  3.25it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6641672551631927: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "Eval mean loss: 1.6641672551631927: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.669726487249136: 100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
      "Training mean loss: 1.533707533031702: 100%|██████████| 32/32 [00:09<00:00,  3.28it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.609646126627922: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s] \n",
      "Eval mean loss: 1.609646126627922: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.609646126627922: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 11   1   0   4   0  22  13]\n",
      " [  1  46 191  10   2   0   5]\n",
      " [  0   1  38   0   0   0   0]\n",
      " [  0   4  86 113   2   0  10]\n",
      " [  4  23  75  31  35   0  54]\n",
      " [  1   0   1   0   0  46   4]\n",
      " [  6   1  15  12   1  23 108]]\n",
      "{'accuracy': 0.32166666666666666}\n",
      "{'f1': 0.3211127958102592}\n",
      "{'precision': 0.5531414617120035}\n",
      "{'recall': 0.32166666666666666}\n",
      "\n",
      "Test mean loss: 1.609646126627922: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "Training mean loss: 1.533707533031702: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   281/281: 100%|██████████| 281/281 [00:27<00:00, 10.29it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1024, unlabelled size = 8976, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.21ba/s]\n",
      "100%|██████████| 8944/8944 [00:02<00:00, 3233.53ex/s]\n",
      "100%|██████████| 1056/1056 [00:00<00:00, 3212.27ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1056, unlabelled size = 8944, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9110220634576045: 100%|██████████| 33/33 [00:09<00:00,  3.48it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8870662674307823: 100%|██████████| 16/16 [00:02<00:00,  5.49it/s]\n",
      "Eval mean loss: 1.8870662674307823: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9110220634576045: 100%|██████████| 33/33 [00:12<00:00,  2.72it/s]\n",
      "Training mean loss: 1.8006477572701194: 100%|██████████| 33/33 [00:09<00:00,  3.34it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.796244852244854: 100%|██████████| 16/16 [00:03<00:00,  5.36it/s] \n",
      "Eval mean loss: 1.796244852244854: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8006477572701194: 100%|██████████| 33/33 [00:12<00:00,  2.56it/s]\n",
      "Training mean loss: 1.7055787967913079: 100%|██████████| 33/33 [00:09<00:00,  3.34it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7095968946814537: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "Eval mean loss: 1.7095968946814537: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7055787967913079: 100%|██████████| 33/33 [00:12<00:00,  2.57it/s]\n",
      "Training mean loss: 1.581550576470115: 100%|██████████| 33/33 [00:09<00:00,  3.33it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6042145192623138: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Eval mean loss: 1.6042145192623138: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.581550576470115: 100%|██████████| 33/33 [00:12<00:00,  2.55it/s]\n",
      "Training mean loss: 1.4657842390465015: 100%|██████████| 33/33 [00:09<00:00,  3.32it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5189436450600624: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.5189436450600624: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.5189436450600624: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  3   0   0   3   0  40   5]\n",
      " [  2  60 139  49   1   1   3]\n",
      " [  0   1  35   2   1   0   0]\n",
      " [  0   3  19 182   1   2   8]\n",
      " [ 11  23  65  35  20  17  51]\n",
      " [  2   0   1   0   0  48   1]\n",
      " [  6   0   5  10   0  62  83]]\n",
      "{'accuracy': 0.35483333333333333}\n",
      "{'f1': 0.3475685671871786}\n",
      "{'precision': 0.5490169434495427}\n",
      "{'recall': 0.35483333333333333}\n",
      "\n",
      "Test mean loss: 1.5189436450600624: 100%|██████████| 16/16 [00:02<00:00,  5.33it/s]\n",
      "Training mean loss: 1.4657842390465015: 100%|██████████| 33/33 [00:15<00:00,  2.07it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   280/280: 100%|██████████| 280/280 [00:27<00:00, 10.28it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1056, unlabelled size = 8944, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.30ba/s]\n",
      "100%|██████████| 8912/8912 [00:02<00:00, 3241.84ex/s]\n",
      "100%|██████████| 1088/1088 [00:00<00:00, 3215.41ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1088, unlabelled size = 8912, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.896860872997957: 100%|██████████| 34/34 [00:09<00:00,  3.51it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8944601267576218: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "Eval mean loss: 1.8944601267576218: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.896860872997957: 100%|██████████| 34/34 [00:12<00:00,  2.75it/s]\n",
      "Training mean loss: 1.789033269180971: 100%|██████████| 34/34 [00:10<00:00,  3.35it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7828496843576431: 100%|██████████| 16/16 [00:02<00:00,  5.49it/s]\n",
      "Eval mean loss: 1.7828496843576431: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.789033269180971: 100%|██████████| 34/34 [00:13<00:00,  2.59it/s]\n",
      "Training mean loss: 1.6538739204406738: 100%|██████████| 34/34 [00:10<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6750089600682259: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "Eval mean loss: 1.6750089600682259: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6538739204406738: 100%|██████████| 34/34 [00:13<00:00,  2.59it/s]\n",
      "Training mean loss: 1.516622006893158: 100%|██████████| 34/34 [00:10<00:00,  3.37it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5411078855395317: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.5411078855395317: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.516622006893158: 100%|██████████| 34/34 [00:13<00:00,  2.60it/s]\n",
      "Training mean loss: 1.3804216980934143: 100%|██████████| 34/34 [00:10<00:00,  3.37it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4472660794854164: 100%|██████████| 16/16 [00:02<00:00,  5.58it/s]\n",
      "Eval mean loss: 1.4472660794854164: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.4472660794854164: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  8   0   0   4   0  35   4]\n",
      " [  0 147  53  18  32   1   4]\n",
      " [  0   7  29   2   1   0   0]\n",
      " [  0   1  21 177  10   4   2]\n",
      " [  2  24  11  35  94  24  32]\n",
      " [  0   1   0   0   0  51   0]\n",
      " [ 13   1   1  19   3  68  61]]\n",
      "{'accuracy': 0.42433333333333334}\n",
      "{'f1': 0.4369532243453194}\n",
      "{'precision': 0.5653729345093288}\n",
      "{'recall': 0.42433333333333334}\n",
      "\n",
      "Test mean loss: 1.4472660794854164: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Training mean loss: 1.3804216980934143: 100%|██████████| 34/34 [00:16<00:00,  2.11it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   279/279: 100%|██████████| 279/279 [00:27<00:00,  9.99it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1088, unlabelled size = 8912, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  4.90ba/s]\n",
      "100%|██████████| 8880/8880 [00:02<00:00, 3195.53ex/s]\n",
      "100%|██████████| 1120/1120 [00:00<00:00, 3224.23ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1120, unlabelled size = 8880, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9089647769927978: 100%|██████████| 35/35 [00:09<00:00,  3.44it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.853128731250763: 100%|██████████| 16/16 [00:02<00:00,  5.51it/s] \n",
      "Eval mean loss: 1.853128731250763: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9089647769927978: 100%|██████████| 35/35 [00:12<00:00,  2.73it/s]\n",
      "Training mean loss: 1.810372359412057: 100%|██████████| 35/35 [00:10<00:00,  3.33it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.721199445426464: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s] \n",
      "Eval mean loss: 1.721199445426464: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.810372359412057: 100%|██████████| 35/35 [00:13<00:00,  2.60it/s]\n",
      "Training mean loss: 1.6681345292500087: 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5859564542770386: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s]\n",
      "Eval mean loss: 1.5859564542770386: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6681345292500087: 100%|██████████| 35/35 [00:13<00:00,  2.54it/s]\n",
      "Training mean loss: 1.542443026815142: 100%|██████████| 35/35 [00:10<00:00,  3.30it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4681964963674545: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 1.4681964963674545: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.542443026815142: 100%|██████████| 35/35 [00:13<00:00,  2.56it/s]\n",
      "Training mean loss: 1.3925620930535452: 100%|██████████| 35/35 [00:10<00:00,  3.29it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.362188883125782: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s] \n",
      "Eval mean loss: 1.362188883125782: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.362188883125782: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 14   0   0   5   2  29   1]\n",
      " [  0 214  15   3  23   0   0]\n",
      " [  0  21  16   1   1   0   0]\n",
      " [  2  16  11 161  22   0   3]\n",
      " [  5  53   4  12 135   6   7]\n",
      " [  0   0   0   0   1  51   0]\n",
      " [ 17   2   2   9  15  36  85]]\n",
      "{'accuracy': 0.5743333333333334}\n",
      "{'f1': 0.5715383836127881}\n",
      "{'precision': 0.6215043352879538}\n",
      "{'recall': 0.5743333333333334}\n",
      "\n",
      "Test mean loss: 1.362188883125782: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "Training mean loss: 1.3925620930535452: 100%|██████████| 35/35 [00:16<00:00,  2.09it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   278/278: 100%|██████████| 278/278 [00:27<00:00, 10.16it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1120, unlabelled size = 8880, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.58ba/s]\n",
      "100%|██████████| 8848/8848 [00:02<00:00, 2968.36ex/s]\n",
      "100%|██████████| 1152/1152 [00:00<00:00, 2752.83ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1152, unlabelled size = 8848, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9133381843566895: 100%|██████████| 36/36 [00:10<00:00,  3.26it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8520342707633972: 100%|██████████| 16/16 [00:03<00:00,  5.36it/s]\n",
      "Eval mean loss: 1.8520342707633972: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9133381843566895: 100%|██████████| 36/36 [00:13<00:00,  2.57it/s]\n",
      "Training mean loss: 1.8091103070312076: 100%|██████████| 36/36 [00:12<00:00,  2.76it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7554801180958748: 100%|██████████| 16/16 [00:03<00:00,  4.12it/s]\n",
      "Eval mean loss: 1.7554801180958748: 100%|██████████| 16/16 [00:03<00:00,  4.14it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8091103070312076: 100%|██████████| 36/36 [00:16<00:00,  2.22it/s]\n",
      "Training mean loss: 1.6575589776039124: 100%|██████████| 36/36 [00:13<00:00,  2.69it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6118507385253906: 100%|██████████| 16/16 [00:03<00:00,  4.43it/s]\n",
      "Eval mean loss: 1.6118507385253906: 100%|██████████| 16/16 [00:03<00:00,  4.48it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6575589776039124: 100%|██████████| 36/36 [00:17<00:00,  2.12it/s]\n",
      "Training mean loss: 1.491741203599506: 100%|██████████| 36/36 [00:12<00:00,  2.98it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4798230826854706: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n",
      "Eval mean loss: 1.4798230826854706: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.491741203599506: 100%|██████████| 36/36 [00:15<00:00,  2.29it/s]\n",
      "Training mean loss: 1.3669864998923407: 100%|██████████| 36/36 [00:13<00:00,  2.68it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3846385478973389: 100%|██████████| 16/16 [00:03<00:00,  4.39it/s]\n",
      "Eval mean loss: 1.3846385478973389: 100%|██████████| 16/16 [00:03<00:00,  4.37it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3846385478973389: 100%|██████████| 16/16 [00:04<00:00,  3.98it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  8   0   0   2   0  36   5]\n",
      " [  1 209  25   1  16   1   2]\n",
      " [  0   9  29   0   1   0   0]\n",
      " [  3  11  80 104   6   0  11]\n",
      " [  5  61  19   4  83   6  44]\n",
      " [  1   1   0   0   0  50   0]\n",
      " [  6   2   5   2   4  30 117]]\n",
      "{'accuracy': 0.503}\n",
      "{'f1': 0.5036879132605098}\n",
      "{'precision': 0.585312896143346}\n",
      "{'recall': 0.503}\n",
      "\n",
      "Test mean loss: 1.3846385478973389: 100%|██████████| 16/16 [00:04<00:00,  3.85it/s]\n",
      "Training mean loss: 1.3669864998923407: 100%|██████████| 36/36 [00:21<00:00,  1.71it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   277/277: 100%|██████████| 277/277 [00:31<00:00,  8.75it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1152, unlabelled size = 8848, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.13ba/s]\n",
      "100%|██████████| 8816/8816 [00:02<00:00, 3085.01ex/s]\n",
      "100%|██████████| 1184/1184 [00:00<00:00, 2943.69ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1184, unlabelled size = 8816, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.92162663227803: 100%|██████████| 37/37 [00:10<00:00,  3.34it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.904245287179947: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s] \n",
      "Eval mean loss: 1.904245287179947: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.92162663227803: 100%|██████████| 37/37 [00:13<00:00,  2.66it/s]\n",
      "Training mean loss: 1.820349870501338: 100%|██████████| 37/37 [00:12<00:00,  3.03it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.775683306157589: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s] \n",
      "Eval mean loss: 1.775683306157589: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.820349870501338: 100%|██████████| 37/37 [00:15<00:00,  2.37it/s]\n",
      "Training mean loss: 1.672164424045666: 100%|██████████| 37/37 [00:12<00:00,  2.93it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6408690810203552: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "Eval mean loss: 1.6408690810203552: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.672164424045666: 100%|██████████| 37/37 [00:15<00:00,  2.32it/s]\n",
      "Training mean loss: 1.5309130629977665: 100%|██████████| 37/37 [00:12<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5048269852995872: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "Eval mean loss: 1.5048269852995872: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.5309130629977665: 100%|██████████| 37/37 [00:15<00:00,  2.43it/s]\n",
      "Training mean loss: 1.3912398976248663: 100%|██████████| 37/37 [00:11<00:00,  3.17it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.418428786098957: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s] \n",
      "Eval mean loss: 1.418428786098957: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.418428786098957: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s] \n",
      "Metrics, confusion matrix\n",
      "[[  3   1   0   1   1  37   8]\n",
      " [  1  69 159   2  21   1   2]\n",
      " [  0   1  38   0   0   0   0]\n",
      " [  0   4  45 135  21   1   9]\n",
      " [  3  26  25   7 136   5  20]\n",
      " [  1   0   1   0   0  50   0]\n",
      " [ 10   0   2   9  20  36  89]]\n",
      "{'accuracy': 0.4665}\n",
      "{'f1': 0.4851892445880361}\n",
      "{'precision': 0.5965217990291335}\n",
      "{'recall': 0.4665}\n",
      "\n",
      "Test mean loss: 1.418428786098957: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "Training mean loss: 1.3912398976248663: 100%|██████████| 37/37 [00:17<00:00,  2.06it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   276/276: 100%|██████████| 276/276 [00:27<00:00, 10.06it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1184, unlabelled size = 8816, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.16ba/s]\n",
      "100%|██████████| 8784/8784 [00:02<00:00, 3140.87ex/s]\n",
      "100%|██████████| 1216/1216 [00:00<00:00, 3075.52ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1216, unlabelled size = 8784, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9278350786158913: 100%|██████████| 38/38 [00:11<00:00,  3.34it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.867920957505703: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s] \n",
      "Eval mean loss: 1.867920957505703: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9278350786158913: 100%|██████████| 38/38 [00:14<00:00,  2.68it/s]\n",
      "Training mean loss: 1.8286557354425128: 100%|██████████| 38/38 [00:12<00:00,  3.14it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7474044188857079: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Eval mean loss: 1.7474044188857079: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8286557354425128: 100%|██████████| 38/38 [00:15<00:00,  2.51it/s]\n",
      "Training mean loss: 1.7042201161384583: 100%|██████████| 38/38 [00:12<00:00,  3.17it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6348832547664642: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Eval mean loss: 1.6348832547664642: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7042201161384583: 100%|██████████| 38/38 [00:15<00:00,  2.51it/s]\n",
      "Training mean loss: 1.5546056408631175: 100%|██████████| 38/38 [00:14<00:00,  2.78it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.488059476017952: 100%|██████████| 16/16 [00:03<00:00,  5.35it/s] \n",
      "Eval mean loss: 1.488059476017952: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.5546056408631175: 100%|██████████| 38/38 [00:17<00:00,  2.22it/s]\n",
      "Training mean loss: 1.4197463455953097: 100%|██████████| 38/38 [00:12<00:00,  2.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3853628784418106: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "Eval mean loss: 1.3853628784418106: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3853628784418106: 100%|██████████| 16/16 [00:03<00:00,  4.85it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 33   0   1   1   1   7   8]\n",
      " [  1 212  19   4  13   1   5]\n",
      " [  0  22  12   4   0   0   1]\n",
      " [  1   7  20 163  12   0  12]\n",
      " [  4  37  11  11 104   4  51]\n",
      " [  7   1   0   0   0  40   4]\n",
      " [ 13   2   1   3   5  14 128]]\n",
      "{'accuracy': 0.5758333333333333}\n",
      "{'f1': 0.5737864673256978}\n",
      "{'precision': 0.6454090411101512}\n",
      "{'recall': 0.5758333333333333}\n",
      "\n",
      "Test mean loss: 1.3853628784418106: 100%|██████████| 16/16 [00:03<00:00,  4.72it/s]\n",
      "Training mean loss: 1.4197463455953097: 100%|██████████| 38/38 [00:19<00:00,  1.96it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   275/275: 100%|██████████| 275/275 [00:28<00:00,  9.81it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1216, unlabelled size = 8784, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.23ba/s]\n",
      "100%|██████████| 8752/8752 [00:02<00:00, 3113.11ex/s]\n",
      "100%|██████████| 1248/1248 [00:00<00:00, 2845.28ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1248, unlabelled size = 8752, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9050076405207317: 100%|██████████| 39/39 [00:11<00:00,  3.40it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.881641186773777: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s] \n",
      "Eval mean loss: 1.881641186773777: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9050076405207317: 100%|██████████| 39/39 [00:14<00:00,  2.76it/s]\n",
      "Training mean loss: 1.7829940227361827: 100%|██████████| 39/39 [00:11<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7258931249380112: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "Eval mean loss: 1.7258931249380112: 100%|██████████| 16/16 [00:02<00:00,  5.49it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7829940227361827: 100%|██████████| 39/39 [00:14<00:00,  2.63it/s]\n",
      "Training mean loss: 1.6393893498640795: 100%|██████████| 39/39 [00:11<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5818313658237457: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.5818313658237457: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6393893498640795: 100%|██████████| 39/39 [00:14<00:00,  2.62it/s]\n",
      "Training mean loss: 1.491730463810456: 100%|██████████| 39/39 [00:11<00:00,  3.31it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4796376377344131: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s]\n",
      "Eval mean loss: 1.4796376377344131: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.491730463810456: 100%|██████████| 39/39 [00:14<00:00,  2.63it/s]\n",
      "Training mean loss: 1.3633227287194667: 100%|██████████| 39/39 [00:11<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3696468323469162: 100%|██████████| 16/16 [00:02<00:00,  5.60it/s]\n",
      "Eval mean loss: 1.3696468323469162: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3696468323469162: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  1   0   0   2   0  25  23]\n",
      " [  0 178  33   2  38   1   3]\n",
      " [  0  14  24   0   1   0   0]\n",
      " [  0  17  29 130  16   0  23]\n",
      " [  0  38   7   4 119   8  46]\n",
      " [  0   0   0   0   1  49   2]\n",
      " [  2   1   2   2   6  20 133]]\n",
      "{'accuracy': 0.5236666666666666}\n",
      "{'f1': 0.5246794755047184}\n",
      "{'precision': 0.5891191316092579}\n",
      "{'recall': 0.5236666666666666}\n",
      "\n",
      "Test mean loss: 1.3696468323469162: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "Training mean loss: 1.3633227287194667: 100%|██████████| 39/39 [00:17<00:00,  2.21it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   274/274: 100%|██████████| 274/274 [00:26<00:00, 10.33it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1248, unlabelled size = 8752, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.61ba/s]\n",
      "100%|██████████| 8720/8720 [00:02<00:00, 3016.25ex/s]\n",
      "100%|██████████| 1280/1280 [00:00<00:00, 3229.34ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1280, unlabelled size = 8720, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9018277436494828: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.903024509549141: 100%|██████████| 16/16 [00:02<00:00,  5.57it/s] \n",
      "Eval mean loss: 1.903024509549141: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9018277436494828: 100%|██████████| 40/40 [00:14<00:00,  2.82it/s]\n",
      "Training mean loss: 1.8012755274772645: 100%|██████████| 40/40 [00:12<00:00,  3.34it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.759307086467743: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s] \n",
      "Eval mean loss: 1.759307086467743: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8012755274772645: 100%|██████████| 40/40 [00:14<00:00,  2.68it/s]\n",
      "Training mean loss: 1.6547959953546525: 100%|██████████| 40/40 [00:12<00:00,  3.34it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.642876259982586: 100%|██████████| 16/16 [00:02<00:00,  5.56it/s] \n",
      "Eval mean loss: 1.642876259982586: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6547959953546525: 100%|██████████| 40/40 [00:14<00:00,  2.68it/s]\n",
      "Training mean loss: 1.5130388945341111: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5074664577841759: 100%|██████████| 16/16 [00:02<00:00,  5.51it/s]\n",
      "Eval mean loss: 1.5074664577841759: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.5130388945341111: 100%|██████████| 40/40 [00:15<00:00,  2.66it/s]\n",
      "Training mean loss: 1.3677119821310044: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3938197940587997: 100%|██████████| 16/16 [00:02<00:00,  5.56it/s]\n",
      "Eval mean loss: 1.3938197940587997: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3938197940587997: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 29   0   0   1   0  15   6]\n",
      " [  0 165  42   6  35   3   4]\n",
      " [  0   3  35   0   1   0   0]\n",
      " [  1  14  24 147  12   2  15]\n",
      " [ 15  27  10   7 111   7  45]\n",
      " [ 11   0   0   0   1  40   0]\n",
      " [ 26   1   1   1   7  18 112]]\n",
      "{'accuracy': 0.4651666666666667}\n",
      "{'f1': 0.5048453040857723}\n",
      "{'precision': 0.6422135607409422}\n",
      "{'recall': 0.4651666666666667}\n",
      "\n",
      "Test mean loss: 1.3938197940587997: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "Training mean loss: 1.3677119821310044: 100%|██████████| 40/40 [00:18<00:00,  2.22it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   273/273: 100%|██████████| 273/273 [00:26<00:00, 10.33it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1280, unlabelled size = 8720, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.55ba/s]\n",
      "100%|██████████| 8688/8688 [00:02<00:00, 3226.73ex/s]\n",
      "100%|██████████| 1312/1312 [00:00<00:00, 3255.90ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1312, unlabelled size = 8688, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9183831592885459: 100%|██████████| 41/41 [00:11<00:00,  3.51it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8709742724895477: 100%|██████████| 16/16 [00:02<00:00,  5.59it/s]\n",
      "Eval mean loss: 1.8709742724895477: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9183831592885459: 100%|██████████| 41/41 [00:14<00:00,  2.87it/s]\n",
      "Training mean loss: 1.802161554010903: 100%|██████████| 41/41 [00:12<00:00,  3.39it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7065984606742859: 100%|██████████| 16/16 [00:02<00:00,  5.57it/s]\n",
      "Eval mean loss: 1.7065984606742859: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.802161554010903: 100%|██████████| 41/41 [00:15<00:00,  2.71it/s]\n",
      "Training mean loss: 1.651031543568867: 100%|██████████| 41/41 [00:12<00:00,  3.39it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5937644392251968: 100%|██████████| 16/16 [00:02<00:00,  5.62it/s]\n",
      "Eval mean loss: 1.5937644392251968: 100%|██████████| 16/16 [00:02<00:00,  5.59it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.651031543568867: 100%|██████████| 41/41 [00:15<00:00,  2.73it/s]\n",
      "Training mean loss: 1.514420474447855: 100%|██████████| 41/41 [00:13<00:00,  3.03it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4637073799967766: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Eval mean loss: 1.4637073799967766: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.514420474447855: 100%|██████████| 41/41 [00:16<00:00,  2.52it/s]\n",
      "Training mean loss: 1.379567085242853: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3710689395666122: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Eval mean loss: 1.3710689395666122: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3710689395666122: 100%|██████████| 16/16 [00:02<00:00,  5.49it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  1   1   0   1   3  37   8]\n",
      " [  0 184  17   3  51   0   0]\n",
      " [  0  15  21   0   3   0   0]\n",
      " [  0  27  12 148  21   2   5]\n",
      " [  0  20   7   5 177   4   9]\n",
      " [  0   1   0   0   1  50   0]\n",
      " [  0   1   1   6  30  37  91]]\n",
      "{'accuracy': 0.5438333333333333}\n",
      "{'f1': 0.5402595600965602}\n",
      "{'precision': 0.6698187130363684}\n",
      "{'recall': 0.5438333333333333}\n",
      "\n",
      "Test mean loss: 1.3710689395666122: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Training mean loss: 1.379567085242853: 100%|██████████| 41/41 [00:18<00:00,  2.22it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   272/272: 100%|██████████| 272/272 [00:26<00:00, 10.27it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1312, unlabelled size = 8688, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.48ba/s]\n",
      "100%|██████████| 8656/8656 [00:02<00:00, 3227.82ex/s]\n",
      "100%|██████████| 1344/1344 [00:00<00:00, 3290.99ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1344, unlabelled size = 8656, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9265788311050052: 100%|██████████| 42/42 [00:11<00:00,  3.52it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.9078754112124443: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Eval mean loss: 1.9078754112124443: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9265788311050052: 100%|██████████| 42/42 [00:14<00:00,  2.89it/s]\n",
      "Training mean loss: 1.8334808746973674: 100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7876886427402496: 100%|██████████| 16/16 [00:02<00:00,  5.63it/s]\n",
      "Eval mean loss: 1.7876886427402496: 100%|██████████| 16/16 [00:02<00:00,  5.57it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8334808746973674: 100%|██████████| 42/42 [00:15<00:00,  2.76it/s]\n",
      "Training mean loss: 1.7105418159848167: 100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6538791358470917: 100%|██████████| 16/16 [00:02<00:00,  5.72it/s]\n",
      "Eval mean loss: 1.6538791358470917: 100%|██████████| 16/16 [00:02<00:00,  5.68it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.7105418159848167: 100%|██████████| 42/42 [00:15<00:00,  2.77it/s]\n",
      "Training mean loss: 1.5682351276988076: 100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5337461233139038: 100%|██████████| 16/16 [00:02<00:00,  5.68it/s]\n",
      "Eval mean loss: 1.5337461233139038: 100%|██████████| 16/16 [00:02<00:00,  5.68it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.5682351276988076: 100%|██████████| 42/42 [00:15<00:00,  2.78it/s]\n",
      "Training mean loss: 1.3950535967236473: 100%|██████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3828145787119865: 100%|██████████| 16/16 [00:02<00:00,  5.81it/s]\n",
      "Eval mean loss: 1.3828145787119865: 100%|██████████| 16/16 [00:02<00:00,  5.75it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3828145787119865: 100%|██████████| 16/16 [00:02<00:00,  5.78it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 29   1   0   1   0  13   7]\n",
      " [  5 228  11   5   3   0   3]\n",
      " [  0  22  15   2   0   0   0]\n",
      " [  2  13  13 164  11   0  12]\n",
      " [  6  44  12  10 123   5  22]\n",
      " [  6   1   0   0   0  45   0]\n",
      " [ 38   2   0   9  15  18  84]]\n",
      "{'accuracy': 0.552}\n",
      "{'f1': 0.5653693331237907}\n",
      "{'precision': 0.6328241438082755}\n",
      "{'recall': 0.552}\n",
      "\n",
      "Test mean loss: 1.3828145787119865: 100%|██████████| 16/16 [00:02<00:00,  5.61it/s]\n",
      "Training mean loss: 1.3950535967236473: 100%|██████████| 42/42 [00:17<00:00,  2.36it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   271/271: 100%|██████████| 271/271 [00:25<00:00, 10.80it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1344, unlabelled size = 8656, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.90ba/s]\n",
      "100%|██████████| 8624/8624 [00:02<00:00, 3397.81ex/s]\n",
      "100%|██████████| 1376/1376 [00:00<00:00, 3269.71ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1376, unlabelled size = 8624, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9166295472965684: 100%|██████████| 43/43 [00:11<00:00,  3.62it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.826769433915615: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s] \n",
      "Eval mean loss: 1.826769433915615: 100%|██████████| 16/16 [00:02<00:00,  5.86it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9166295472965684: 100%|██████████| 43/43 [00:14<00:00,  3.00it/s]\n",
      "Training mean loss: 1.8059569985367532: 100%|██████████| 43/43 [00:12<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7004890367388725: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 1.7004890367388725: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.8059569985367532: 100%|██████████| 43/43 [00:15<00:00,  2.75it/s]\n",
      "Training mean loss: 1.6610705353492914: 100%|██████████| 43/43 [00:12<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5797145813703537: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "Eval mean loss: 1.5797145813703537: 100%|██████████| 16/16 [00:02<00:00,  5.86it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6610705353492914: 100%|██████████| 43/43 [00:14<00:00,  2.88it/s]\n",
      "Training mean loss: 1.5266118132790854: 100%|██████████| 43/43 [00:12<00:00,  3.53it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.461346097290516: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s] \n",
      "Eval mean loss: 1.461346097290516: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.5266118132790854: 100%|██████████| 43/43 [00:14<00:00,  2.87it/s]\n",
      "Training mean loss: 1.389463408048763: 100%|██████████| 43/43 [00:12<00:00,  3.53it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3428453505039215: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "Eval mean loss: 1.3428453505039215: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3428453505039215: 100%|██████████| 16/16 [00:02<00:00,  5.94it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   2   0  41   8]\n",
      " [  0 230  13   5   4   2   1]\n",
      " [  0  22  14   2   1   0   0]\n",
      " [  0   7  25 165   7   1  10]\n",
      " [  0  67  11  17  91  10  26]\n",
      " [  0   1   0   0   0  51   0]\n",
      " [  0   5   0  10   6  53  92]]\n",
      "{'accuracy': 0.5801666666666667}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.589164950273786}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.6179881078601499}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.6113452757288373}\n",
      "\n",
      "Test mean loss: 1.3428453505039215: 100%|██████████| 16/16 [00:02<00:00,  5.79it/s]\n",
      "Training mean loss: 1.389463408048763: 100%|██████████| 43/43 [00:17<00:00,  2.43it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   270/270: 100%|██████████| 270/270 [00:24<00:00, 11.24it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1376, unlabelled size = 8624, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.04ba/s]\n",
      "100%|██████████| 8592/8592 [00:02<00:00, 3235.56ex/s]\n",
      "100%|██████████| 1408/1408 [00:00<00:00, 3435.37ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1408, unlabelled size = 8592, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9085309532555668: 100%|██████████| 44/44 [00:11<00:00,  3.72it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8383569419384003: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s]\n",
      "Eval mean loss: 1.8383569419384003: 100%|██████████| 16/16 [00:02<00:00,  5.94it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9085309532555668: 100%|██████████| 44/44 [00:14<00:00,  3.09it/s]\n",
      "Training mean loss: 1.7617259242317893: 100%|██████████| 44/44 [00:12<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6957696676254272: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Eval mean loss: 1.6957696676254272: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7617259242317893: 100%|██████████| 44/44 [00:15<00:00,  2.92it/s]\n",
      "Training mean loss: 1.6089009940624237: 100%|██████████| 44/44 [00:12<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5619560107588768: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Eval mean loss: 1.5619560107588768: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6089009940624237: 100%|██████████| 44/44 [00:15<00:00,  2.92it/s]\n",
      "Training mean loss: 1.4701363904909655: 100%|██████████| 44/44 [00:12<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4518420025706291: 100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n",
      "Eval mean loss: 1.4518420025706291: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4701363904909655: 100%|██████████| 44/44 [00:15<00:00,  2.92it/s]\n",
      "Training mean loss: 1.3513234474442222: 100%|██████████| 44/44 [00:12<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3538768887519836: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Eval mean loss: 1.3538768887519836: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3538768887519836: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   2   1  36  12]\n",
      " [  0 156  77   4  17   0   1]\n",
      " [  0   5  33   0   1   0   0]\n",
      " [  0  29  21 135  20   0  10]\n",
      " [  0  53  12   6 115   3  33]\n",
      " [  0   0   1   0   0  50   1]\n",
      " [  0   0   2   6  17  44  97]]\n",
      "{'accuracy': 0.49366666666666664}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'f1': 0.5212450265695338}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'precision': 0.5710334393124086}\n",
      "There is label not found in predictions: {'alt'}\n",
      "Printing metric without this label\n",
      "{'recall': 0.52019669827889}\n",
      "\n",
      "Test mean loss: 1.3538768887519836: 100%|██████████| 16/16 [00:02<00:00,  5.79it/s]\n",
      "Training mean loss: 1.3513234474442222: 100%|██████████| 44/44 [00:17<00:00,  2.47it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   269/269: 100%|██████████| 269/269 [00:24<00:00, 11.13it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1408, unlabelled size = 8592, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.88ba/s]\n",
      "100%|██████████| 8560/8560 [00:02<00:00, 3391.12ex/s]\n",
      "100%|██████████| 1440/1440 [00:00<00:00, 3466.86ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1440, unlabelled size = 8560, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.880365326669481: 100%|██████████| 45/45 [00:12<00:00,  3.64it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8726669177412987: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "Eval mean loss: 1.8726669177412987: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.880365326669481: 100%|██████████| 45/45 [00:14<00:00,  3.05it/s]\n",
      "Training mean loss: 1.7504318131340875: 100%|██████████| 45/45 [00:12<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.73284462839365: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]  \n",
      "Eval mean loss: 1.73284462839365: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7504318131340875: 100%|██████████| 45/45 [00:15<00:00,  2.91it/s]\n",
      "Training mean loss: 1.5889264424641927: 100%|██████████| 45/45 [00:12<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5733431726694107: 100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
      "Eval mean loss: 1.5733431726694107: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5889264424641927: 100%|██████████| 45/45 [00:15<00:00,  2.91it/s]\n",
      "Training mean loss: 1.4415417909622192: 100%|██████████| 45/45 [00:12<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4278575330972672: 100%|██████████| 16/16 [00:02<00:00,  5.94it/s]\n",
      "Eval mean loss: 1.4278575330972672: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4415417909622192: 100%|██████████| 45/45 [00:15<00:00,  2.91it/s]\n",
      "Training mean loss: 1.2726289802127415: 100%|██████████| 45/45 [00:12<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2984522134065628: 100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n",
      "Eval mean loss: 1.2984522134065628: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2984522134065628: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  6   0   0   2   0  23  20]\n",
      " [  0 160  68   3  15   2   7]\n",
      " [  0   1  37   0   1   0   0]\n",
      " [  0  11  22 156  11   0  15]\n",
      " [  2  27  24   8 114   2  45]\n",
      " [  3   0   1   0   0  47   1]\n",
      " [  3   0   3   1   4  21 134]]\n",
      "{'accuracy': 0.51}\n",
      "{'f1': 0.534621496303487}\n",
      "{'precision': 0.6776586263756856}\n",
      "{'recall': 0.51}\n",
      "\n",
      "Test mean loss: 1.2984522134065628: 100%|██████████| 16/16 [00:02<00:00,  5.76it/s]\n",
      "Training mean loss: 1.2726289802127415: 100%|██████████| 45/45 [00:18<00:00,  2.47it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   268/268: 100%|██████████| 268/268 [00:23<00:00, 11.18it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1440, unlabelled size = 8560, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.97ba/s]\n",
      "100%|██████████| 8528/8528 [00:02<00:00, 3425.34ex/s]\n",
      "100%|██████████| 1472/1472 [00:00<00:00, 3409.08ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1472, unlabelled size = 8528, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8993429178776948: 100%|██████████| 46/46 [00:12<00:00,  3.65it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8242539167404175: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "Eval mean loss: 1.8242539167404175: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8993429178776948: 100%|██████████| 46/46 [00:14<00:00,  3.08it/s]\n",
      "Training mean loss: 1.765443488307621: 100%|██████████| 46/46 [00:12<00:00,  3.56it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7200799211859703: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "Eval mean loss: 1.7200799211859703: 100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.765443488307621: 100%|██████████| 46/46 [00:15<00:00,  2.94it/s]\n",
      "Training mean loss: 1.6141714168631511: 100%|██████████| 46/46 [00:12<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5659079104661942: 100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
      "Eval mean loss: 1.5659079104661942: 100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6141714168631511: 100%|██████████| 46/46 [00:15<00:00,  2.93it/s]\n",
      "Training mean loss: 1.4370925504228342: 100%|██████████| 46/46 [00:12<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4004529044032097: 100%|██████████| 16/16 [00:02<00:00,  6.04it/s]\n",
      "Eval mean loss: 1.4004529044032097: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4370925504228342: 100%|██████████| 46/46 [00:15<00:00,  2.94it/s]\n",
      "Training mean loss: 1.2854277180588765: 100%|██████████| 46/46 [00:12<00:00,  3.56it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2517120242118835: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "Eval mean loss: 1.2517120242118835: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2517120242118835: 100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 27   0   0   3   1  11   9]\n",
      " [  1 170  51   4  23   1   5]\n",
      " [  0   6  32   0   1   0   0]\n",
      " [  0   5  23 159  12   0  16]\n",
      " [  2  36  10   5 129   2  38]\n",
      " [  6   1   0   0   0  42   3]\n",
      " [ 10   1   2   2   9  17 125]]\n",
      "{'accuracy': 0.5328333333333334}\n",
      "{'f1': 0.5615688681101259}\n",
      "{'precision': 0.661755335987813}\n",
      "{'recall': 0.5328333333333334}\n",
      "\n",
      "Test mean loss: 1.2517120242118835: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]\n",
      "Training mean loss: 1.2854277180588765: 100%|██████████| 46/46 [00:18<00:00,  2.50it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   267/267: 100%|██████████| 267/267 [00:23<00:00, 11.17it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1472, unlabelled size = 8528, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.09ba/s]\n",
      "100%|██████████| 8496/8496 [00:02<00:00, 3413.73ex/s]\n",
      "100%|██████████| 1504/1504 [00:00<00:00, 3425.52ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1504, unlabelled size = 8496, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8960535678457706: 100%|██████████| 47/47 [00:12<00:00,  3.68it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8423478156328201: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s]\n",
      "Eval mean loss: 1.8423478156328201: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8960535678457706: 100%|██████████| 47/47 [00:15<00:00,  3.12it/s]\n",
      "Training mean loss: 1.7702551471426131: 100%|██████████| 47/47 [00:13<00:00,  3.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7106670215725899: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Eval mean loss: 1.7106670215725899: 100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7702551471426131: 100%|██████████| 47/47 [00:15<00:00,  2.95it/s]\n",
      "Training mean loss: 1.6131260648686836: 100%|██████████| 47/47 [00:13<00:00,  3.57it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.571481078863144: 100%|██████████| 16/16 [00:02<00:00,  6.06it/s] \n",
      "Eval mean loss: 1.571481078863144: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6131260648686836: 100%|██████████| 47/47 [00:15<00:00,  2.96it/s]\n",
      "Training mean loss: 1.4334463844908045: 100%|██████████| 47/47 [00:13<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4155172780156136: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.4155172780156136: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4334463844908045: 100%|██████████| 47/47 [00:15<00:00,  2.97it/s]\n",
      "Training mean loss: 1.2781558290440986: 100%|██████████| 47/47 [00:13<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.260674573481083: 100%|██████████| 16/16 [00:02<00:00,  6.09it/s] \n",
      "Eval mean loss: 1.260674573481083: 100%|██████████| 16/16 [00:02<00:00,  6.06it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.260674573481083: 100%|██████████| 16/16 [00:02<00:00,  6.09it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 28   0   0   3   1  11   8]\n",
      " [  2 139  67  18  26   1   2]\n",
      " [  0   4  32   2   1   0   0]\n",
      " [  1   6   6 178  14   0  10]\n",
      " [  8  16  12  19 149   1  17]\n",
      " [  8   0   1   0   0  42   1]\n",
      " [ 18   1   2   8  10  19 108]]\n",
      "{'accuracy': 0.5411666666666667}\n",
      "{'f1': 0.5379651862465056}\n",
      "{'precision': 0.6467103789996599}\n",
      "{'recall': 0.5411666666666667}\n",
      "\n",
      "Test mean loss: 1.260674573481083: 100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n",
      "Training mean loss: 1.2781558290440986: 100%|██████████| 47/47 [00:18<00:00,  2.54it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   266/266: 100%|██████████| 266/266 [00:23<00:00, 11.36it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1504, unlabelled size = 8496, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.20ba/s]\n",
      "100%|██████████| 8464/8464 [00:02<00:00, 3235.53ex/s]\n",
      "100%|██████████| 1536/1536 [00:00<00:00, 3434.21ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1536, unlabelled size = 8464, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8940538465976715: 100%|██████████| 48/48 [00:12<00:00,  3.69it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8478355705738068: 100%|██████████| 16/16 [00:02<00:00,  6.10it/s]\n",
      "Eval mean loss: 1.8478355705738068: 100%|██████████| 16/16 [00:02<00:00,  6.07it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8940538465976715: 100%|██████████| 48/48 [00:15<00:00,  3.15it/s]\n",
      "Training mean loss: 1.7489435200889905: 100%|██████████| 48/48 [00:13<00:00,  3.57it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6986618041992188: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n",
      "Eval mean loss: 1.6986618041992188: 100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7489435200889905: 100%|██████████| 48/48 [00:16<00:00,  2.97it/s]\n",
      "Training mean loss: 1.5907014931241672: 100%|██████████| 48/48 [00:13<00:00,  3.57it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.537741795182228: 100%|██████████| 16/16 [00:02<00:00,  6.04it/s] \n",
      "Eval mean loss: 1.537741795182228: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5907014931241672: 100%|██████████| 48/48 [00:16<00:00,  2.98it/s]\n",
      "Training mean loss: 1.4268639062841733: 100%|██████████| 48/48 [00:13<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3982011154294014: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Eval mean loss: 1.3982011154294014: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4268639062841733: 100%|██████████| 48/48 [00:16<00:00,  2.96it/s]\n",
      "Training mean loss: 1.2828540330131848: 100%|██████████| 48/48 [00:13<00:00,  3.56it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2789366841316223: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Eval mean loss: 1.2789366841316223: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2789366841316223: 100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 27   0   0   3   1  12   8]\n",
      " [  0 164  69  12   8   0   2]\n",
      " [  0  10  29   0   0   0   0]\n",
      " [  0   4  23 176   4   0   8]\n",
      " [  6  32  24  19 104   1  36]\n",
      " [  5   1   0   0   0  46   0]\n",
      " [ 18   2   0  11   8  20 107]]\n",
      "{'accuracy': 0.5108333333333334}\n",
      "{'f1': 0.5417142402764584}\n",
      "{'precision': 0.6590799827936593}\n",
      "{'recall': 0.5108333333333334}\n",
      "\n",
      "Test mean loss: 1.2789366841316223: 100%|██████████| 16/16 [00:02<00:00,  5.79it/s]\n",
      "Training mean loss: 1.2828540330131848: 100%|██████████| 48/48 [00:18<00:00,  2.53it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   265/265: 100%|██████████| 265/265 [00:23<00:00, 11.28it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1536, unlabelled size = 8464, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.10ba/s]\n",
      "100%|██████████| 8432/8432 [00:02<00:00, 3384.20ex/s]\n",
      "100%|██████████| 1568/1568 [00:00<00:00, 3470.28ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1568, unlabelled size = 8432, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.925371637149733: 100%|██████████| 49/49 [00:13<00:00,  3.64it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8593071475625038: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.8593071475625038: 100%|██████████| 16/16 [00:02<00:00,  6.02it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.925371637149733: 100%|██████████| 49/49 [00:15<00:00,  3.12it/s]\n",
      "Training mean loss: 1.7915527698945026: 100%|██████████| 49/49 [00:13<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7562273368239403: 100%|██████████| 16/16 [00:02<00:00,  6.07it/s]\n",
      "Eval mean loss: 1.7562273368239403: 100%|██████████| 16/16 [00:02<00:00,  6.02it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7915527698945026: 100%|██████████| 49/49 [00:16<00:00,  2.99it/s]\n",
      "Training mean loss: 1.6499535210278569: 100%|██████████| 49/49 [00:13<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6067981496453285: 100%|██████████| 16/16 [00:02<00:00,  6.10it/s]\n",
      "Eval mean loss: 1.6067981496453285: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.6499535210278569: 100%|██████████| 49/49 [00:16<00:00,  2.98it/s]\n",
      "Training mean loss: 1.4855872003399595: 100%|██████████| 49/49 [00:13<00:00,  3.59it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4277888536453247: 100%|██████████| 16/16 [00:02<00:00,  6.13it/s]\n",
      "Eval mean loss: 1.4277888536453247: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4855872003399595: 100%|██████████| 49/49 [00:16<00:00,  3.00it/s]\n",
      "Training mean loss: 1.338766521337081: 100%|██████████| 49/49 [00:13<00:00,  3.57it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3138976320624352: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "Eval mean loss: 1.3138976320624352: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3138976320624352: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 33   0   0   1   0  13   4]\n",
      " [  4 214  19   1   8   0   9]\n",
      " [  0  21  17   0   1   0   0]\n",
      " [  2   2  32 166   4   0   9]\n",
      " [  7  50  30   7  55   2  71]\n",
      " [  6   1   0   0   0  45   0]\n",
      " [ 18   2   3   0   0  20 123]]\n",
      "{'accuracy': 0.5435}\n",
      "{'f1': 0.5415297990761049}\n",
      "{'precision': 0.5888919111168754}\n",
      "{'recall': 0.5435}\n",
      "\n",
      "Test mean loss: 1.3138976320624352: 100%|██████████| 16/16 [00:02<00:00,  5.87it/s]\n",
      "Training mean loss: 1.338766521337081: 100%|██████████| 49/49 [00:19<00:00,  2.56it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   264/264: 100%|██████████| 264/264 [00:23<00:00, 11.40it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1568, unlabelled size = 8432, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.34ba/s]\n",
      "100%|██████████| 8400/8400 [00:02<00:00, 3410.33ex/s]\n",
      "100%|██████████| 1600/1600 [00:00<00:00, 3435.65ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1600, unlabelled size = 8400, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.873131754398346: 100%|██████████| 50/50 [00:13<00:00,  3.70it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.815676011145115: 100%|██████████| 16/16 [00:02<00:00,  6.12it/s] \n",
      "Eval mean loss: 1.815676011145115: 100%|██████████| 16/16 [00:02<00:00,  6.04it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.873131754398346: 100%|██████████| 50/50 [00:15<00:00,  3.15it/s]\n",
      "Training mean loss: 1.7079169464111328: 100%|██████████| 50/50 [00:13<00:00,  3.59it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6794340834021568: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.6794340834021568: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7079169464111328: 100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "Training mean loss: 1.5498944449424743: 100%|██████████| 50/50 [00:14<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4972618073225021: 100%|██████████| 16/16 [00:02<00:00,  6.07it/s]\n",
      "Eval mean loss: 1.4972618073225021: 100%|██████████| 16/16 [00:02<00:00,  6.04it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5498944449424743: 100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "Training mean loss: 1.3958181166648864: 100%|██████████| 50/50 [00:14<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3684111014008522: 100%|██████████| 16/16 [00:02<00:00,  6.09it/s]\n",
      "Eval mean loss: 1.3684111014008522: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3958181166648864: 100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "Training mean loss: 1.2500698947906494: 100%|██████████| 50/50 [00:13<00:00,  3.60it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2481244504451752: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.2481244504451752: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2481244504451752: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  0   0   0   2   0  36  13]\n",
      " [  0 194  21   4  30   0   6]\n",
      " [  0  11  27   0   1   0   0]\n",
      " [  0   4  16 155  17   0  23]\n",
      " [  1  30   7   7 125   3  49]\n",
      " [  1   1   0   0   0  49   1]\n",
      " [  3   2   0   3   4  29 125]]\n",
      "{'accuracy': 0.5318333333333334}\n",
      "{'f1': 0.5358655367651883}\n",
      "{'precision': 0.624883009108489}\n",
      "{'recall': 0.5318333333333334}\n",
      "\n",
      "Test mean loss: 1.2481244504451752: 100%|██████████| 16/16 [00:02<00:00,  5.75it/s]\n",
      "Training mean loss: 1.2500698947906494: 100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   263/263: 100%|██████████| 263/263 [00:23<00:00, 11.37it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1600, unlabelled size = 8400, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.21ba/s]\n",
      "100%|██████████| 8368/8368 [00:02<00:00, 3395.64ex/s]\n",
      "100%|██████████| 1632/1632 [00:00<00:00, 3404.65ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1632, unlabelled size = 8368, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8983858753653133: 100%|██████████| 51/51 [00:13<00:00,  3.66it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7995286881923676: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "Eval mean loss: 1.7995286881923676: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8983858753653133: 100%|██████████| 51/51 [00:16<00:00,  3.13it/s]\n",
      "Training mean loss: 1.7354315472584145: 100%|██████████| 51/51 [00:14<00:00,  3.50it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.631982073187828: 100%|██████████| 16/16 [00:02<00:00,  5.86it/s] \n",
      "Eval mean loss: 1.631982073187828: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7354315472584145: 100%|██████████| 51/51 [00:17<00:00,  2.97it/s]\n",
      "Training mean loss: 1.55239204565684: 100%|██████████| 51/51 [00:14<00:00,  3.55it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.478388600051403: 100%|██████████| 16/16 [00:02<00:00,  6.06it/s] \n",
      "Eval mean loss: 1.478388600051403: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.55239204565684: 100%|██████████| 51/51 [00:16<00:00,  3.01it/s]\n",
      "Training mean loss: 1.4009549150279923: 100%|██████████| 51/51 [00:14<00:00,  3.56it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3624056577682495: 100%|██████████| 16/16 [00:02<00:00,  6.07it/s]\n",
      "Eval mean loss: 1.3624056577682495: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4009549150279923: 100%|██████████| 51/51 [00:16<00:00,  3.01it/s]\n",
      "Training mean loss: 1.250935484381283: 100%|██████████| 51/51 [00:14<00:00,  3.58it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2526497393846512: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "Eval mean loss: 1.2526497393846512: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2526497393846512: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 16   0   0   2   1  27   5]\n",
      " [  0  90 142  17   5   0   1]\n",
      " [  0   5  33   1   0   0   0]\n",
      " [  0   5  16 182   6   0   6]\n",
      " [  3  36  14  25 122   2  20]\n",
      " [  2   1   0   1   0  48   0]\n",
      " [ 10   1   2   7   9  33 104]]\n",
      "{'accuracy': 0.5436666666666666}\n",
      "{'f1': 0.5594028283614276}\n",
      "{'precision': 0.610605408129891}\n",
      "{'recall': 0.5436666666666666}\n",
      "\n",
      "Test mean loss: 1.2526497393846512: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n",
      "Training mean loss: 1.250935484381283: 100%|██████████| 51/51 [00:19<00:00,  2.60it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   262/262: 100%|██████████| 262/262 [00:22<00:00, 11.44it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1632, unlabelled size = 8368, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.17ba/s]\n",
      "100%|██████████| 8336/8336 [00:02<00:00, 3223.87ex/s]\n",
      "100%|██████████| 1664/1664 [00:00<00:00, 3326.97ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1664, unlabelled size = 8336, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9175331042363093: 100%|██████████| 52/52 [00:13<00:00,  3.66it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8959768563508987: 100%|██████████| 16/16 [00:02<00:00,  6.06it/s]\n",
      "Eval mean loss: 1.8959768563508987: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9175331042363093: 100%|██████████| 52/52 [00:16<00:00,  3.16it/s]\n",
      "Training mean loss: 1.77865476333178: 100%|██████████| 52/52 [00:14<00:00,  3.58it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7466548085212708: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "Eval mean loss: 1.7466548085212708: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.77865476333178: 100%|██████████| 52/52 [00:17<00:00,  3.03it/s]\n",
      "Training mean loss: 1.616149026613969: 100%|██████████| 52/52 [00:14<00:00,  3.56it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5943762958049774: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "Eval mean loss: 1.5943762958049774: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.616149026613969: 100%|██████████| 52/52 [00:17<00:00,  3.01it/s]\n",
      "Training mean loss: 1.4577343601446886: 100%|██████████| 52/52 [00:14<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4570706486701965: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.4570706486701965: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.4577343601446886: 100%|██████████| 52/52 [00:17<00:00,  3.02it/s]\n",
      "Training mean loss: 1.285489721940114: 100%|██████████| 52/52 [00:14<00:00,  3.59it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3045570030808449: 100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n",
      "Eval mean loss: 1.3045570030808449: 100%|██████████| 16/16 [00:02<00:00,  5.88it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.3045570030808449: 100%|██████████| 16/16 [00:02<00:00,  6.00it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 25   0   0   3   1  21   1]\n",
      " [  2 173  50   8  22   0   0]\n",
      " [  0   7  31   0   1   0   0]\n",
      " [  2   3  54 144   9   0   3]\n",
      " [  5  26  23   9 150   0   9]\n",
      " [  3   1   0   0   0  48   0]\n",
      " [ 21   2   4  12  12  25  90]]\n",
      "{'accuracy': 0.49333333333333335}\n",
      "{'f1': 0.500853741430182}\n",
      "{'precision': 0.6582964121649578}\n",
      "{'recall': 0.49333333333333335}\n",
      "\n",
      "Test mean loss: 1.3045570030808449: 100%|██████████| 16/16 [00:02<00:00,  5.85it/s]\n",
      "Training mean loss: 1.285489721940114: 100%|██████████| 52/52 [00:20<00:00,  2.60it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   261/261: 100%|██████████| 261/261 [00:22<00:00, 11.39it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1664, unlabelled size = 8336, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.37ba/s]\n",
      "100%|██████████| 8304/8304 [00:02<00:00, 3392.14ex/s]\n",
      "100%|██████████| 1696/1696 [00:00<00:00, 3355.07ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1696, unlabelled size = 8304, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.879479208082523: 100%|██████████| 53/53 [00:14<00:00,  3.67it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8462266474962234: 100%|██████████| 16/16 [00:02<00:00,  6.12it/s]\n",
      "Eval mean loss: 1.8462266474962234: 100%|██████████| 16/16 [00:02<00:00,  6.09it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.879479208082523: 100%|██████████| 53/53 [00:16<00:00,  3.18it/s]\n",
      "Training mean loss: 1.685259076784242: 100%|██████████| 53/53 [00:14<00:00,  3.63it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6506536900997162: 100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n",
      "Eval mean loss: 1.6506536900997162: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.685259076784242: 100%|██████████| 53/53 [00:17<00:00,  3.05it/s]\n",
      "Training mean loss: 1.500184214340066: 100%|██████████| 53/53 [00:14<00:00,  3.60it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.512011133134365: 100%|██████████| 16/16 [00:02<00:00,  5.87it/s] \n",
      "Eval mean loss: 1.512011133134365: 100%|██████████| 16/16 [00:02<00:00,  5.87it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.500184214340066: 100%|██████████| 53/53 [00:17<00:00,  3.03it/s]\n",
      "Training mean loss: 1.3527239021265283: 100%|██████████| 53/53 [00:14<00:00,  3.60it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3808265179395676: 100%|██████████| 16/16 [00:02<00:00,  5.87it/s]\n",
      "Eval mean loss: 1.3808265179395676: 100%|██████████| 16/16 [00:02<00:00,  5.82it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3527239021265283: 100%|██████████| 53/53 [00:17<00:00,  3.04it/s]\n",
      "Training mean loss: 1.2071944587635544: 100%|██████████| 53/53 [00:14<00:00,  3.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.270318627357483: 100%|██████████| 16/16 [00:02<00:00,  6.06it/s] \n",
      "Eval mean loss: 1.270318627357483: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.270318627357483: 100%|██████████| 16/16 [00:02<00:00,  6.13it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 21   0   0   2   1  23   4]\n",
      " [  0 127 105   5  15   2   1]\n",
      " [  0   1  37   0   1   0   0]\n",
      " [  2   8  18 167  11   0   9]\n",
      " [  5  33  21  11 123   5  24]\n",
      " [  2   0   1   0   0  49   0]\n",
      " [ 51   0   2   5  11  25  72]]\n",
      "{'accuracy': 0.46166666666666667}\n",
      "{'f1': 0.4899745488920789}\n",
      "{'precision': 0.6490558933323687}\n",
      "{'recall': 0.46166666666666667}\n",
      "\n",
      "Test mean loss: 1.270318627357483: 100%|██████████| 16/16 [00:02<00:00,  5.94it/s]\n",
      "Training mean loss: 1.2071944587635544: 100%|██████████| 53/53 [00:20<00:00,  2.64it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   260/260: 100%|██████████| 260/260 [00:22<00:00, 11.44it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1696, unlabelled size = 8304, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.25ba/s]\n",
      "100%|██████████| 8272/8272 [00:02<00:00, 3368.06ex/s]\n",
      "100%|██████████| 1728/1728 [00:00<00:00, 3438.65ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1728, unlabelled size = 8272, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8870117664337158: 100%|██████████| 54/54 [00:14<00:00,  3.66it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8194900676608086: 100%|██████████| 16/16 [00:02<00:00,  6.15it/s]\n",
      "Eval mean loss: 1.8194900676608086: 100%|██████████| 16/16 [00:02<00:00,  6.11it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8870117664337158: 100%|██████████| 54/54 [00:16<00:00,  3.19it/s]\n",
      "Training mean loss: 1.7254047967769481: 100%|██████████| 54/54 [00:15<00:00,  3.59it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.596312366425991: 100%|██████████| 16/16 [00:02<00:00,  6.11it/s] \n",
      "Eval mean loss: 1.596312366425991: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7254047967769481: 100%|██████████| 54/54 [00:17<00:00,  3.06it/s]\n",
      "Training mean loss: 1.5323674700878285: 100%|██████████| 54/54 [00:14<00:00,  3.61it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4158579409122467: 100%|██████████| 16/16 [00:02<00:00,  6.18it/s]\n",
      "Eval mean loss: 1.4158579409122467: 100%|██████████| 16/16 [00:02<00:00,  6.10it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5323674700878285: 100%|██████████| 54/54 [00:17<00:00,  3.07it/s]\n",
      "Training mean loss: 1.321323487493727: 100%|██████████| 54/54 [00:16<00:00,  2.79it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.260344110429287: 100%|██████████| 16/16 [00:02<00:00,  5.62it/s] \n",
      "Eval mean loss: 1.260344110429287: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.321323487493727: 100%|██████████| 54/54 [00:19<00:00,  2.75it/s]\n",
      "Training mean loss: 1.1739297575420804: 100%|██████████| 54/54 [00:15<00:00,  3.54it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1546005308628082: 100%|██████████| 16/16 [00:02<00:00,  5.84it/s]\n",
      "Eval mean loss: 1.1546005308628082: 100%|██████████| 16/16 [00:02<00:00,  5.81it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1546005308628082: 100%|██████████| 16/16 [00:02<00:00,  5.66it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 14   0   0   3   0  21  13]\n",
      " [  0 150  17   6  81   0   1]\n",
      " [  0  10  23   0   6   0   0]\n",
      " [  0  10   6 173  14   0  12]\n",
      " [  1  17   6   5 167   1  25]\n",
      " [  0   0   0   0   1  48   3]\n",
      " [  0   0   1   2  14  24 125]]\n",
      "{'accuracy': 0.6158333333333333}\n",
      "{'f1': 0.6103645632405217}\n",
      "{'precision': 0.6701068508278488}\n",
      "{'recall': 0.6158333333333333}\n",
      "\n",
      "Test mean loss: 1.1546005308628082: 100%|██████████| 16/16 [00:02<00:00,  5.57it/s]\n",
      "Training mean loss: 1.1739297575420804: 100%|██████████| 54/54 [00:20<00:00,  2.58it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   259/259: 100%|██████████| 259/259 [00:23<00:00, 11.03it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1728, unlabelled size = 8272, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.24ba/s]\n",
      "100%|██████████| 8240/8240 [00:02<00:00, 3369.14ex/s]\n",
      "100%|██████████| 1760/1760 [00:00<00:00, 3435.53ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1760, unlabelled size = 8240, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8771252458745784: 100%|██████████| 55/55 [00:14<00:00,  3.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.829019233584404: 100%|██████████| 16/16 [00:02<00:00,  5.85it/s] \n",
      "Eval mean loss: 1.829019233584404: 100%|██████████| 16/16 [00:02<00:00,  5.84it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8771252458745784: 100%|██████████| 55/55 [00:17<00:00,  3.16it/s]\n",
      "Training mean loss: 1.717892174287276: 100%|██████████| 55/55 [00:15<00:00,  3.54it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6722902804613113: 100%|██████████| 16/16 [00:02<00:00,  6.03it/s]\n",
      "Eval mean loss: 1.6722902804613113: 100%|██████████| 16/16 [00:02<00:00,  5.99it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.717892174287276: 100%|██████████| 55/55 [00:18<00:00,  3.03it/s]\n",
      "Training mean loss: 1.5393982258709995: 100%|██████████| 55/55 [00:15<00:00,  3.39it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.520753651857376: 100%|██████████| 16/16 [00:02<00:00,  5.62it/s] \n",
      "Eval mean loss: 1.520753651857376: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5393982258709995: 100%|██████████| 55/55 [00:18<00:00,  2.94it/s]\n",
      "Training mean loss: 1.3695450262589888: 100%|██████████| 55/55 [00:16<00:00,  3.46it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3619734942913055: 100%|██████████| 16/16 [00:02<00:00,  5.83it/s]\n",
      "Eval mean loss: 1.3619734942913055: 100%|██████████| 16/16 [00:02<00:00,  5.78it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3695450262589888: 100%|██████████| 55/55 [00:18<00:00,  2.89it/s]\n",
      "Training mean loss: 1.2264638250524347: 100%|██████████| 55/55 [00:15<00:00,  3.46it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2329932153224945: 100%|██████████| 16/16 [00:02<00:00,  5.81it/s]\n",
      "Eval mean loss: 1.2329932153224945: 100%|██████████| 16/16 [00:02<00:00,  5.79it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2329932153224945: 100%|██████████| 16/16 [00:02<00:00,  5.78it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 21   0   0   2   4  22   2]\n",
      " [  0 167  59  12  17   0   0]\n",
      " [  0   6  32   0   1   0   0]\n",
      " [  0   2  37 163   5   0   8]\n",
      " [  3  25  24  15 134   2  19]\n",
      " [  2   1   0   0   0  49   0]\n",
      " [ 12   2   2   6   8  23 113]]\n",
      "{'accuracy': 0.5288333333333334}\n",
      "{'f1': 0.5568585718694937}\n",
      "{'precision': 0.6774763409003175}\n",
      "{'recall': 0.5288333333333334}\n",
      "\n",
      "Test mean loss: 1.2329932153224945: 100%|██████████| 16/16 [00:02<00:00,  5.65it/s]\n",
      "Training mean loss: 1.2264638250524347: 100%|██████████| 55/55 [00:21<00:00,  2.57it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   258/258: 100%|██████████| 258/258 [00:23<00:00, 10.95it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1760, unlabelled size = 8240, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.27ba/s]\n",
      "100%|██████████| 8208/8208 [00:02<00:00, 3017.56ex/s]\n",
      "100%|██████████| 1792/1792 [00:00<00:00, 3395.97ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1792, unlabelled size = 8208, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9235670587846212: 100%|██████████| 56/56 [00:15<00:00,  3.50it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.854847863316536: 100%|██████████| 16/16 [00:02<00:00,  5.64it/s] \n",
      "Eval mean loss: 1.854847863316536: 100%|██████████| 16/16 [00:02<00:00,  5.64it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9235670587846212: 100%|██████████| 56/56 [00:18<00:00,  2.99it/s]\n",
      "Training mean loss: 1.7796858698129654: 100%|██████████| 56/56 [00:17<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6687035411596298: 100%|██████████| 16/16 [00:02<00:00,  5.62it/s]\n",
      "Eval mean loss: 1.6687035411596298: 100%|██████████| 16/16 [00:02<00:00,  5.62it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7796858698129654: 100%|██████████| 56/56 [00:19<00:00,  2.80it/s]\n",
      "Training mean loss: 1.5785055458545685: 100%|██████████| 56/56 [00:17<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4960475414991379: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.4960475414991379: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5785055458545685: 100%|██████████| 56/56 [00:20<00:00,  2.76it/s]\n",
      "Training mean loss: 1.3749309054442815: 100%|██████████| 56/56 [00:16<00:00,  3.33it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3232889845967293: 100%|██████████| 16/16 [00:02<00:00,  5.61it/s]\n",
      "Eval mean loss: 1.3232889845967293: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3749309054442815: 100%|██████████| 56/56 [00:19<00:00,  2.84it/s]\n",
      "Training mean loss: 1.1865481904574804: 100%|██████████| 56/56 [00:16<00:00,  3.43it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1725783348083496: 100%|██████████| 16/16 [00:02<00:00,  5.69it/s]\n",
      "Eval mean loss: 1.1725783348083496: 100%|██████████| 16/16 [00:02<00:00,  5.66it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1725783348083496: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 29   0   0   2   0  12   8]\n",
      " [  0 199  23   4  27   0   2]\n",
      " [  0   8  28   2   1   0   0]\n",
      " [  1   3  13 168  20   0  10]\n",
      " [  7  26   3   7 156   2  21]\n",
      " [  6   1   0   0   0  45   0]\n",
      " [ 15   2   0   4   7  23 115]]\n",
      "{'accuracy': 0.6276666666666667}\n",
      "{'f1': 0.6376052790244902}\n",
      "{'precision': 0.6748761032057552}\n",
      "{'recall': 0.6276666666666667}\n",
      "\n",
      "Test mean loss: 1.1725783348083496: 100%|██████████| 16/16 [00:03<00:00,  4.61it/s]\n",
      "Training mean loss: 1.1865481904574804: 100%|██████████| 56/56 [00:22<00:00,  2.47it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   257/257: 100%|██████████| 257/257 [00:27<00:00,  9.50it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1792, unlabelled size = 8208, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.98ba/s]\n",
      "100%|██████████| 8176/8176 [00:02<00:00, 3201.39ex/s]\n",
      "100%|██████████| 1824/1824 [00:00<00:00, 3279.54ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1824, unlabelled size = 8176, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.868081021727177: 100%|██████████| 57/57 [00:18<00:00,  2.98it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7889713272452354: 100%|██████████| 16/16 [00:03<00:00,  4.99it/s]\n",
      "Eval mean loss: 1.7889713272452354: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.868081021727177: 100%|██████████| 57/57 [00:22<00:00,  2.58it/s]\n",
      "Training mean loss: 1.6703763928329736: 100%|██████████| 57/57 [00:19<00:00,  2.96it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6544612795114517: 100%|██████████| 16/16 [00:03<00:00,  4.55it/s]\n",
      "Eval mean loss: 1.6544612795114517: 100%|██████████| 16/16 [00:03<00:00,  4.51it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6703763928329736: 100%|██████████| 57/57 [00:22<00:00,  2.50it/s]\n",
      "Training mean loss: 1.4949724235032733: 100%|██████████| 57/57 [00:19<00:00,  3.19it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5039449483156204: 100%|██████████| 16/16 [00:03<00:00,  4.72it/s]\n",
      "Eval mean loss: 1.5039449483156204: 100%|██████████| 16/16 [00:03<00:00,  4.69it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4949724235032733: 100%|██████████| 57/57 [00:22<00:00,  2.54it/s]\n",
      "Training mean loss: 1.3331107152135748: 100%|██████████| 57/57 [00:19<00:00,  3.20it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.373433068394661: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s] \n",
      "Eval mean loss: 1.373433068394661: 100%|██████████| 16/16 [00:03<00:00,  4.85it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3331107152135748: 100%|██████████| 57/57 [00:22<00:00,  2.50it/s]\n",
      "Training mean loss: 1.1867170710312693: 100%|██████████| 57/57 [00:18<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2250841781497002: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "Eval mean loss: 1.2250841781497002: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2250841781497002: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 17   0   0   2   2  24   6]\n",
      " [  2 146  74   6  26   0   1]\n",
      " [  0   3  35   0   1   0   0]\n",
      " [  1  20  18 145  23   0   8]\n",
      " [  2  24   7   7 160   1  21]\n",
      " [  1   0   1   0   0  49   1]\n",
      " [ 19   1   1   5  19  23  98]]\n",
      "{'accuracy': 0.46166666666666667}\n",
      "{'f1': 0.482398861206299}\n",
      "{'precision': 0.6307585448073055}\n",
      "{'recall': 0.46166666666666667}\n",
      "\n",
      "Test mean loss: 1.2250841781497002: 100%|██████████| 16/16 [00:03<00:00,  4.56it/s]\n",
      "Training mean loss: 1.1867170710312693: 100%|██████████| 57/57 [00:24<00:00,  2.30it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   256/256: 100%|██████████| 256/256 [00:25<00:00, 10.18it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1824, unlabelled size = 8176, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.13ba/s]\n",
      "100%|██████████| 8144/8144 [00:02<00:00, 3200.14ex/s]\n",
      "100%|██████████| 1856/1856 [00:00<00:00, 3264.22ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1856, unlabelled size = 8144, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8785966120917221: 100%|██████████| 58/58 [00:16<00:00,  3.44it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8102768808603287: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "Eval mean loss: 1.8102768808603287: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8785966120917221: 100%|██████████| 58/58 [00:19<00:00,  2.98it/s]\n",
      "Training mean loss: 1.7152179849558864: 100%|██████████| 58/58 [00:17<00:00,  3.39it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.645602509379387: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s] \n",
      "Eval mean loss: 1.645602509379387: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7152179849558864: 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]\n",
      "Training mean loss: 1.5243177783900295: 100%|██████████| 58/58 [00:19<00:00,  2.65it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4763123914599419: 100%|██████████| 16/16 [00:03<00:00,  4.39it/s]\n",
      "Eval mean loss: 1.4763123914599419: 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.5243177783900295: 100%|██████████| 58/58 [00:23<00:00,  2.45it/s]\n",
      "Training mean loss: 1.36085981952733: 100%|██████████| 58/58 [00:20<00:00,  2.91it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3550924956798553: 100%|██████████| 16/16 [00:03<00:00,  4.75it/s]\n",
      "Eval mean loss: 1.3550924956798553: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.36085981952733: 100%|██████████| 58/58 [00:23<00:00,  2.44it/s]\n",
      "Training mean loss: 1.1996852961079827: 100%|██████████| 58/58 [00:20<00:00,  2.77it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2065369784832: 100%|██████████| 16/16 [00:03<00:00,  4.61it/s]   \n",
      "Eval mean loss: 1.2065369784832: 100%|██████████| 16/16 [00:03<00:00,  4.61it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.2065369784832: 100%|██████████| 16/16 [00:03<00:00,  4.84it/s]   \n",
      "Metrics, confusion matrix\n",
      "[[ 30   0   0   2   0  10   9]\n",
      " [  0  76 143  10  20   2   4]\n",
      " [  0   0  37   1   1   0   0]\n",
      " [  0   2  11 181  11   0  10]\n",
      " [  4  17  29  17 114   2  39]\n",
      " [  7   1   0   0   0  44   0]\n",
      " [ 18   1   2   3   4  18 120]]\n",
      "{'accuracy': 0.5005}\n",
      "{'f1': 0.49277954631882737}\n",
      "{'precision': 0.6486936076544739}\n",
      "{'recall': 0.5005}\n",
      "\n",
      "Test mean loss: 1.2065369784832: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Training mean loss: 1.1996852961079827: 100%|██████████| 58/58 [00:27<00:00,  2.11it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   255/255: 100%|██████████| 255/255 [00:25<00:00, 10.04it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1856, unlabelled size = 8144, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.23ba/s]\n",
      "100%|██████████| 8112/8112 [00:02<00:00, 3174.90ex/s]\n",
      "100%|██████████| 1888/1888 [00:00<00:00, 3241.22ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1888, unlabelled size = 8112, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.876427159471027: 100%|██████████| 59/59 [00:17<00:00,  3.26it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8012342900037766: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Eval mean loss: 1.8012342900037766: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.876427159471027: 100%|██████████| 59/59 [00:20<00:00,  2.83it/s]\n",
      "Training mean loss: 1.692901112265506: 100%|██████████| 59/59 [00:19<00:00,  3.07it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5805975645780563: 100%|██████████| 16/16 [00:03<00:00,  5.20it/s]\n",
      "Eval mean loss: 1.5805975645780563: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.692901112265506: 100%|██████████| 59/59 [00:22<00:00,  2.60it/s]\n",
      "Training mean loss: 1.4980283510887016: 100%|██████████| 59/59 [00:22<00:00,  2.69it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4291020557284355: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "Eval mean loss: 1.4291020557284355: 100%|██████████| 16/16 [00:03<00:00,  4.39it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4980283510887016: 100%|██████████| 59/59 [00:25<00:00,  2.29it/s]\n",
      "Training mean loss: 1.3345516617015256: 100%|██████████| 59/59 [00:19<00:00,  2.93it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2806279808282852: 100%|██████████| 16/16 [00:03<00:00,  4.67it/s]\n",
      "Eval mean loss: 1.2806279808282852: 100%|██████████| 16/16 [00:03<00:00,  4.63it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3345516617015256: 100%|██████████| 59/59 [00:23<00:00,  2.53it/s]\n",
      "Training mean loss: 1.1866672281491555: 100%|██████████| 59/59 [00:18<00:00,  3.24it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1610648334026337: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "Eval mean loss: 1.1610648334026337: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1610648334026337: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "Metrics, confusion matrix\n",
      "[[  1   0   0   2   2  37   9]\n",
      " [  0 170  66   7  12   0   0]\n",
      " [  0   2  35   1   1   0   0]\n",
      " [  0   4  22 176   7   0   6]\n",
      " [  1  28  26  15 137   1  14]\n",
      " [  0   1   0   0   0  51   0]\n",
      " [  1   1   1   6  18  25 114]]\n",
      "{'accuracy': 0.6003333333333334}\n",
      "{'f1': 0.6116535762271504}\n",
      "{'precision': 0.6923858512426823}\n",
      "{'recall': 0.6003333333333334}\n",
      "\n",
      "Test mean loss: 1.1610648334026337: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "Training mean loss: 1.1866672281491555: 100%|██████████| 59/59 [00:24<00:00,  2.39it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   254/254: 100%|██████████| 254/254 [00:26<00:00,  9.69it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1888, unlabelled size = 8112, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  4.68ba/s]\n",
      "100%|██████████| 8080/8080 [00:02<00:00, 2849.81ex/s]\n",
      "100%|██████████| 1920/1920 [00:00<00:00, 3278.69ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1920, unlabelled size = 8080, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9013391514619191: 100%|██████████| 60/60 [00:18<00:00,  3.02it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.833951711654663: 100%|██████████| 16/16 [00:03<00:00,  4.65it/s] \n",
      "Eval mean loss: 1.833951711654663: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9013391514619191: 100%|██████████| 60/60 [00:21<00:00,  2.73it/s]\n",
      "Training mean loss: 1.7488296627998352: 100%|██████████| 60/60 [00:19<00:00,  3.19it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6929139271378517: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "Eval mean loss: 1.6929139271378517: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7488296627998352: 100%|██████████| 60/60 [00:22<00:00,  2.66it/s]\n",
      "Training mean loss: 1.550994336605072: 100%|██████████| 60/60 [00:19<00:00,  3.13it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4947601184248924: 100%|██████████| 16/16 [00:03<00:00,  5.35it/s]\n",
      "Eval mean loss: 1.4947601184248924: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.550994336605072: 100%|██████████| 60/60 [00:22<00:00,  2.73it/s]\n",
      "Training mean loss: 1.3573191086451213: 100%|██████████| 60/60 [00:20<00:00,  2.88it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3676520884037018: 100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n",
      "Eval mean loss: 1.3676520884037018: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.3573191086451213: 100%|██████████| 60/60 [00:23<00:00,  2.54it/s]\n",
      "Training mean loss: 1.1981031437714895: 100%|██████████| 60/60 [00:20<00:00,  3.26it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1920893043279648: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.1920893043279648: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1920893043279648: 100%|██████████| 16/16 [00:02<00:00,  5.58it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 27   0   0   3   1  17   3]\n",
      " [  3 202  38   6   5   0   1]\n",
      " [  0   6  32   0   1   0   0]\n",
      " [  1   3  26 173   5   0   7]\n",
      " [  8  43  20  12 121   4  14]\n",
      " [  3   1   0   0   0  48   0]\n",
      " [ 27   2   0  10   7  21  99]]\n",
      "{'accuracy': 0.5728333333333333}\n",
      "{'f1': 0.5939147487477826}\n",
      "{'precision': 0.6908976932591393}\n",
      "{'recall': 0.5728333333333333}\n",
      "\n",
      "Test mean loss: 1.1920893043279648: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Training mean loss: 1.1981031437714895: 100%|██████████| 60/60 [00:26<00:00,  2.30it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   253/253: 100%|██████████| 253/253 [00:27<00:00,  9.31it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1920, unlabelled size = 8080, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.66ba/s]\n",
      "100%|██████████| 8048/8048 [00:02<00:00, 2727.27ex/s]\n",
      "100%|██████████| 1952/1952 [00:00<00:00, 2801.41ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1952, unlabelled size = 8048, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.899953631104016: 100%|██████████| 61/61 [00:19<00:00,  2.92it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.793937973678112: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s] \n",
      "Eval mean loss: 1.793937973678112: 100%|██████████| 16/16 [00:03<00:00,  4.83it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.899953631104016: 100%|██████████| 61/61 [00:22<00:00,  2.69it/s]\n",
      "Training mean loss: 1.6899896410645032: 100%|██████████| 61/61 [00:20<00:00,  2.96it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5462063252925873: 100%|██████████| 16/16 [00:03<00:00,  4.71it/s]\n",
      "Eval mean loss: 1.5462063252925873: 100%|██████████| 16/16 [00:03<00:00,  4.74it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6899896410645032: 100%|██████████| 61/61 [00:23<00:00,  2.58it/s]\n",
      "Training mean loss: 1.4815153313464806: 100%|██████████| 61/61 [00:19<00:00,  3.05it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3762858510017395: 100%|██████████| 16/16 [00:03<00:00,  4.45it/s]\n",
      "Eval mean loss: 1.3762858510017395: 100%|██████████| 16/16 [00:03<00:00,  4.39it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4815153313464806: 100%|██████████| 61/61 [00:23<00:00,  2.62it/s]\n",
      "Training mean loss: 1.300262423812366: 100%|██████████| 61/61 [00:19<00:00,  3.11it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2543001025915146: 100%|██████████| 16/16 [00:03<00:00,  5.25it/s]\n",
      "Eval mean loss: 1.2543001025915146: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.300262423812366: 100%|██████████| 61/61 [00:22<00:00,  2.71it/s]\n",
      "Training mean loss: 1.122194077147812: 100%|██████████| 61/61 [00:18<00:00,  3.31it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1214165166020393: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Eval mean loss: 1.1214165166020393: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1214165166020393: 100%|██████████| 16/16 [00:04<00:00,  3.99it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 14   0   0   1   1  25  10]\n",
      " [  1 182  53   8  10   0   1]\n",
      " [  0   1  35   1   1   1   0]\n",
      " [  0   4  12 185   8   0   6]\n",
      " [  3  39  18  16 125   1  20]\n",
      " [  0   0   1   0   0  51   0]\n",
      " [  3   1   1   6  12  27 116]]\n",
      "{'accuracy': 0.6421666666666667}\n",
      "{'f1': 0.647063699462201}\n",
      "{'precision': 0.6881202544129053}\n",
      "{'recall': 0.6421666666666667}\n",
      "\n",
      "Test mean loss: 1.1214165166020393: 100%|██████████| 16/16 [00:04<00:00,  3.87it/s]\n",
      "Training mean loss: 1.122194077147812: 100%|██████████| 61/61 [00:25<00:00,  2.39it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   252/252: 100%|██████████| 252/252 [00:26<00:00,  9.39it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1952, unlabelled size = 8048, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.73ba/s]\n",
      "100%|██████████| 8016/8016 [00:02<00:00, 2747.86ex/s]\n",
      "100%|██████████| 1984/1984 [00:00<00:00, 3028.49ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 1984, unlabelled size = 8016, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8666792492712698: 100%|██████████| 62/62 [00:20<00:00,  2.92it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8064804822206497: 100%|██████████| 16/16 [00:04<00:00,  3.95it/s]\n",
      "Eval mean loss: 1.8064804822206497: 100%|██████████| 16/16 [00:04<00:00,  3.81it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8666792492712698: 100%|██████████| 62/62 [00:24<00:00,  2.51it/s]\n",
      "Training mean loss: 1.6584865431631766: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5943466797471046: 100%|██████████| 16/16 [00:03<00:00,  5.05it/s]\n",
      "Eval mean loss: 1.5943466797471046: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6584865431631766: 100%|██████████| 62/62 [00:23<00:00,  2.64it/s]\n",
      "Training mean loss: 1.4572616219520569: 100%|██████████| 62/62 [00:19<00:00,  3.24it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4055499956011772: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "Eval mean loss: 1.4055499956011772: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4572616219520569: 100%|██████████| 62/62 [00:22<00:00,  2.78it/s]\n",
      "Training mean loss: 1.288897322070214: 100%|██████████| 62/62 [00:19<00:00,  3.22it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.258293092250824: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s] \n",
      "Eval mean loss: 1.258293092250824: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.288897322070214: 100%|██████████| 62/62 [00:22<00:00,  2.73it/s]\n",
      "Training mean loss: 1.1339787158273882: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1271571889519691: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 1.1271571889519691: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1271571889519691: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 28   0   0   1   1  13   8]\n",
      " [  0 193  39   4  17   0   2]\n",
      " [  0   5  32   1   1   0   0]\n",
      " [  0   8  14 169  13   0  11]\n",
      " [  3  45   8   9 121   2  34]\n",
      " [  3   0   0   0   1  47   1]\n",
      " [ 13   1   0   3   7  16 126]]\n",
      "{'accuracy': 0.6051666666666666}\n",
      "{'f1': 0.6060917824550892}\n",
      "{'precision': 0.6907145428144125}\n",
      "{'recall': 0.6051666666666666}\n",
      "\n",
      "Test mean loss: 1.1271571889519691: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "Training mean loss: 1.1339787158273882: 100%|██████████| 62/62 [00:24<00:00,  2.50it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   251/251: 100%|██████████| 251/251 [00:24<00:00, 10.07it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 1984, unlabelled size = 8016, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.13ba/s]\n",
      "100%|██████████| 7984/7984 [00:02<00:00, 3122.19ex/s]\n",
      "100%|██████████| 2016/2016 [00:00<00:00, 2517.94ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2016, unlabelled size = 7984, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8557132217619154: 100%|██████████| 63/63 [00:18<00:00,  3.35it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7642033770680428: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.7642033770680428: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8557132217619154: 100%|██████████| 63/63 [00:21<00:00,  2.97it/s]\n",
      "Training mean loss: 1.666289696617732: 100%|██████████| 63/63 [00:19<00:00,  3.30it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.573330894112587: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s] \n",
      "Eval mean loss: 1.573330894112587: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.666289696617732: 100%|██████████| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training mean loss: 1.4792524292355491: 100%|██████████| 63/63 [00:18<00:00,  3.35it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4222217947244644: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Eval mean loss: 1.4222217947244644: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4792524292355491: 100%|██████████| 63/63 [00:21<00:00,  2.87it/s]\n",
      "Training mean loss: 1.2953825791676838: 100%|██████████| 63/63 [00:19<00:00,  3.24it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2839750722050667: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s]\n",
      "Eval mean loss: 1.2839750722050667: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2953825791676838: 100%|██████████| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training mean loss: 1.126278731558058: 100%|██████████| 63/63 [00:20<00:00,  3.11it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1409424096345901: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Eval mean loss: 1.1409424096345901: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1409424096345901: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 28   0   0   1   0  13   9]\n",
      " [  0 155  59   8  30   1   2]\n",
      " [  0   8  29   1   1   0   0]\n",
      " [  0   3  10 177  13   0  12]\n",
      " [  2  29  10  12 134   1  34]\n",
      " [  0   0   0   0   1  49   2]\n",
      " [ 10   1   0   5   5  22 123]]\n",
      "{'accuracy': 0.589}\n",
      "{'f1': 0.5870384459724306}\n",
      "{'precision': 0.6429442388368484}\n",
      "{'recall': 0.589}\n",
      "\n",
      "Test mean loss: 1.1409424096345901: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Training mean loss: 1.126278731558058: 100%|██████████| 63/63 [00:26<00:00,  2.40it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   250/250: 100%|██████████| 250/250 [00:24<00:00, 10.16it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2016, unlabelled size = 7984, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.39ba/s]\n",
      "100%|██████████| 7952/7952 [00:02<00:00, 3217.43ex/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 3152.76ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2048, unlabelled size = 7952, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.870743289589882: 100%|██████████| 64/64 [00:18<00:00,  3.27it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.789358913898468: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s] \n",
      "Eval mean loss: 1.789358913898468: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.870743289589882: 100%|██████████| 64/64 [00:21<00:00,  2.93it/s]\n",
      "Training mean loss: 1.65057073533535: 100%|██████████| 64/64 [00:19<00:00,  3.33it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5324776843190193: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "Eval mean loss: 1.5324776843190193: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.65057073533535: 100%|██████████| 64/64 [00:22<00:00,  2.88it/s]\n",
      "Training mean loss: 1.4240075703710318: 100%|██████████| 64/64 [00:19<00:00,  3.30it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3683856055140495: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "Eval mean loss: 1.3683856055140495: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4240075703710318: 100%|██████████| 64/64 [00:22<00:00,  2.83it/s]\n",
      "Training mean loss: 1.259695390239358: 100%|██████████| 64/64 [00:21<00:00,  3.03it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.200301706790924: 100%|██████████| 16/16 [00:03<00:00,  4.66it/s] \n",
      "Eval mean loss: 1.200301706790924: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.259695390239358: 100%|██████████| 64/64 [00:25<00:00,  2.54it/s]\n",
      "Training mean loss: 1.0933445747941732: 100%|██████████| 64/64 [00:21<00:00,  3.09it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0605663359165192: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "Eval mean loss: 1.0605663359165192: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0605663359165192: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 23   0   0   1   0  14  13]\n",
      " [  1 210  19   3  19   0   3]\n",
      " [  0   8  29   1   1   0   0]\n",
      " [  0   3  20 168  11   0  13]\n",
      " [  2  33   4   7 149   0  27]\n",
      " [  1   1   0   0   0  49   1]\n",
      " [  5   2   1   3   9  21 125]]\n",
      "{'accuracy': 0.624}\n",
      "{'f1': 0.6349341696604055}\n",
      "{'precision': 0.696047114497583}\n",
      "{'recall': 0.624}\n",
      "\n",
      "Test mean loss: 1.0605663359165192: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "Training mean loss: 1.0933445747941732: 100%|██████████| 64/64 [00:27<00:00,  2.34it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   249/249: 100%|██████████| 249/249 [00:25<00:00,  9.77it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2048, unlabelled size = 7952, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.78ba/s]\n",
      "100%|██████████| 7920/7920 [00:02<00:00, 3119.65ex/s]\n",
      "100%|██████████| 2080/2080 [00:00<00:00, 3139.00ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2080, unlabelled size = 7920, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8938327642587516: 100%|██████████| 65/65 [00:19<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8024813160300255: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Eval mean loss: 1.8024813160300255: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8938327642587516: 100%|██████████| 65/65 [00:22<00:00,  2.89it/s]\n",
      "Training mean loss: 1.6899855265250572: 100%|██████████| 65/65 [00:20<00:00,  3.11it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5449484586715698: 100%|██████████| 16/16 [00:03<00:00,  5.18it/s]\n",
      "Eval mean loss: 1.5449484586715698: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6899855265250572: 100%|██████████| 65/65 [00:23<00:00,  2.72it/s]\n",
      "Training mean loss: 1.479631282733037: 100%|██████████| 65/65 [00:20<00:00,  3.23it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3756332024931908: 100%|██████████| 16/16 [00:03<00:00,  5.34it/s]\n",
      "Eval mean loss: 1.3756332024931908: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.479631282733037: 100%|██████████| 65/65 [00:23<00:00,  2.80it/s]\n",
      "Training mean loss: 1.2851720901635977: 100%|██████████| 65/65 [00:20<00:00,  3.09it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2120158597826958: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Eval mean loss: 1.2120158597826958: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2851720901635977: 100%|██████████| 65/65 [00:23<00:00,  2.75it/s]\n",
      "Training mean loss: 1.1051474653757536: 100%|██████████| 65/65 [00:20<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1024670228362083: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Eval mean loss: 1.1024670228362083: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1024670228362083: 100%|██████████| 16/16 [00:03<00:00,  5.35it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 22   0   0   1   2  20   6]\n",
      " [  1 165  51   3  34   0   1]\n",
      " [  0   5  32   0   2   0   0]\n",
      " [  1   2   5 184  16   1   6]\n",
      " [  5  19   7  10 164   4  13]\n",
      " [  3   1   0   0   0  48   0]\n",
      " [ 18   0   1   7  11  19 110]]\n",
      "{'accuracy': 0.6445}\n",
      "{'f1': 0.6475563497369637}\n",
      "{'precision': 0.6857296498296326}\n",
      "{'recall': 0.6445}\n",
      "\n",
      "Test mean loss: 1.1024670228362083: 100%|██████████| 16/16 [00:03<00:00,  5.20it/s]\n",
      "Training mean loss: 1.1051474653757536: 100%|██████████| 65/65 [00:26<00:00,  2.43it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   248/248: 100%|██████████| 248/248 [00:24<00:00,  9.95it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2080, unlabelled size = 7920, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.97ba/s]\n",
      "100%|██████████| 7888/7888 [00:03<00:00, 2509.06ex/s]\n",
      "100%|██████████| 2112/2112 [00:00<00:00, 3004.82ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2112, unlabelled size = 7888, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9013267683260369: 100%|██████████| 66/66 [00:23<00:00,  2.63it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8172499760985374: 100%|██████████| 16/16 [00:03<00:00,  4.35it/s]\n",
      "Eval mean loss: 1.8172499760985374: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9013267683260369: 100%|██████████| 66/66 [00:27<00:00,  2.41it/s]\n",
      "Training mean loss: 1.70169464747111: 100%|██████████| 66/66 [00:22<00:00,  2.93it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5762196853756905: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "Eval mean loss: 1.5762196853756905: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.70169464747111: 100%|██████████| 66/66 [00:26<00:00,  2.54it/s]\n",
      "Training mean loss: 1.4944454576029922: 100%|██████████| 66/66 [00:21<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4025826677680016: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "Eval mean loss: 1.4025826677680016: 100%|██████████| 16/16 [00:03<00:00,  5.06it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4944454576029922: 100%|██████████| 66/66 [00:24<00:00,  2.68it/s]\n",
      "Training mean loss: 1.2973407163764492: 100%|██████████| 66/66 [00:21<00:00,  3.05it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2481821402907372: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "Eval mean loss: 1.2481821402907372: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2973407163764492: 100%|██████████| 66/66 [00:24<00:00,  2.65it/s]\n",
      "Training mean loss: 1.13230407779867: 100%|██████████| 66/66 [00:21<00:00,  3.17it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1085860505700111: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Eval mean loss: 1.1085860505700111: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.1085860505700111: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 23   0   0   2   0  13  13]\n",
      " [  0 193  34   6  20   1   1]\n",
      " [  0   5  33   0   1   0   0]\n",
      " [  0   7  12 176  11   0   9]\n",
      " [  2  36   7  11 142   0  24]\n",
      " [  2   1   0   0   0  49   0]\n",
      " [ 13   1   1   7   8  18 118]]\n",
      "{'accuracy': 0.6263333333333333}\n",
      "{'f1': 0.6222224657037565}\n",
      "{'precision': 0.6586831732990553}\n",
      "{'recall': 0.6263333333333333}\n",
      "\n",
      "Test mean loss: 1.1085860505700111: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "Training mean loss: 1.13230407779867: 100%|██████████| 66/66 [00:27<00:00,  2.40it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   247/247: 100%|██████████| 247/247 [00:25<00:00,  9.87it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2112, unlabelled size = 7888, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.16ba/s]\n",
      "100%|██████████| 7856/7856 [00:02<00:00, 2788.22ex/s]\n",
      "100%|██████████| 2144/2144 [00:00<00:00, 2915.17ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2144, unlabelled size = 7856, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8840083933588285: 100%|██████████| 67/67 [00:20<00:00,  3.14it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7690018266439438: 100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n",
      "Eval mean loss: 1.7690018266439438: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8840083933588285: 100%|██████████| 67/67 [00:23<00:00,  2.85it/s]\n",
      "Training mean loss: 1.6924921558864081: 100%|██████████| 67/67 [00:24<00:00,  2.88it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.558418519794941: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s] \n",
      "Eval mean loss: 1.558418519794941: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6924921558864081: 100%|██████████| 67/67 [00:27<00:00,  2.46it/s]\n",
      "Training mean loss: 1.4510964973648983: 100%|██████████| 67/67 [00:21<00:00,  3.05it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3577276542782784: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "Eval mean loss: 1.3577276542782784: 100%|██████████| 16/16 [00:03<00:00,  4.80it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4510964973648983: 100%|██████████| 67/67 [00:25<00:00,  2.66it/s]\n",
      "Training mean loss: 1.2249949761291048: 100%|██████████| 67/67 [00:24<00:00,  2.73it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1667839735746384: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Eval mean loss: 1.1667839735746384: 100%|██████████| 16/16 [00:03<00:00,  4.71it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2249949761291048: 100%|██████████| 67/67 [00:27<00:00,  2.41it/s]\n",
      "Training mean loss: 1.0320855841707828: 100%|██████████| 67/67 [00:22<00:00,  2.93it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.014650784432888: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s] \n",
      "Eval mean loss: 1.014650784432888: 100%|██████████| 16/16 [00:03<00:00,  4.90it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.014650784432888: 100%|██████████| 16/16 [00:03<00:00,  4.98it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 31   0   0   2   0   8  10]\n",
      " [  0 183  33   1  35   0   3]\n",
      " [  0   9  28   1   1   0   0]\n",
      " [  0   1   7 185  16   0   6]\n",
      " [  2  19   6  11 162   0  22]\n",
      " [  7   1   0   0   0  44   0]\n",
      " [ 15   1   0   7  13  13 117]]\n",
      "{'accuracy': 0.6606666666666666}\n",
      "{'f1': 0.6715165513966521}\n",
      "{'precision': 0.7012367951790429}\n",
      "{'recall': 0.6606666666666666}\n",
      "\n",
      "Test mean loss: 1.014650784432888: 100%|██████████| 16/16 [00:03<00:00,  4.83it/s]\n",
      "Training mean loss: 1.0320855841707828: 100%|██████████| 67/67 [00:29<00:00,  2.28it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   246/246: 100%|██████████| 246/246 [00:26<00:00,  9.41it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2144, unlabelled size = 7856, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.00ba/s]\n",
      "100%|██████████| 7824/7824 [00:02<00:00, 3041.84ex/s]\n",
      "100%|██████████| 2176/2176 [00:00<00:00, 2958.44ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2176, unlabelled size = 7824, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8663092904231127: 100%|██████████| 68/68 [00:23<00:00,  2.96it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8044074326753616: 100%|██████████| 16/16 [00:03<00:00,  4.19it/s]\n",
      "Eval mean loss: 1.8044074326753616: 100%|██████████| 16/16 [00:03<00:00,  4.17it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8663092904231127: 100%|██████████| 68/68 [00:26<00:00,  2.53it/s]\n",
      "Training mean loss: 1.66279077705215: 100%|██████████| 68/68 [00:22<00:00,  3.11it/s]  \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6057433187961578: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Eval mean loss: 1.6057433187961578: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.66279077705215: 100%|██████████| 68/68 [00:25<00:00,  2.65it/s]\n",
      "Training mean loss: 1.4648745936505936: 100%|██████████| 68/68 [00:21<00:00,  3.19it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3946152850985527: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 1.3946152850985527: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4648745936505936: 100%|██████████| 68/68 [00:24<00:00,  2.78it/s]\n",
      "Training mean loss: 1.2847305027877582: 100%|██████████| 68/68 [00:22<00:00,  2.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2266122922301292: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n",
      "Eval mean loss: 1.2266122922301292: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2847305027877582: 100%|██████████| 68/68 [00:25<00:00,  2.68it/s]\n",
      "Training mean loss: 1.1099422293550827: 100%|██████████| 68/68 [00:22<00:00,  3.06it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.094533946365118: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s] \n",
      "Eval mean loss: 1.094533946365118: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.094533946365118: 100%|██████████| 16/16 [00:03<00:00,  4.89it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 17   0   0   1   0  24   9]\n",
      " [  4 212  24   3   6   0   6]\n",
      " [  0  16  21   1   1   0   0]\n",
      " [  1   4  16 171   8   0  15]\n",
      " [  3  28  18   8 126   1  38]\n",
      " [  1   1   0   0   0  50   0]\n",
      " [  9   1   0   3   5  23 125]]\n",
      "{'accuracy': 0.5736666666666667}\n",
      "{'f1': 0.5985201805028068}\n",
      "{'precision': 0.7140300755282972}\n",
      "{'recall': 0.5736666666666667}\n",
      "\n",
      "Test mean loss: 1.094533946365118: 100%|██████████| 16/16 [00:03<00:00,  4.84it/s]\n",
      "Training mean loss: 1.1099422293550827: 100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   245/245: 100%|██████████| 245/245 [00:25<00:00,  9.53it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2176, unlabelled size = 7824, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.20ba/s]\n",
      "100%|██████████| 7792/7792 [00:02<00:00, 3104.51ex/s]\n",
      "100%|██████████| 2208/2208 [00:00<00:00, 2962.07ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2208, unlabelled size = 7792, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8987054617508599: 100%|██████████| 69/69 [00:21<00:00,  3.04it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7854673936963081: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "Eval mean loss: 1.7854673936963081: 100%|██████████| 16/16 [00:03<00:00,  5.18it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8987054617508599: 100%|██████████| 69/69 [00:24<00:00,  2.83it/s]\n",
      "Training mean loss: 1.671845819639123: 100%|██████████| 69/69 [00:22<00:00,  3.07it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5524756088852882: 100%|██████████| 16/16 [00:03<00:00,  4.88it/s]\n",
      "Eval mean loss: 1.5524756088852882: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.671845819639123: 100%|██████████| 69/69 [00:26<00:00,  2.63it/s]\n",
      "Training mean loss: 1.4334405090497888: 100%|██████████| 69/69 [00:22<00:00,  3.13it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3747837841510773: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Eval mean loss: 1.3747837841510773: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4334405090497888: 100%|██████████| 69/69 [00:25<00:00,  2.71it/s]\n",
      "Training mean loss: 1.2608760802642158: 100%|██████████| 69/69 [00:21<00:00,  3.22it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.200658269226551: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s] \n",
      "Eval mean loss: 1.200658269226551: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2608760802642158: 100%|██████████| 69/69 [00:24<00:00,  2.78it/s]\n",
      "Training mean loss: 1.0715411270874133: 100%|██████████| 69/69 [00:23<00:00,  2.85it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0800699591636658: 100%|██████████| 16/16 [00:03<00:00,  5.35it/s]\n",
      "Eval mean loss: 1.0800699591636658: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0800699591636658: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 33   0   0   1   1   8   8]\n",
      " [  1 129  58   4  60   0   3]\n",
      " [  0   4  31   0   4   0   0]\n",
      " [  1   1  13 179  12   0   9]\n",
      " [  3   7  10   7 177   0  18]\n",
      " [  4   0   0   0   2  46   0]\n",
      " [ 18   0   0   3  12  14 119]]\n",
      "{'accuracy': 0.63}\n",
      "{'f1': 0.6391586536468861}\n",
      "{'precision': 0.6957481111696505}\n",
      "{'recall': 0.63}\n",
      "\n",
      "Test mean loss: 1.0800699591636658: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "Training mean loss: 1.0715411270874133: 100%|██████████| 69/69 [00:29<00:00,  2.30it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   244/244: 100%|██████████| 244/244 [00:24<00:00,  9.91it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2208, unlabelled size = 7792, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.12ba/s]\n",
      "100%|██████████| 7760/7760 [00:02<00:00, 3051.88ex/s]\n",
      "100%|██████████| 2240/2240 [00:00<00:00, 2718.30ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2240, unlabelled size = 7760, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.9021447454180036: 100%|██████████| 70/70 [00:20<00:00,  3.31it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8415569737553596: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Eval mean loss: 1.8415569737553596: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.9021447454180036: 100%|██████████| 70/70 [00:23<00:00,  2.93it/s]\n",
      "Training mean loss: 1.7242310762405395: 100%|██████████| 70/70 [00:23<00:00,  3.04it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6302071288228035: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 1.6302071288228035: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.7242310762405395: 100%|██████████| 70/70 [00:26<00:00,  2.69it/s]\n",
      "Training mean loss: 1.4887556961604527: 100%|██████████| 70/70 [00:22<00:00,  2.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4042768478393555: 100%|██████████| 16/16 [00:03<00:00,  4.68it/s]\n",
      "Eval mean loss: 1.4042768478393555: 100%|██████████| 16/16 [00:03<00:00,  4.53it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4887556961604527: 100%|██████████| 70/70 [00:26<00:00,  2.64it/s]\n",
      "Training mean loss: 1.2764030967439923: 100%|██████████| 70/70 [00:24<00:00,  2.76it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2331695780158043: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "Eval mean loss: 1.2331695780158043: 100%|██████████| 16/16 [00:03<00:00,  4.90it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2764030967439923: 100%|██████████| 70/70 [00:27<00:00,  2.54it/s]\n",
      "Training mean loss: 1.095006307533809: 100%|██████████| 70/70 [00:21<00:00,  3.22it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.093383427709341: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s] \n",
      "Eval mean loss: 1.093383427709341: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.093383427709341: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 11   0   0   2   0  28  10]\n",
      " [  1 180  48   3  21   0   2]\n",
      " [  0   4  34   0   1   0   0]\n",
      " [  0   6  15 173  14   0   7]\n",
      " [  2  37   8  13 137   0  25]\n",
      " [  0   2   0   0   0  48   2]\n",
      " [  5   1   0   7  11  24 118]]\n",
      "{'accuracy': 0.5813333333333334}\n",
      "{'f1': 0.6001331047748488}\n",
      "{'precision': 0.668370080620186}\n",
      "{'recall': 0.5813333333333334}\n",
      "\n",
      "Test mean loss: 1.093383427709341: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "Training mean loss: 1.095006307533809: 100%|██████████| 70/70 [00:27<00:00,  2.50it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   243/243: 100%|██████████| 243/243 [00:24<00:00, 10.12it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2240, unlabelled size = 7760, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.15ba/s]\n",
      "100%|██████████| 7728/7728 [00:02<00:00, 2959.90ex/s]\n",
      "100%|██████████| 2272/2272 [00:00<00:00, 3008.47ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2272, unlabelled size = 7728, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8474515794028699: 100%|██████████| 71/71 [00:20<00:00,  3.35it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.774951048195362: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s] \n",
      "Eval mean loss: 1.774951048195362: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8474515794028699: 100%|██████████| 71/71 [00:23<00:00,  3.01it/s]\n",
      "Training mean loss: 1.6109327497616621: 100%|██████████| 71/71 [00:21<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5504138842225075: 100%|██████████| 16/16 [00:02<00:00,  5.60it/s]\n",
      "Eval mean loss: 1.5504138842225075: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6109327497616621: 100%|██████████| 71/71 [00:24<00:00,  2.89it/s]\n",
      "Training mean loss: 1.3937072166254822: 100%|██████████| 71/71 [00:21<00:00,  3.32it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.356346532702446: 100%|██████████| 16/16 [00:02<00:00,  5.58it/s] \n",
      "Eval mean loss: 1.356346532702446: 100%|██████████| 16/16 [00:02<00:00,  5.55it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3937072166254822: 100%|██████████| 71/71 [00:24<00:00,  2.93it/s]\n",
      "Training mean loss: 1.2064970496674658: 100%|██████████| 71/71 [00:21<00:00,  3.34it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1978670880198479: 100%|██████████| 16/16 [00:02<00:00,  5.66it/s]\n",
      "Eval mean loss: 1.1978670880198479: 100%|██████████| 16/16 [00:02<00:00,  5.61it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2064970496674658: 100%|██████████| 71/71 [00:24<00:00,  2.94it/s]\n",
      "Training mean loss: 1.037257430419116: 100%|██████████| 71/71 [00:21<00:00,  3.35it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0375363156199455: 100%|██████████| 16/16 [00:02<00:00,  5.53it/s]\n",
      "Eval mean loss: 1.0375363156199455: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0375363156199455: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 22   0   1   1   1  17   9]\n",
      " [  0 179  30   1  43   0   2]\n",
      " [  0   8  29   1   1   0   0]\n",
      " [  1   5  11 173  18   0   7]\n",
      " [  5  22   5   3 173   0  14]\n",
      " [  0   1   0   0   0  51   0]\n",
      " [  8   1   0   3  14  19 121]]\n",
      "{'accuracy': 0.555}\n",
      "{'f1': 0.6008037232869814}\n",
      "{'precision': 0.7373501709589447}\n",
      "{'recall': 0.555}\n",
      "\n",
      "Test mean loss: 1.0375363156199455: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "Training mean loss: 1.037257430419116: 100%|██████████| 71/71 [00:27<00:00,  2.60it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   242/242: 100%|██████████| 242/242 [00:23<00:00, 10.41it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2272, unlabelled size = 7728, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.57ba/s]\n",
      "100%|██████████| 7696/7696 [00:02<00:00, 3180.16ex/s]\n",
      "100%|██████████| 2304/2304 [00:00<00:00, 3068.28ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2304, unlabelled size = 7696, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8621395412418578: 100%|██████████| 72/72 [00:21<00:00,  3.32it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.733150526881218: 100%|██████████| 16/16 [00:02<00:00,  5.46it/s] \n",
      "Eval mean loss: 1.733150526881218: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8621395412418578: 100%|██████████| 72/72 [00:23<00:00,  3.00it/s]\n",
      "Training mean loss: 1.6158038824796677: 100%|██████████| 72/72 [00:21<00:00,  3.31it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4864384308457375: 100%|██████████| 16/16 [00:03<00:00,  5.36it/s]\n",
      "Eval mean loss: 1.4864384308457375: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6158038824796677: 100%|██████████| 72/72 [00:25<00:00,  2.88it/s]\n",
      "Training mean loss: 1.3996779885556963: 100%|██████████| 72/72 [00:22<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3167582228779793: 100%|██████████| 16/16 [00:02<00:00,  5.34it/s]\n",
      "Eval mean loss: 1.3167582228779793: 100%|██████████| 16/16 [00:02<00:00,  5.34it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3996779885556963: 100%|██████████| 72/72 [00:25<00:00,  2.86it/s]\n",
      "Training mean loss: 1.209598696894116: 100%|██████████| 72/72 [00:22<00:00,  3.26it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1571850255131721: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "Eval mean loss: 1.1571850255131721: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.209598696894116: 100%|██████████| 72/72 [00:24<00:00,  2.88it/s]\n",
      "Training mean loss: 1.0529317888948653: 100%|██████████| 72/72 [00:22<00:00,  3.27it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0326092168688774: 100%|██████████| 16/16 [00:02<00:00,  5.45it/s]\n",
      "Eval mean loss: 1.0326092168688774: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0326092168688774: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 23   0   0   2   1  17   8]\n",
      " [  0 146  46   3  58   0   2]\n",
      " [  0   4  33   0   2   0   0]\n",
      " [  0   2   9 185  11   0   8]\n",
      " [  3  21   9   9 157   1  22]\n",
      " [  0   1   0   0   0  50   1]\n",
      " [  9   1   0   7   9  19 121]]\n",
      "{'accuracy': 0.5958333333333333}\n",
      "{'f1': 0.6123054636417983}\n",
      "{'precision': 0.692963153860416}\n",
      "{'recall': 0.5958333333333333}\n",
      "\n",
      "Test mean loss: 1.0326092168688774: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "Training mean loss: 1.0529317888948653: 100%|██████████| 72/72 [00:28<00:00,  2.56it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   241/241: 100%|██████████| 241/241 [00:23<00:00, 10.22it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2304, unlabelled size = 7696, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.34ba/s]\n",
      "100%|██████████| 7664/7664 [00:02<00:00, 3142.12ex/s]\n",
      "100%|██████████| 2336/2336 [00:00<00:00, 3147.54ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2336, unlabelled size = 7664, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8304772132063565: 100%|██████████| 73/73 [00:21<00:00,  3.30it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7597011551260948: 100%|██████████| 16/16 [00:02<00:00,  5.54it/s]\n",
      "Eval mean loss: 1.7597011551260948: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8304772132063565: 100%|██████████| 73/73 [00:24<00:00,  3.00it/s]\n",
      "Training mean loss: 1.6144774368364516: 100%|██████████| 73/73 [00:22<00:00,  3.32it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5891580358147621: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Eval mean loss: 1.5891580358147621: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6144774368364516: 100%|██████████| 73/73 [00:25<00:00,  2.89it/s]\n",
      "Training mean loss: 1.3952685023007327: 100%|██████████| 73/73 [00:22<00:00,  3.27it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3620911091566086: 100%|██████████| 16/16 [00:02<00:00,  5.52it/s]\n",
      "Eval mean loss: 1.3620911091566086: 100%|██████████| 16/16 [00:02<00:00,  5.48it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3952685023007327: 100%|██████████| 73/73 [00:25<00:00,  2.90it/s]\n",
      "Training mean loss: 1.1986736483769873: 100%|██████████| 73/73 [00:22<00:00,  3.19it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1738662049174309: 100%|██████████| 16/16 [00:04<00:00,  3.33it/s]\n",
      "Eval mean loss: 1.1738662049174309: 100%|██████████| 16/16 [00:04<00:00,  3.30it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1986736483769873: 100%|██████████| 73/73 [00:27<00:00,  2.68it/s]\n",
      "Training mean loss: 1.0326719839278966: 100%|██████████| 73/73 [00:22<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0237595029175282: 100%|██████████| 16/16 [00:02<00:00,  5.51it/s]\n",
      "Eval mean loss: 1.0237595029175282: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0237595029175282: 100%|██████████| 16/16 [00:03<00:00,  5.37it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 40   0   0   2   0   6   3]\n",
      " [  3 194  22   1  34   0   1]\n",
      " [  0  11  27   0   1   0   0]\n",
      " [  3   1  19 171  12   0   9]\n",
      " [  4  23   5   8 158   0  24]\n",
      " [  7   1   0   0   0  44   0]\n",
      " [ 20   1   0   4   9  16 116]]\n",
      "{'accuracy': 0.5948333333333333}\n",
      "{'f1': 0.6189701271403307}\n",
      "{'precision': 0.7092101551422638}\n",
      "{'recall': 0.5948333333333333}\n",
      "\n",
      "Test mean loss: 1.0237595029175282: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s]\n",
      "Training mean loss: 1.0326719839278966: 100%|██████████| 73/73 [00:28<00:00,  2.53it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   240/240: 100%|██████████| 240/240 [00:23<00:00, 10.03it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2336, unlabelled size = 7664, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.30ba/s]\n",
      "100%|██████████| 7632/7632 [00:02<00:00, 3117.72ex/s]\n",
      "100%|██████████| 2368/2368 [00:00<00:00, 3172.91ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2368, unlabelled size = 7632, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8612856816601109: 100%|██████████| 74/74 [00:22<00:00,  3.26it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.778394490480423: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s] \n",
      "Eval mean loss: 1.778394490480423: 100%|██████████| 16/16 [00:02<00:00,  5.34it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8612856816601109: 100%|██████████| 74/74 [00:25<00:00,  2.94it/s]\n",
      "Training mean loss: 1.624162812490721: 100%|██████████| 74/74 [00:23<00:00,  3.13it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5359016209840775: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Eval mean loss: 1.5359016209840775: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.624162812490721: 100%|██████████| 74/74 [00:26<00:00,  2.82it/s]\n",
      "Training mean loss: 1.406998648836806: 100%|██████████| 74/74 [00:23<00:00,  3.22it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3292095959186554: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Eval mean loss: 1.3292095959186554: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.406998648836806: 100%|██████████| 74/74 [00:26<00:00,  2.82it/s]\n",
      "Training mean loss: 1.2080143126281533: 100%|██████████| 74/74 [00:23<00:00,  3.16it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.193781517446041: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s] \n",
      "Eval mean loss: 1.193781517446041: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.2080143126281533: 100%|██████████| 74/74 [00:26<00:00,  2.80it/s]\n",
      "Training mean loss: 1.0340824175525356: 100%|██████████| 74/74 [00:23<00:00,  3.18it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0315886214375496: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Eval mean loss: 1.0315886214375496: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0315886214375496: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 28   0   0   3   1  14   5]\n",
      " [  0 182  28   1  43   0   1]\n",
      " [  0   7  30   0   2   0   0]\n",
      " [  0   4  15 176  15   0   5]\n",
      " [  4  27   7   4 170   0  10]\n",
      " [  4   0   0   0   2  46   0]\n",
      " [ 22   0   0   9  20  19  96]]\n",
      "{'accuracy': 0.6118333333333333}\n",
      "{'f1': 0.6275843094936284}\n",
      "{'precision': 0.7108260065680905}\n",
      "{'recall': 0.6118333333333333}\n",
      "\n",
      "Test mean loss: 1.0315886214375496: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "Training mean loss: 1.0340824175525356: 100%|██████████| 74/74 [00:29<00:00,  2.53it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   239/239: 100%|██████████| 239/239 [00:23<00:00,  9.98it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2368, unlabelled size = 7632, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.44ba/s]\n",
      "100%|██████████| 7600/7600 [00:02<00:00, 3043.85ex/s]\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 3161.19ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2400, unlabelled size = 7600, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8784199555714924: 100%|██████████| 75/75 [00:22<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7936020269989967: 100%|██████████| 16/16 [00:03<00:00,  4.63it/s]\n",
      "Eval mean loss: 1.7936020269989967: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8784199555714924: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
      "Training mean loss: 1.6447085332870484: 100%|██████████| 75/75 [00:24<00:00,  3.18it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5367621555924416: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s]\n",
      "Eval mean loss: 1.5367621555924416: 100%|██████████| 16/16 [00:02<00:00,  5.34it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6447085332870484: 100%|██████████| 75/75 [00:27<00:00,  2.76it/s]\n",
      "Training mean loss: 1.387658076286316: 100%|██████████| 75/75 [00:23<00:00,  3.16it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3022598251700401: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "Eval mean loss: 1.3022598251700401: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.387658076286316: 100%|██████████| 75/75 [00:27<00:00,  2.77it/s]\n",
      "Training mean loss: 1.1699271774291993: 100%|██████████| 75/75 [00:27<00:00,  2.43it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1421863213181496: 100%|██████████| 16/16 [00:03<00:00,  4.86it/s]\n",
      "Eval mean loss: 1.1421863213181496: 100%|██████████| 16/16 [00:03<00:00,  4.86it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1699271774291993: 100%|██████████| 75/75 [00:30<00:00,  2.42it/s]\n",
      "Training mean loss: 0.9917363214492798: 100%|██████████| 75/75 [00:24<00:00,  3.07it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9626520052552223: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "Eval mean loss: 0.9626520052552223: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9626520052552223: 100%|██████████| 16/16 [00:03<00:00,  5.34it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 31   0   0   1   0   8  11]\n",
      " [  2 210  19   4  16   2   2]\n",
      " [  0   6  30   2   1   0   0]\n",
      " [  0   6   6 184   9   0  10]\n",
      " [  2  27   5  12 141   0  35]\n",
      " [ 10   1   0   0   0  41   0]\n",
      " [ 17   1   0   3   7  12 126]]\n",
      "{'accuracy': 0.6335}\n",
      "{'f1': 0.6513728583569408}\n",
      "{'precision': 0.7014531190595383}\n",
      "{'recall': 0.6335}\n",
      "\n",
      "Test mean loss: 0.9626520052552223: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s]\n",
      "Training mean loss: 0.9917363214492798: 100%|██████████| 75/75 [00:30<00:00,  2.42it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   238/238: 100%|██████████| 238/238 [00:24<00:00,  9.84it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2400, unlabelled size = 7600, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.42ba/s]\n",
      "100%|██████████| 7568/7568 [00:02<00:00, 3010.33ex/s]\n",
      "100%|██████████| 2432/2432 [00:00<00:00, 2995.96ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2432, unlabelled size = 7568, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8941036682379873: 100%|██████████| 76/76 [00:27<00:00,  3.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8436779901385307: 100%|██████████| 16/16 [00:03<00:00,  5.12it/s]\n",
      "Eval mean loss: 1.8436779901385307: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8941036682379873: 100%|██████████| 76/76 [00:30<00:00,  2.51it/s]\n",
      "Training mean loss: 1.665217300778941: 100%|██████████| 76/76 [00:24<00:00,  3.10it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.572368137538433: 100%|██████████| 16/16 [00:03<00:00,  5.37it/s] \n",
      "Eval mean loss: 1.572368137538433: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.665217300778941: 100%|██████████| 76/76 [00:27<00:00,  2.73it/s]\n",
      "Training mean loss: 1.4153765032165928: 100%|██████████| 76/76 [00:24<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3447297289967537: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "Eval mean loss: 1.3447297289967537: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4153765032165928: 100%|██████████| 76/76 [00:27<00:00,  2.79it/s]\n",
      "Training mean loss: 1.1908016298946582: 100%|██████████| 76/76 [00:24<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1854447573423386: 100%|██████████| 16/16 [00:03<00:00,  5.12it/s]\n",
      "Eval mean loss: 1.1854447573423386: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1908016298946582: 100%|██████████| 76/76 [00:27<00:00,  2.78it/s]\n",
      "Training mean loss: 1.020971102149863: 100%|██████████| 76/76 [00:25<00:00,  3.07it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0341944321990013: 100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n",
      "Eval mean loss: 1.0341944321990013: 100%|██████████| 16/16 [00:03<00:00,  5.05it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0341944321990013: 100%|██████████| 16/16 [00:03<00:00,  5.35it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 34   0   0   1   1   6   9]\n",
      " [  0 184  34   1  32   0   4]\n",
      " [  0   9  27   2   1   0   0]\n",
      " [  0   3  13 176  12   0  11]\n",
      " [  3  29   4   5 154   1  26]\n",
      " [  8   1   0   0   0  43   0]\n",
      " [ 20   1   0   4  11  14 116]]\n",
      "{'accuracy': 0.5746666666666667}\n",
      "{'f1': 0.5987350985533256}\n",
      "{'precision': 0.6690869577096081}\n",
      "{'recall': 0.5746666666666667}\n",
      "\n",
      "Test mean loss: 1.0341944321990013: 100%|██████████| 16/16 [00:03<00:00,  5.19it/s]\n",
      "Training mean loss: 1.020971102149863: 100%|██████████| 76/76 [00:31<00:00,  2.43it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   237/237: 100%|██████████| 237/237 [00:24<00:00,  9.59it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2432, unlabelled size = 7568, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.37ba/s]\n",
      "100%|██████████| 7536/7536 [00:02<00:00, 2961.93ex/s]\n",
      "100%|██████████| 2464/2464 [00:00<00:00, 2842.61ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2464, unlabelled size = 7536, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8696091562122494: 100%|██████████| 77/77 [00:23<00:00,  3.17it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7615100741386414: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 1.7615100741386414: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8696091562122494: 100%|██████████| 77/77 [00:26<00:00,  2.91it/s]\n",
      "Training mean loss: 1.6318293097731356: 100%|██████████| 77/77 [00:25<00:00,  3.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5455397963523865: 100%|██████████| 16/16 [00:03<00:00,  5.12it/s]\n",
      "Eval mean loss: 1.5455397963523865: 100%|██████████| 16/16 [00:03<00:00,  5.11it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6318293097731356: 100%|██████████| 77/77 [00:28<00:00,  2.73it/s]\n",
      "Training mean loss: 1.4115629892844659: 100%|██████████| 77/77 [00:25<00:00,  3.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3610735386610031: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s]\n",
      "Eval mean loss: 1.3610735386610031: 100%|██████████| 16/16 [00:03<00:00,  4.84it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4115629892844659: 100%|██████████| 77/77 [00:28<00:00,  2.67it/s]\n",
      "Training mean loss: 1.1994142222714115: 100%|██████████| 77/77 [00:24<00:00,  3.18it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1790804043412209: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "Eval mean loss: 1.1790804043412209: 100%|██████████| 16/16 [00:03<00:00,  5.27it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1994142222714115: 100%|██████████| 77/77 [00:27<00:00,  2.83it/s]\n",
      "Training mean loss: 1.0212581095757423: 100%|██████████| 77/77 [00:26<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0321237072348595: 100%|██████████| 16/16 [00:03<00:00,  4.82it/s]\n",
      "Eval mean loss: 1.0321237072348595: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 1.0321237072348595: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 25   0   0   1   1  16   8]\n",
      " [  0 194  25   4  29   1   2]\n",
      " [  0   5  32   1   1   0   0]\n",
      " [  0   6  11 170  16   0  12]\n",
      " [  4  34   4   7 149   1  23]\n",
      " [  1   1   0   0   0  50   0]\n",
      " [ 13   1   0   4  13  17 118]]\n",
      "{'accuracy': 0.6285}\n",
      "{'f1': 0.6403450027124831}\n",
      "{'precision': 0.688341377040245}\n",
      "{'recall': 0.6285}\n",
      "\n",
      "Test mean loss: 1.0321237072348595: 100%|██████████| 16/16 [00:03<00:00,  4.89it/s]\n",
      "Training mean loss: 1.0212581095757423: 100%|██████████| 77/77 [00:33<00:00,  2.31it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   236/236: 100%|██████████| 236/236 [00:25<00:00,  9.09it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2464, unlabelled size = 7536, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.32ba/s]\n",
      "100%|██████████| 7504/7504 [00:02<00:00, 3072.86ex/s]\n",
      "100%|██████████| 2496/2496 [00:00<00:00, 2803.75ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2496, unlabelled size = 7504, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8597534696261089: 100%|██████████| 78/78 [00:25<00:00,  2.90it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7618078589439392: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Eval mean loss: 1.7618078589439392: 100%|██████████| 16/16 [00:03<00:00,  4.64it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8597534696261089: 100%|██████████| 78/78 [00:28<00:00,  2.72it/s]\n",
      "Training mean loss: 1.6157410618586419: 100%|██████████| 78/78 [00:26<00:00,  2.97it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4718330204486847: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "Eval mean loss: 1.4718330204486847: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6157410618586419: 100%|██████████| 78/78 [00:29<00:00,  2.63it/s]\n",
      "Training mean loss: 1.3574605446595411: 100%|██████████| 78/78 [00:25<00:00,  3.02it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2643587663769722: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n",
      "Eval mean loss: 1.2643587663769722: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3574605446595411: 100%|██████████| 78/78 [00:28<00:00,  2.73it/s]\n",
      "Training mean loss: 1.1292600234349568: 100%|██████████| 78/78 [00:25<00:00,  3.11it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1145605072379112: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "Eval mean loss: 1.1145605072379112: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1292600234349568: 100%|██████████| 78/78 [00:28<00:00,  2.73it/s]\n",
      "Training mean loss: 0.9674880084318992: 100%|██████████| 78/78 [00:24<00:00,  3.13it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9518841244280338: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "Eval mean loss: 0.9518841244280338: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9518841244280338: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 27   0   0   2   1  11  10]\n",
      " [  0 186  21   8  38   1   1]\n",
      " [  0   6  30   2   1   0   0]\n",
      " [  0   3   9 188   9   0   6]\n",
      " [  3  19   3  11 167   0  19]\n",
      " [  7   1   0   0   0  42   2]\n",
      " [ 14   1   1   6  14  13 117]]\n",
      "{'accuracy': 0.6586666666666666}\n",
      "{'f1': 0.6607597200934521}\n",
      "{'precision': 0.7035935973758997}\n",
      "{'recall': 0.6586666666666666}\n",
      "\n",
      "Test mean loss: 0.9518841244280338: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n",
      "Training mean loss: 0.9674880084318992: 100%|██████████| 78/78 [00:31<00:00,  2.51it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   235/235: 100%|██████████| 235/235 [00:25<00:00,  9.24it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2496, unlabelled size = 7504, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.40ba/s]\n",
      "100%|██████████| 7472/7472 [00:02<00:00, 3085.96ex/s]\n",
      "100%|██████████| 2528/2528 [00:00<00:00, 3154.25ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2528, unlabelled size = 7472, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8255467414855957: 100%|██████████| 79/79 [00:24<00:00,  3.16it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7089363262057304: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s]\n",
      "Eval mean loss: 1.7089363262057304: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8255467414855957: 100%|██████████| 79/79 [00:27<00:00,  2.88it/s]\n",
      "Training mean loss: 1.578860160670703: 100%|██████████| 79/79 [00:25<00:00,  3.05it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4943075776100159: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "Eval mean loss: 1.4943075776100159: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.578860160670703: 100%|██████████| 79/79 [00:28<00:00,  2.75it/s]\n",
      "Training mean loss: 1.3651431361331214: 100%|██████████| 79/79 [00:27<00:00,  2.85it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2844203934073448: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "Eval mean loss: 1.2844203934073448: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3651431361331214: 100%|██████████| 79/79 [00:30<00:00,  2.60it/s]\n",
      "Training mean loss: 1.156193244306347: 100%|██████████| 79/79 [00:26<00:00,  2.87it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1406037360429764: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "Eval mean loss: 1.1406037360429764: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.156193244306347: 100%|██████████| 79/79 [00:29<00:00,  2.66it/s]\n",
      "Training mean loss: 0.984155410452734: 100%|██████████| 79/79 [00:26<00:00,  3.09it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9914761558175087: 100%|██████████| 16/16 [00:03<00:00,  4.84it/s]\n",
      "Eval mean loss: 0.9914761558175087: 100%|██████████| 16/16 [00:03<00:00,  4.88it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9914761558175087: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 22   0   0   1   1  16  11]\n",
      " [  1 188  35   5  23   1   2]\n",
      " [  0  12  24   2   1   0   0]\n",
      " [  0   3  12 189   4   0   7]\n",
      " [  4  31  12   7 149   0  19]\n",
      " [  3   1   0   0   0  48   0]\n",
      " [  3   1   0   7  10  18 127]]\n",
      "{'accuracy': 0.6563333333333333}\n",
      "{'f1': 0.6727786969268866}\n",
      "{'precision': 0.7143244740909813}\n",
      "{'recall': 0.6563333333333333}\n",
      "\n",
      "Test mean loss: 0.9914761558175087: 100%|██████████| 16/16 [00:03<00:00,  4.88it/s]\n",
      "Training mean loss: 0.984155410452734: 100%|██████████| 79/79 [00:33<00:00,  2.39it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   234/234: 100%|██████████| 234/234 [00:24<00:00,  9.58it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2528, unlabelled size = 7472, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.28ba/s]\n",
      "100%|██████████| 7440/7440 [00:02<00:00, 2962.91ex/s]\n",
      "100%|██████████| 2560/2560 [00:00<00:00, 2975.18ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2560, unlabelled size = 7440, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8295376747846603: 100%|██████████| 80/80 [00:27<00:00,  2.61it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7048466354608536: 100%|██████████| 16/16 [00:03<00:00,  5.15it/s]\n",
      "Eval mean loss: 1.7048466354608536: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8295376747846603: 100%|██████████| 80/80 [00:31<00:00,  2.58it/s]\n",
      "Training mean loss: 1.5745702683925629: 100%|██████████| 80/80 [00:26<00:00,  3.12it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.473272055387497: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s] \n",
      "Eval mean loss: 1.473272055387497: 100%|██████████| 16/16 [00:02<00:00,  5.37it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5745702683925629: 100%|██████████| 80/80 [00:29<00:00,  2.73it/s]\n",
      "Training mean loss: 1.3536683008074761: 100%|██████████| 80/80 [00:26<00:00,  3.02it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3020530194044113: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Eval mean loss: 1.3020530194044113: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3536683008074761: 100%|██████████| 80/80 [00:29<00:00,  2.73it/s]\n",
      "Training mean loss: 1.1541748553514481: 100%|██████████| 80/80 [00:26<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.118053860962391: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s] \n",
      "Eval mean loss: 1.118053860962391: 100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1541748553514481: 100%|██████████| 80/80 [00:29<00:00,  2.73it/s]\n",
      "Training mean loss: 0.9719847410917282: 100%|██████████| 80/80 [00:27<00:00,  3.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9692905060946941: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "Eval mean loss: 0.9692905060946941: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9692905060946941: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 31   0   0   3   1  11   5]\n",
      " [  0 162  42   2  47   0   2]\n",
      " [  0   4  32   1   2   0   0]\n",
      " [  0   4   9 184  10   0   8]\n",
      " [  4  21   9   5 169   1  13]\n",
      " [  5   0   0   0   1  46   0]\n",
      " [ 26   1   0   6  18  14 101]]\n",
      "{'accuracy': 0.6145}\n",
      "{'f1': 0.6296364598900054}\n",
      "{'precision': 0.7118648009314223}\n",
      "{'recall': 0.6145}\n",
      "\n",
      "Test mean loss: 0.9692905060946941: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n",
      "Training mean loss: 0.9719847410917282: 100%|██████████| 80/80 [00:33<00:00,  2.38it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   233/233: 100%|██████████| 233/233 [00:23<00:00,  9.84it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2560, unlabelled size = 7440, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.37ba/s]\n",
      "100%|██████████| 7408/7408 [00:02<00:00, 3087.99ex/s]\n",
      "100%|██████████| 2592/2592 [00:00<00:00, 3191.12ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2592, unlabelled size = 7408, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8434517633767775: 100%|██████████| 81/81 [00:24<00:00,  3.17it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7508996650576591: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "Eval mean loss: 1.7508996650576591: 100%|██████████| 16/16 [00:03<00:00,  5.30it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8434517633767775: 100%|██████████| 81/81 [00:27<00:00,  2.93it/s]\n",
      "Training mean loss: 1.5781142505598658: 100%|██████████| 81/81 [00:28<00:00,  2.79it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.48998611420393: 100%|██████████| 16/16 [00:03<00:00,  5.13it/s]  \n",
      "Eval mean loss: 1.48998611420393: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5781142505598658: 100%|██████████| 81/81 [00:31<00:00,  2.54it/s]\n",
      "Training mean loss: 1.3324583032984791: 100%|██████████| 81/81 [00:29<00:00,  2.63it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2752217948436737: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]\n",
      "Eval mean loss: 1.2752217948436737: 100%|██████████| 16/16 [00:03<00:00,  4.73it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3324583032984791: 100%|██████████| 81/81 [00:33<00:00,  2.44it/s]\n",
      "Training mean loss: 1.1387862430678473: 100%|██████████| 81/81 [00:28<00:00,  2.91it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1077294498682022: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "Eval mean loss: 1.1077294498682022: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1387862430678473: 100%|██████████| 81/81 [00:31<00:00,  2.56it/s]\n",
      "Training mean loss: 0.9557615371397984: 100%|██████████| 81/81 [00:26<00:00,  3.13it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9545097835361958: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "Eval mean loss: 0.9545097835361958: 100%|██████████| 16/16 [00:03<00:00,  5.18it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9545097835361958: 100%|██████████| 16/16 [00:03<00:00,  5.18it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 27   0   0   2   1  12   9]\n",
      " [  0 184  38   6  25   0   2]\n",
      " [  0   4  34   0   1   0   0]\n",
      " [  0   5   9 179  15   0   7]\n",
      " [  1  22   4  12 170   1  12]\n",
      " [  1   1   0   0   0  49   1]\n",
      " [ 15   1   0   7  14  18 111]]\n",
      "{'accuracy': 0.5961666666666666}\n",
      "{'f1': 0.6182250943383943}\n",
      "{'precision': 0.7295160735640978}\n",
      "{'recall': 0.5961666666666666}\n",
      "\n",
      "Test mean loss: 0.9545097835361958: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "Training mean loss: 0.9557615371397984: 100%|██████████| 81/81 [00:32<00:00,  2.48it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   232/232: 100%|██████████| 232/232 [00:27<00:00,  8.44it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2592, unlabelled size = 7408, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.12ba/s]\n",
      "100%|██████████| 7376/7376 [00:03<00:00, 2183.95ex/s]\n",
      "100%|██████████| 2624/2624 [00:01<00:00, 2083.90ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2624, unlabelled size = 7376, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8534190204085372: 100%|██████████| 82/82 [00:28<00:00,  3.10it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7175771594047546: 100%|██████████| 16/16 [00:03<00:00,  4.49it/s]\n",
      "Eval mean loss: 1.7175771594047546: 100%|██████████| 16/16 [00:03<00:00,  4.44it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8534190204085372: 100%|██████████| 82/82 [00:31<00:00,  2.58it/s]\n",
      "Training mean loss: 1.6012204696492451: 100%|██████████| 82/82 [00:26<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5098422467708588: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "Eval mean loss: 1.5098422467708588: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6012204696492451: 100%|██████████| 82/82 [00:30<00:00,  2.72it/s]\n",
      "Training mean loss: 1.3637330953667803: 100%|██████████| 82/82 [00:26<00:00,  3.18it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.302688181400299: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s] \n",
      "Eval mean loss: 1.302688181400299: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3637330953667803: 100%|██████████| 82/82 [00:29<00:00,  2.82it/s]\n",
      "Training mean loss: 1.1474077621611154: 100%|██████████| 82/82 [00:25<00:00,  3.15it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1115408837795258: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
      "Eval mean loss: 1.1115408837795258: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1474077621611154: 100%|██████████| 82/82 [00:28<00:00,  2.85it/s]\n",
      "Training mean loss: 0.9590455577140902: 100%|██████████| 82/82 [00:25<00:00,  3.26it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9631337746977806: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s]\n",
      "Eval mean loss: 0.9631337746977806: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9631337746977806: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 30   0   0   2   0   9  10]\n",
      " [  0 186  30   3  33   1   2]\n",
      " [  0   7  29   1   2   0   0]\n",
      " [  0   3  11 181  11   0   9]\n",
      " [  3  18  13   7 159   0  22]\n",
      " [  4   0   0   0   1  46   1]\n",
      " [  7   1   0   3   9  16 130]]\n",
      "{'accuracy': 0.6253333333333333}\n",
      "{'f1': 0.6530735241271253}\n",
      "{'precision': 0.7348999102174394}\n",
      "{'recall': 0.6253333333333333}\n",
      "\n",
      "Test mean loss: 0.9631337746977806: 100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n",
      "Training mean loss: 0.9590455577140902: 100%|██████████| 82/82 [00:31<00:00,  2.60it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   231/231: 100%|██████████| 231/231 [00:23<00:00, 10.00it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2624, unlabelled size = 7376, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.66ba/s]\n",
      "100%|██████████| 7344/7344 [00:02<00:00, 3133.29ex/s]\n",
      "100%|██████████| 2656/2656 [00:00<00:00, 3168.54ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2656, unlabelled size = 7344, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8797691687043891: 100%|██████████| 83/83 [00:24<00:00,  3.27it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.769577495753765: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s] \n",
      "Eval mean loss: 1.769577495753765: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8797691687043891: 100%|██████████| 83/83 [00:27<00:00,  3.00it/s]\n",
      "Training mean loss: 1.6547685574336224: 100%|██████████| 83/83 [00:26<00:00,  2.96it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.527249313890934: 100%|██████████| 16/16 [00:03<00:00,  5.26it/s] \n",
      "Eval mean loss: 1.527249313890934: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6547685574336224: 100%|██████████| 83/83 [00:29<00:00,  2.81it/s]\n",
      "Training mean loss: 1.4083786929946347: 100%|██████████| 83/83 [00:27<00:00,  3.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3162352070212364: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Eval mean loss: 1.3162352070212364: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.4083786929946347: 100%|██████████| 83/83 [00:30<00:00,  2.70it/s]\n",
      "Training mean loss: 1.1833046559827873: 100%|██████████| 83/83 [00:27<00:00,  2.89it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1362032517790794: 100%|██████████| 16/16 [00:03<00:00,  4.64it/s]\n",
      "Eval mean loss: 1.1362032517790794: 100%|██████████| 16/16 [00:03<00:00,  4.55it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1833046559827873: 100%|██████████| 83/83 [00:30<00:00,  2.69it/s]\n",
      "Training mean loss: 0.9838186193661518: 100%|██████████| 83/83 [00:29<00:00,  2.83it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9779203906655312: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "Eval mean loss: 0.9779203906655312: 100%|██████████| 16/16 [00:03<00:00,  4.99it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9779203906655312: 100%|██████████| 16/16 [00:03<00:00,  4.84it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 30   0   0   1   1   9  10]\n",
      " [  0 183  39   6  24   1   2]\n",
      " [  0   6  31   1   1   0   0]\n",
      " [  0   3   8 186   9   0   9]\n",
      " [  5  26   6   9 154   1  21]\n",
      " [  6   1   0   0   0  45   0]\n",
      " [ 21   1   0   4  12  16 112]]\n",
      "{'accuracy': 0.6528333333333334}\n",
      "{'f1': 0.6572426556248039}\n",
      "{'precision': 0.6839585538420573}\n",
      "{'recall': 0.6528333333333334}\n",
      "\n",
      "Test mean loss: 0.9779203906655312: 100%|██████████| 16/16 [00:03<00:00,  4.66it/s]\n",
      "Training mean loss: 0.9838186193661518: 100%|██████████| 83/83 [00:35<00:00,  2.32it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   230/230: 100%|██████████| 230/230 [00:23<00:00,  9.85it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2656, unlabelled size = 7344, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.28ba/s]\n",
      "100%|██████████| 7312/7312 [00:02<00:00, 3128.69ex/s]\n",
      "100%|██████████| 2688/2688 [00:00<00:00, 3220.32ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2688, unlabelled size = 7312, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8233218562035334: 100%|██████████| 84/84 [00:25<00:00,  3.23it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6904493570327759: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "Eval mean loss: 1.6904493570327759: 100%|██████████| 16/16 [00:02<00:00,  5.38it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8233218562035334: 100%|██████████| 84/84 [00:28<00:00,  2.99it/s]\n",
      "Training mean loss: 1.5460845019136156: 100%|██████████| 84/84 [00:25<00:00,  3.26it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4759223833680153: 100%|██████████| 16/16 [00:03<00:00,  5.40it/s]\n",
      "Eval mean loss: 1.4759223833680153: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5460845019136156: 100%|██████████| 84/84 [00:28<00:00,  2.91it/s]\n",
      "Training mean loss: 1.3503793463820504: 100%|██████████| 84/84 [00:25<00:00,  3.25it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3001257255673409: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Eval mean loss: 1.3001257255673409: 100%|██████████| 16/16 [00:02<00:00,  5.36it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3503793463820504: 100%|██████████| 84/84 [00:28<00:00,  2.92it/s]\n",
      "Training mean loss: 1.1552665943191165: 100%|██████████| 84/84 [00:25<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1238827630877495: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Eval mean loss: 1.1238827630877495: 100%|██████████| 16/16 [00:03<00:00,  5.28it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1552665943191165: 100%|██████████| 84/84 [00:28<00:00,  2.92it/s]\n",
      "Training mean loss: 0.968938722496941: 100%|██████████| 84/84 [00:25<00:00,  3.27it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9983891062438488: 100%|██████████| 16/16 [00:03<00:00,  5.34it/s]\n",
      "Eval mean loss: 0.9983891062438488: 100%|██████████| 16/16 [00:03<00:00,  5.33it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9983891062438488: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 23   0   0   1   1  16  10]\n",
      " [  1 178  33   5  33   1   4]\n",
      " [  0   6  31   0   2   0   0]\n",
      " [  2   4  12 169  17   0  11]\n",
      " [  3  23  10   5 156   0  25]\n",
      " [  0   1   0   0   0  50   1]\n",
      " [  8   1   0   2  10  19 126]]\n",
      "{'accuracy': 0.6008333333333333}\n",
      "{'f1': 0.623372239447791}\n",
      "{'precision': 0.7146088521909554}\n",
      "{'recall': 0.6008333333333333}\n",
      "\n",
      "Test mean loss: 0.9983891062438488: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "Training mean loss: 0.968938722496941: 100%|██████████| 84/84 [00:31<00:00,  2.63it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   229/229: 100%|██████████| 229/229 [00:22<00:00, 10.00it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2688, unlabelled size = 7312, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.67ba/s]\n",
      "100%|██████████| 7280/7280 [00:02<00:00, 3096.05ex/s]\n",
      "100%|██████████| 2720/2720 [00:00<00:00, 3040.74ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2720, unlabelled size = 7280, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8337135469212251: 100%|██████████| 85/85 [00:25<00:00,  3.29it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.8085963428020477: 100%|██████████| 16/16 [00:03<00:00,  5.35it/s]\n",
      "Eval mean loss: 1.8085963428020477: 100%|██████████| 16/16 [00:03<00:00,  5.32it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8337135469212251: 100%|██████████| 85/85 [00:28<00:00,  3.01it/s]\n",
      "Training mean loss: 1.5849675487069523: 100%|██████████| 85/85 [00:26<00:00,  3.23it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5121950656175613: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\n",
      "Eval mean loss: 1.5121950656175613: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5849675487069523: 100%|██████████| 85/85 [00:29<00:00,  2.92it/s]\n",
      "Training mean loss: 1.3694874426897834: 100%|██████████| 85/85 [00:25<00:00,  3.29it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2909357473254204: 100%|██████████| 16/16 [00:03<00:00,  5.22it/s]\n",
      "Eval mean loss: 1.2909357473254204: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3694874426897834: 100%|██████████| 85/85 [00:29<00:00,  2.93it/s]\n",
      "Training mean loss: 1.1966701689888448: 100%|██████████| 85/85 [00:26<00:00,  3.28it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.142067588865757: 100%|██████████| 16/16 [00:02<00:00,  5.44it/s] \n",
      "Eval mean loss: 1.142067588865757: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1966701689888448: 100%|██████████| 85/85 [00:29<00:00,  2.92it/s]\n",
      "Training mean loss: 1.022055210085476: 100%|██████████| 85/85 [00:26<00:00,  3.28it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9806270860135555: 100%|██████████| 16/16 [00:02<00:00,  5.43it/s]\n",
      "Eval mean loss: 0.9806270860135555: 100%|██████████| 16/16 [00:02<00:00,  5.39it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9806270860135555: 100%|██████████| 16/16 [00:03<00:00,  5.38it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 35   0   0   1   1   8   6]\n",
      " [  1 188  15   3  46   0   2]\n",
      " [  0  10  27   1   1   0   0]\n",
      " [  1   3   8 178  14   0  11]\n",
      " [  5  17   4   7 168   0  21]\n",
      " [  6   1   0   0   0  45   0]\n",
      " [ 14   1   1   1   8  16 125]]\n",
      "{'accuracy': 0.6073333333333333}\n",
      "{'f1': 0.6314957760001539}\n",
      "{'precision': 0.7054850360681242}\n",
      "{'recall': 0.6073333333333333}\n",
      "\n",
      "Test mean loss: 0.9806270860135555: 100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "Training mean loss: 1.022055210085476: 100%|██████████| 85/85 [00:32<00:00,  2.65it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   228/228: 100%|██████████| 228/228 [00:23<00:00,  9.87it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2720, unlabelled size = 7280, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.22ba/s]\n",
      "100%|██████████| 7248/7248 [00:02<00:00, 2820.29ex/s]\n",
      "100%|██████████| 2752/2752 [00:01<00:00, 2515.60ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2752, unlabelled size = 7248, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8665633922399476: 100%|██████████| 86/86 [00:30<00:00,  2.83it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7360231652855873: 100%|██████████| 16/16 [00:03<00:00,  4.58it/s]\n",
      "Eval mean loss: 1.7360231652855873: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8665633922399476: 100%|██████████| 86/86 [00:34<00:00,  2.51it/s]\n",
      "Training mean loss: 1.6045132029888243: 100%|██████████| 86/86 [00:30<00:00,  2.87it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4908774644136429: 100%|██████████| 16/16 [00:03<00:00,  4.67it/s]\n",
      "Eval mean loss: 1.4908774644136429: 100%|██████████| 16/16 [00:03<00:00,  4.64it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6045132029888243: 100%|██████████| 86/86 [00:33<00:00,  2.56it/s]\n",
      "Training mean loss: 1.3435088382210842: 100%|██████████| 86/86 [00:32<00:00,  2.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.266551747918129: 100%|██████████| 16/16 [00:03<00:00,  4.44it/s] \n",
      "Eval mean loss: 1.266551747918129: 100%|██████████| 16/16 [00:03<00:00,  4.50it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3435088382210842: 100%|██████████| 86/86 [00:35<00:00,  2.39it/s]\n",
      "Training mean loss: 1.141473268353662: 100%|██████████| 86/86 [00:34<00:00,  2.47it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1003176346421242: 100%|██████████| 16/16 [00:03<00:00,  4.73it/s]\n",
      "Eval mean loss: 1.1003176346421242: 100%|██████████| 16/16 [00:03<00:00,  4.72it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.141473268353662: 100%|██████████| 86/86 [00:38<00:00,  2.25it/s]\n",
      "Training mean loss: 0.9241168519785238: 100%|██████████| 86/86 [00:32<00:00,  2.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9263011775910854: 100%|██████████| 16/16 [00:03<00:00,  4.63it/s]\n",
      "Eval mean loss: 0.9263011775910854: 100%|██████████| 16/16 [00:03<00:00,  4.47it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9263011775910854: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 29   0   0   2   0  11   9]\n",
      " [  1 163  51   7  32   0   1]\n",
      " [  0   4  30   1   4   0   0]\n",
      " [  1   3   5 190  10   0   6]\n",
      " [  2  15   8  10 171   0  16]\n",
      " [  2   0   0   0   1  48   1]\n",
      " [ 13   1   0   4  15  15 118]]\n",
      "{'accuracy': 0.656}\n",
      "{'f1': 0.6658096086051468}\n",
      "{'precision': 0.7016283716757653}\n",
      "{'recall': 0.656}\n",
      "\n",
      "Test mean loss: 0.9263011775910854: 100%|██████████| 16/16 [00:03<00:00,  4.33it/s]\n",
      "Training mean loss: 0.9241168519785238: 100%|██████████| 86/86 [00:39<00:00,  2.16it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   227/227: 100%|██████████| 227/227 [00:24<00:00,  9.41it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2752, unlabelled size = 7248, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.45ba/s]\n",
      "100%|██████████| 7216/7216 [00:02<00:00, 3000.02ex/s]\n",
      "100%|██████████| 2784/2784 [00:00<00:00, 3056.42ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2784, unlabelled size = 7216, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8461550309740264: 100%|██████████| 87/87 [00:30<00:00,  2.73it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7262323498725891: 100%|██████████| 16/16 [00:03<00:00,  5.24it/s]\n",
      "Eval mean loss: 1.7262323498725891: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8461550309740264: 100%|██████████| 87/87 [00:33<00:00,  2.61it/s]\n",
      "Training mean loss: 1.5715297145405034: 100%|██████████| 87/87 [00:32<00:00,  2.81it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4527192413806915: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "Eval mean loss: 1.4527192413806915: 100%|██████████| 16/16 [00:03<00:00,  4.54it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5715297145405034: 100%|██████████| 87/87 [00:35<00:00,  2.43it/s]\n",
      "Training mean loss: 1.3167209447115318: 100%|██████████| 87/87 [00:35<00:00,  2.56it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.235406368970871: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s] \n",
      "Eval mean loss: 1.235406368970871: 100%|██████████| 16/16 [00:03<00:00,  4.90it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3167209447115318: 100%|██████████| 87/87 [00:38<00:00,  2.25it/s]\n",
      "Training mean loss: 1.0988204986199566: 100%|██████████| 87/87 [00:32<00:00,  2.84it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0680889189243317: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "Eval mean loss: 1.0680889189243317: 100%|██████████| 16/16 [00:03<00:00,  4.84it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0988204986199566: 100%|██████████| 87/87 [00:35<00:00,  2.46it/s]\n",
      "Training mean loss: 0.9031161892003027: 100%|██████████| 87/87 [00:30<00:00,  2.60it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9100971557199955: 100%|██████████| 16/16 [00:03<00:00,  4.64it/s]\n",
      "Eval mean loss: 0.9100971557199955: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9100971557199955: 100%|██████████| 16/16 [00:03<00:00,  4.99it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 31   0   0   1   1  12   6]\n",
      " [  2 192  16   4  39   0   2]\n",
      " [  0   7  31   0   1   0   0]\n",
      " [  1   3  10 181  13   0   7]\n",
      " [  4  18   3   9 168   1  19]\n",
      " [  6   0   0   0   1  45   0]\n",
      " [ 12   1   0   4  12  18 119]]\n",
      "{'accuracy': 0.6726666666666666}\n",
      "{'f1': 0.6876442722616715}\n",
      "{'precision': 0.730596928052787}\n",
      "{'recall': 0.6726666666666666}\n",
      "\n",
      "Test mean loss: 0.9100971557199955: 100%|██████████| 16/16 [00:03<00:00,  4.83it/s]\n",
      "Training mean loss: 0.9031161892003027: 100%|██████████| 87/87 [00:37<00:00,  2.30it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   226/226: 100%|██████████| 226/226 [00:27<00:00,  8.28it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2784, unlabelled size = 7216, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.74ba/s]\n",
      "100%|██████████| 7184/7184 [00:02<00:00, 2882.38ex/s]\n",
      "100%|██████████| 2816/2816 [00:00<00:00, 3006.00ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2816, unlabelled size = 7184, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8504742180759257: 100%|██████████| 88/88 [00:28<00:00,  2.88it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7876426205039024: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "Eval mean loss: 1.7876426205039024: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8504742180759257: 100%|██████████| 88/88 [00:32<00:00,  2.74it/s]\n",
      "Training mean loss: 1.5995676205916838: 100%|██████████| 88/88 [00:31<00:00,  2.89it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5289166048169136: 100%|██████████| 16/16 [00:03<00:00,  4.70it/s]\n",
      "Eval mean loss: 1.5289166048169136: 100%|██████████| 16/16 [00:03<00:00,  4.71it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5995676205916838: 100%|██████████| 88/88 [00:35<00:00,  2.49it/s]\n",
      "Training mean loss: 1.3831202306530692: 100%|██████████| 88/88 [00:30<00:00,  2.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3371901363134384: 100%|██████████| 16/16 [00:03<00:00,  4.71it/s]\n",
      "Eval mean loss: 1.3371901363134384: 100%|██████████| 16/16 [00:03<00:00,  4.68it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3831202306530692: 100%|██████████| 88/88 [00:34<00:00,  2.57it/s]\n",
      "Training mean loss: 1.1789519278840586: 100%|██████████| 88/88 [00:29<00:00,  3.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1500618159770966: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n",
      "Eval mean loss: 1.1500618159770966: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1789519278840586: 100%|██████████| 88/88 [00:33<00:00,  2.66it/s]\n",
      "Training mean loss: 0.9913170324130491: 100%|██████████| 88/88 [00:32<00:00,  2.65it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9950045682489872: 100%|██████████| 16/16 [00:04<00:00,  3.52it/s]\n",
      "Eval mean loss: 0.9950045682489872: 100%|██████████| 16/16 [00:04<00:00,  3.56it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9950045682489872: 100%|██████████| 16/16 [00:04<00:00,  3.78it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 36   0   0   2   0   9   4]\n",
      " [  0 200  16   6  28   2   3]\n",
      " [  0  11  25   2   1   0   0]\n",
      " [  0   4   7 183  11   0  10]\n",
      " [  4  21   5   8 157   0  27]\n",
      " [  9   1   0   0   0  42   0]\n",
      " [ 31   1   0   5  10  12 107]]\n",
      "{'accuracy': 0.6095}\n",
      "{'f1': 0.6283641303058674}\n",
      "{'precision': 0.6840538776099917}\n",
      "{'recall': 0.6095}\n",
      "\n",
      "Test mean loss: 0.9950045682489872: 100%|██████████| 16/16 [00:04<00:00,  3.59it/s]\n",
      "Training mean loss: 0.9913170324130491: 100%|██████████| 88/88 [00:41<00:00,  2.11it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   225/225: 100%|██████████| 225/225 [00:29<00:00,  7.51it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2816, unlabelled size = 7184, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.14ba/s]\n",
      "100%|██████████| 7152/7152 [00:02<00:00, 2850.25ex/s]\n",
      "100%|██████████| 2848/2848 [00:01<00:00, 2717.99ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2848, unlabelled size = 7152, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8604994034499265: 100%|██████████| 89/89 [00:32<00:00,  2.50it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7711045518517494: 100%|██████████| 16/16 [00:03<00:00,  4.58it/s]\n",
      "Eval mean loss: 1.7711045518517494: 100%|██████████| 16/16 [00:03<00:00,  4.51it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8604994034499265: 100%|██████████| 89/89 [00:35<00:00,  2.48it/s]\n",
      "Training mean loss: 1.6072268445840043: 100%|██████████| 89/89 [00:33<00:00,  2.80it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5006792172789574: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "Eval mean loss: 1.5006792172789574: 100%|██████████| 16/16 [00:03<00:00,  4.85it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.6072268445840043: 100%|██████████| 89/89 [00:36<00:00,  2.42it/s]\n",
      "Training mean loss: 1.3398616380905837: 100%|██████████| 89/89 [00:31<00:00,  2.81it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.251912385225296: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s] \n",
      "Eval mean loss: 1.251912385225296: 100%|██████████| 16/16 [00:03<00:00,  4.97it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3398616380905837: 100%|██████████| 89/89 [00:34<00:00,  2.57it/s]\n",
      "Training mean loss: 1.1095468475577537: 100%|██████████| 89/89 [00:33<00:00,  2.68it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1000222712755203: 100%|██████████| 16/16 [00:03<00:00,  4.90it/s]\n",
      "Eval mean loss: 1.1000222712755203: 100%|██████████| 16/16 [00:03<00:00,  4.89it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1095468475577537: 100%|██████████| 89/89 [00:37<00:00,  2.39it/s]\n",
      "Training mean loss: 0.9094371005390467: 100%|██████████| 89/89 [00:30<00:00,  2.76it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.92076525837183: 100%|██████████| 16/16 [00:03<00:00,  4.13it/s]  \n",
      "Eval mean loss: 0.92076525837183: 100%|██████████| 16/16 [00:03<00:00,  4.12it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.92076525837183: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]  \n",
      "Metrics, confusion matrix\n",
      "[[ 33   0   0   2   0   9   7]\n",
      " [  0 188  32   7  24   0   4]\n",
      " [  0   7  30   1   1   0   0]\n",
      " [  0   3   9 188   6   0   9]\n",
      " [  3  31   5  12 139   0  32]\n",
      " [  3   0   0   0   1  47   1]\n",
      " [ 10   1   0   7   5  15 128]]\n",
      "{'accuracy': 0.6283333333333333}\n",
      "{'f1': 0.6481677062540443}\n",
      "{'precision': 0.7110970717543702}\n",
      "{'recall': 0.6283333333333333}\n",
      "\n",
      "Test mean loss: 0.92076525837183: 100%|██████████| 16/16 [00:03<00:00,  4.23it/s]\n",
      "Training mean loss: 0.9094371005390467: 100%|██████████| 89/89 [00:38<00:00,  2.33it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   224/224: 100%|██████████| 224/224 [00:29<00:00,  7.70it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2848, unlabelled size = 7152, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.79ba/s]\n",
      "100%|██████████| 7120/7120 [00:03<00:00, 2243.48ex/s]\n",
      "100%|██████████| 2880/2880 [00:00<00:00, 2947.23ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2880, unlabelled size = 7120, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8193765534294977: 100%|██████████| 90/90 [00:36<00:00,  2.38it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6849961057305336: 100%|██████████| 16/16 [00:03<00:00,  4.46it/s]\n",
      "Eval mean loss: 1.6849961057305336: 100%|██████████| 16/16 [00:03<00:00,  4.46it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8193765534294977: 100%|██████████| 90/90 [00:40<00:00,  2.23it/s]\n",
      "Training mean loss: 1.528018335501353: 100%|██████████| 90/90 [00:38<00:00,  2.42it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4316729754209518: 100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\n",
      "Eval mean loss: 1.4316729754209518: 100%|██████████| 16/16 [00:04<00:00,  3.71it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.528018335501353: 100%|██████████| 90/90 [00:42<00:00,  2.10it/s]\n",
      "Training mean loss: 1.2879140814145407: 100%|██████████| 90/90 [00:31<00:00,  2.89it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2479931861162186: 100%|██████████| 16/16 [00:03<00:00,  4.80it/s]\n",
      "Eval mean loss: 1.2479931861162186: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.2879140814145407: 100%|██████████| 90/90 [00:34<00:00,  2.60it/s]\n",
      "Training mean loss: 1.0869167844454448: 100%|██████████| 90/90 [00:31<00:00,  2.94it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0926464200019836: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "Eval mean loss: 1.0926464200019836: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0869167844454448: 100%|██████████| 90/90 [00:34<00:00,  2.61it/s]\n",
      "Training mean loss: 0.9297486192650265: 100%|██████████| 90/90 [00:32<00:00,  2.70it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9248348474502563: 100%|██████████| 16/16 [00:04<00:00,  3.83it/s]\n",
      "Eval mean loss: 0.9248348474502563: 100%|██████████| 16/16 [00:04<00:00,  3.89it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.9248348474502563: 100%|██████████| 16/16 [00:04<00:00,  3.37it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 35   0   0   1   3   6   6]\n",
      " [  0 189  25   4  33   1   3]\n",
      " [  0   8  28   1   2   0   0]\n",
      " [  0   3   9 182  14   0   7]\n",
      " [  4  20   3   7 163   0  25]\n",
      " [  7   1   0   0   0  44   0]\n",
      " [ 18   1   0   5  12  15 115]]\n",
      "{'accuracy': 0.6561666666666667}\n",
      "{'f1': 0.673363621024295}\n",
      "{'precision': 0.7196850987588501}\n",
      "{'recall': 0.6561666666666667}\n",
      "\n",
      "Test mean loss: 0.9248348474502563: 100%|██████████| 16/16 [00:04<00:00,  3.31it/s]\n",
      "Training mean loss: 0.9297486192650265: 100%|██████████| 90/90 [00:41<00:00,  2.18it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   223/223: 100%|██████████| 223/223 [00:27<00:00,  8.14it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2880, unlabelled size = 7120, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.72ba/s]\n",
      "100%|██████████| 7088/7088 [00:03<00:00, 2146.50ex/s]\n",
      "100%|██████████| 2912/2912 [00:01<00:00, 2813.81ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2912, unlabelled size = 7088, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8326489204888816: 100%|██████████| 91/91 [00:34<00:00,  2.58it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7207942008972168: 100%|██████████| 16/16 [00:03<00:00,  4.23it/s]\n",
      "Eval mean loss: 1.7207942008972168: 100%|██████████| 16/16 [00:03<00:00,  4.19it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8326489204888816: 100%|██████████| 91/91 [00:38<00:00,  2.36it/s]\n",
      "Training mean loss: 1.570155959862929: 100%|██████████| 91/91 [00:41<00:00,  2.31it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4648974314332008: 100%|██████████| 16/16 [00:04<00:00,  3.70it/s]\n",
      "Eval mean loss: 1.4648974314332008: 100%|██████████| 16/16 [00:04<00:00,  3.54it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.570155959862929: 100%|██████████| 91/91 [00:45<00:00,  1.99it/s]\n",
      "Training mean loss: 1.3246206097550444: 100%|██████████| 91/91 [00:36<00:00,  2.50it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.247565858066082: 100%|██████████| 16/16 [00:03<00:00,  4.41it/s] \n",
      "Eval mean loss: 1.247565858066082: 100%|██████████| 16/16 [00:03<00:00,  4.37it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3246206097550444: 100%|██████████| 91/91 [00:40<00:00,  2.27it/s]\n",
      "Training mean loss: 1.1094188559186327: 100%|██████████| 91/91 [00:36<00:00,  2.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0423167683184147: 100%|██████████| 16/16 [00:04<00:00,  3.98it/s]\n",
      "Eval mean loss: 1.0423167683184147: 100%|██████████| 16/16 [00:04<00:00,  3.93it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1094188559186327: 100%|██████████| 91/91 [00:40<00:00,  2.26it/s]\n",
      "Training mean loss: 0.8949441287543748: 100%|██████████| 91/91 [00:39<00:00,  2.47it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8872346021234989: 100%|██████████| 16/16 [00:03<00:00,  4.10it/s]\n",
      "Eval mean loss: 0.8872346021234989: 100%|██████████| 16/16 [00:03<00:00,  4.05it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8872346021234989: 100%|██████████| 16/16 [00:03<00:00,  4.55it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 35   0   0   2   1   8   5]\n",
      " [  2 207  22   1  20   0   3]\n",
      " [  0  11  27   0   1   0   0]\n",
      " [  0   3  19 171  11   0  11]\n",
      " [  3  27   8   5 164   0  15]\n",
      " [  5   1   0   0   0  45   1]\n",
      " [ 12   1   0   5   9  13 126]]\n",
      "{'accuracy': 0.6638333333333334}\n",
      "{'f1': 0.6878815356256749}\n",
      "{'precision': 0.744932787367602}\n",
      "{'recall': 0.6638333333333334}\n",
      "\n",
      "Test mean loss: 0.8872346021234989: 100%|██████████| 16/16 [00:03<00:00,  4.38it/s]\n",
      "Training mean loss: 0.8949441287543748: 100%|██████████| 91/91 [00:46<00:00,  1.94it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   222/222: 100%|██████████| 222/222 [00:32<00:00,  6.91it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2912, unlabelled size = 7088, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.59ba/s]\n",
      "100%|██████████| 7056/7056 [00:03<00:00, 1947.59ex/s]\n",
      "100%|██████████| 2944/2944 [00:01<00:00, 2440.24ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2944, unlabelled size = 7056, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8573478525099547: 100%|██████████| 92/92 [00:35<00:00,  2.72it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7450670823454857: 100%|██████████| 16/16 [00:04<00:00,  4.01it/s]\n",
      "Eval mean loss: 1.7450670823454857: 100%|██████████| 16/16 [00:04<00:00,  3.96it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8573478525099547: 100%|██████████| 92/92 [00:39<00:00,  2.35it/s]\n",
      "Training mean loss: 1.591209098048832: 100%|██████████| 92/92 [00:32<00:00,  2.91it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4687381014227867: 100%|██████████| 16/16 [00:03<00:00,  4.35it/s]\n",
      "Eval mean loss: 1.4687381014227867: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.591209098048832: 100%|██████████| 92/92 [00:36<00:00,  2.51it/s]\n",
      "Training mean loss: 1.326767006646032: 100%|██████████| 92/92 [00:34<00:00,  2.70it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.232384704053402: 100%|██████████| 16/16 [00:03<00:00,  4.82it/s] \n",
      "Eval mean loss: 1.232384704053402: 100%|██████████| 16/16 [00:03<00:00,  4.81it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.326767006646032: 100%|██████████| 92/92 [00:37<00:00,  2.45it/s]\n",
      "Training mean loss: 1.0830066398434017: 100%|██████████| 92/92 [00:34<00:00,  2.71it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0701721981167793: 100%|██████████| 16/16 [00:03<00:00,  4.75it/s]\n",
      "Eval mean loss: 1.0701721981167793: 100%|██████████| 16/16 [00:03<00:00,  4.76it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0830066398434017: 100%|██████████| 92/92 [00:37<00:00,  2.43it/s]\n",
      "Training mean loss: 0.8905089976994888: 100%|██████████| 92/92 [00:32<00:00,  2.78it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8840477354824543: 100%|██████████| 16/16 [00:03<00:00,  4.40it/s]\n",
      "Eval mean loss: 0.8840477354824543: 100%|██████████| 16/16 [00:03<00:00,  4.37it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8840477354824543: 100%|██████████| 16/16 [00:03<00:00,  4.33it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 33   0   0   4   0   5   9]\n",
      " [  0 208  22   5  19   0   1]\n",
      " [  0   7  30   1   1   0   0]\n",
      " [  0   5   7 186  11   0   6]\n",
      " [  3  33   7   8 159   0  12]\n",
      " [ 11   1   0   0   0  39   1]\n",
      " [ 11   3   0   4  15  13 120]]\n",
      "{'accuracy': 0.665}\n",
      "{'f1': 0.6685403143745604}\n",
      "{'precision': 0.7017497139452944}\n",
      "{'recall': 0.665}\n",
      "\n",
      "Test mean loss: 0.8840477354824543: 100%|██████████| 16/16 [00:03<00:00,  4.14it/s]\n",
      "Training mean loss: 0.8905089976994888: 100%|██████████| 92/92 [00:40<00:00,  2.28it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   221/221: 100%|██████████| 221/221 [00:24<00:00,  9.00it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2944, unlabelled size = 7056, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.35ba/s]\n",
      "100%|██████████| 7024/7024 [00:02<00:00, 2840.80ex/s]\n",
      "100%|██████████| 2976/2976 [00:01<00:00, 2940.42ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 2976, unlabelled size = 7024, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8284611304601033: 100%|██████████| 93/93 [00:32<00:00,  2.64it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6963530033826828: 100%|██████████| 16/16 [00:03<00:00,  4.37it/s]\n",
      "Eval mean loss: 1.6963530033826828: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8284611304601033: 100%|██████████| 93/93 [00:36<00:00,  2.55it/s]\n",
      "Training mean loss: 1.5391128242656749: 100%|██████████| 93/93 [00:33<00:00,  2.79it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.41714296489954: 100%|██████████| 16/16 [00:03<00:00,  4.82it/s]  \n",
      "Eval mean loss: 1.41714296489954: 100%|██████████| 16/16 [00:03<00:00,  4.80it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5391128242656749: 100%|██████████| 93/93 [00:37<00:00,  2.50it/s]\n",
      "Training mean loss: 1.295026748411117: 100%|██████████| 93/93 [00:32<00:00,  2.83it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1956017911434174: 100%|██████████| 16/16 [00:03<00:00,  4.36it/s]\n",
      "Eval mean loss: 1.1956017911434174: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.295026748411117: 100%|██████████| 93/93 [00:36<00:00,  2.57it/s]\n",
      "Training mean loss: 1.1019399063561552: 100%|██████████| 93/93 [00:37<00:00,  2.38it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0255243815481663: 100%|██████████| 16/16 [00:03<00:00,  4.03it/s]\n",
      "Eval mean loss: 1.0255243815481663: 100%|██████████| 16/16 [00:03<00:00,  4.02it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.1019399063561552: 100%|██████████| 93/93 [00:41<00:00,  2.24it/s]\n",
      "Training mean loss: 0.9183382795703027: 100%|██████████| 93/93 [00:40<00:00,  2.55it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8853081837296486: 100%|██████████| 16/16 [00:03<00:00,  4.53it/s]\n",
      "Eval mean loss: 0.8853081837296486: 100%|██████████| 16/16 [00:03<00:00,  4.52it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8853081837296486: 100%|██████████| 16/16 [00:03<00:00,  4.67it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 30   0   0   2   0   9  10]\n",
      " [  0 211  15   4  21   1   3]\n",
      " [  0   7  29   1   2   0   0]\n",
      " [  0   3   7 185  10   0  10]\n",
      " [  3  32   5  10 144   0  28]\n",
      " [  6   0   0   0   1  45   0]\n",
      " [ 12   0   0   2   9  13 130]]\n",
      "{'accuracy': 0.6853333333333333}\n",
      "{'f1': 0.6842324910840192}\n",
      "{'precision': 0.7139304059472109}\n",
      "{'recall': 0.6853333333333333}\n",
      "\n",
      "Test mean loss: 0.8853081837296486: 100%|██████████| 16/16 [00:03<00:00,  4.52it/s]\n",
      "Training mean loss: 0.9183382795703027: 100%|██████████| 93/93 [00:47<00:00,  1.96it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   220/220: 100%|██████████| 220/220 [00:25<00:00,  8.63it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 2976, unlabelled size = 7024, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.18ba/s]\n",
      "100%|██████████| 6992/6992 [00:02<00:00, 2714.63ex/s]\n",
      "100%|██████████| 3008/3008 [00:01<00:00, 2994.96ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3008, unlabelled size = 6992, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8469967220691925: 100%|██████████| 94/94 [00:33<00:00,  2.78it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7186608836054802: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Eval mean loss: 1.7186608836054802: 100%|██████████| 16/16 [00:03<00:00,  4.56it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8469967220691925: 100%|██████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Training mean loss: 1.5624652619057513: 100%|██████████| 94/94 [00:35<00:00,  2.66it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4694457352161407: 100%|██████████| 16/16 [00:03<00:00,  4.66it/s]\n",
      "Eval mean loss: 1.4694457352161407: 100%|██████████| 16/16 [00:03<00:00,  4.65it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5624652619057513: 100%|██████████| 94/94 [00:38<00:00,  2.42it/s]\n",
      "Training mean loss: 1.3166064062017075: 100%|██████████| 94/94 [00:36<00:00,  2.68it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2403905391693115: 100%|██████████| 16/16 [00:03<00:00,  4.47it/s]\n",
      "Eval mean loss: 1.2403905391693115: 100%|██████████| 16/16 [00:03<00:00,  4.45it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3166064062017075: 100%|██████████| 94/94 [00:40<00:00,  2.34it/s]\n",
      "Training mean loss: 1.0825106901057222: 100%|██████████| 94/94 [00:33<00:00,  2.76it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.028416559100151: 100%|██████████| 16/16 [00:03<00:00,  4.42it/s] \n",
      "Eval mean loss: 1.028416559100151: 100%|██████████| 16/16 [00:03<00:00,  4.45it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0825106901057222: 100%|██████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Training mean loss: 0.8723792960035041: 100%|██████████| 94/94 [00:32<00:00,  2.89it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8607738204300404: 100%|██████████| 16/16 [00:03<00:00,  4.90it/s]\n",
      "Eval mean loss: 0.8607738204300404: 100%|██████████| 16/16 [00:03<00:00,  4.88it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8607738204300404: 100%|██████████| 16/16 [00:03<00:00,  4.72it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 35   1   0   1   1   9   4]\n",
      " [  1 232  10   3   9   0   0]\n",
      " [  0   8  28   2   1   0   0]\n",
      " [  0   6  11 183  11   0   4]\n",
      " [  5  53   5   9 137   0  13]\n",
      " [  3   1   0   0   0  48   0]\n",
      " [ 12   1   0   6  14  18 115]]\n",
      "{'accuracy': 0.6686666666666666}\n",
      "{'f1': 0.6822309079888027}\n",
      "{'precision': 0.7333083164292886}\n",
      "{'recall': 0.6686666666666666}\n",
      "\n",
      "Test mean loss: 0.8607738204300404: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "Training mean loss: 0.8723792960035041: 100%|██████████| 94/94 [00:39<00:00,  2.39it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   219/219: 100%|██████████| 219/219 [00:30<00:00,  7.07it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3008, unlabelled size = 6992, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.53ba/s]\n",
      "100%|██████████| 6960/6960 [00:03<00:00, 2238.57ex/s]\n",
      "100%|██████████| 3040/3040 [00:02<00:00, 1377.02ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3040, unlabelled size = 6960, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8684027433395385: 100%|██████████| 95/95 [00:34<00:00,  2.68it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7701178938150406: 100%|██████████| 16/16 [00:04<00:00,  3.74it/s]\n",
      "Eval mean loss: 1.7701178938150406: 100%|██████████| 16/16 [00:04<00:00,  3.76it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8684027433395385: 100%|██████████| 95/95 [00:39<00:00,  2.43it/s]\n",
      "Training mean loss: 1.606755815054241: 100%|██████████| 95/95 [00:36<00:00,  2.76it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.5289260223507881: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "Eval mean loss: 1.5289260223507881: 100%|██████████| 16/16 [00:03<00:00,  4.59it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.606755815054241: 100%|██████████| 95/95 [00:40<00:00,  2.37it/s]\n",
      "Training mean loss: 1.345809060648868: 100%|██████████| 95/95 [00:37<00:00,  2.58it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2657962962985039: 100%|██████████| 16/16 [00:04<00:00,  3.79it/s]\n",
      "Eval mean loss: 1.2657962962985039: 100%|██████████| 16/16 [00:04<00:00,  3.79it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.345809060648868: 100%|██████████| 95/95 [00:42<00:00,  2.26it/s]\n",
      "Training mean loss: 1.115474119311885: 100%|██████████| 95/95 [00:37<00:00,  2.36it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0642813220620155: 100%|██████████| 16/16 [00:03<00:00,  4.27it/s]\n",
      "Eval mean loss: 1.0642813220620155: 100%|██████████| 16/16 [00:03<00:00,  4.21it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.115474119311885: 100%|██████████| 95/95 [00:41<00:00,  2.30it/s]\n",
      "Training mean loss: 0.8928562321160969: 100%|██████████| 95/95 [00:35<00:00,  2.53it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8900335319340229: 100%|██████████| 16/16 [00:03<00:00,  4.30it/s]\n",
      "Eval mean loss: 0.8900335319340229: 100%|██████████| 16/16 [00:03<00:00,  4.23it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8900335319340229: 100%|██████████| 16/16 [00:03<00:00,  4.47it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 26   0   0   1   2  17   5]\n",
      " [  0 191  20   4  38   0   2]\n",
      " [  0   9  27   1   2   0   0]\n",
      " [  0   2   9 176  15   0  13]\n",
      " [  2  17   2   7 173   1  20]\n",
      " [  0   1   0   0   0  50   1]\n",
      " [  6   1   0   1  11  20 127]]\n",
      "{'accuracy': 0.6358333333333334}\n",
      "{'f1': 0.6557355285815363}\n",
      "{'precision': 0.7170217375293612}\n",
      "{'recall': 0.6358333333333334}\n",
      "\n",
      "Test mean loss: 0.8900335319340229: 100%|██████████| 16/16 [00:03<00:00,  4.30it/s]\n",
      "Training mean loss: 0.8928562321160969: 100%|██████████| 95/95 [00:42<00:00,  2.22it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   218/218: 100%|██████████| 218/218 [00:30<00:00,  7.25it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3040, unlabelled size = 6960, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.58ba/s]\n",
      "100%|██████████| 6928/6928 [00:02<00:00, 2372.32ex/s]\n",
      "100%|██████████| 3072/3072 [00:01<00:00, 2831.16ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3072, unlabelled size = 6928, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8446396725873153: 100%|██████████| 96/96 [00:34<00:00,  2.69it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6997895911335945: 100%|██████████| 16/16 [00:03<00:00,  4.40it/s]\n",
      "Eval mean loss: 1.6997895911335945: 100%|██████████| 16/16 [00:03<00:00,  4.34it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8446396725873153: 100%|██████████| 96/96 [00:37<00:00,  2.53it/s]\n",
      "Training mean loss: 1.5527468932171662: 100%|██████████| 96/96 [00:34<00:00,  2.80it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4225761219859123: 100%|██████████| 16/16 [00:03<00:00,  4.68it/s]\n",
      "Eval mean loss: 1.4225761219859123: 100%|██████████| 16/16 [00:03<00:00,  4.67it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5527468932171662: 100%|██████████| 96/96 [00:37<00:00,  2.54it/s]\n",
      "Training mean loss: 1.2930782275895278: 100%|██████████| 96/96 [00:39<00:00,  2.13it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1892835944890976: 100%|██████████| 16/16 [00:03<00:00,  4.11it/s]\n",
      "Eval mean loss: 1.1892835944890976: 100%|██████████| 16/16 [00:03<00:00,  4.03it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.2930782275895278: 100%|██████████| 96/96 [00:43<00:00,  2.22it/s]\n",
      "Training mean loss: 1.0668999931464593: 100%|██████████| 96/96 [00:37<00:00,  2.66it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9816832542419434: 100%|██████████| 16/16 [00:03<00:00,  4.69it/s]\n",
      "Eval mean loss: 0.9816832542419434: 100%|██████████| 16/16 [00:03<00:00,  4.66it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0668999931464593: 100%|██████████| 96/96 [00:40<00:00,  2.35it/s]\n",
      "Training mean loss: 0.8482922123124202: 100%|██████████| 96/96 [00:33<00:00,  2.91it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8439231514930725: 100%|██████████| 16/16 [00:03<00:00,  4.66it/s]\n",
      "Eval mean loss: 0.8439231514930725: 100%|██████████| 16/16 [00:03<00:00,  4.69it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8439231514930725: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 28   0   0   1   2  11   9]\n",
      " [  1 186  11   9  47   0   1]\n",
      " [  0   5  30   2   2   0   0]\n",
      " [  0   2   6 187  13   0   7]\n",
      " [  3  13   3   9 177   0  17]\n",
      " [  4   0   0   0   1  46   1]\n",
      " [  9   0   0   2  12  15 128]]\n",
      "{'accuracy': 0.7111666666666666}\n",
      "{'f1': 0.7197736684785163}\n",
      "{'precision': 0.7394892995342877}\n",
      "{'recall': 0.7111666666666666}\n",
      "\n",
      "Test mean loss: 0.8439231514930725: 100%|██████████| 16/16 [00:03<00:00,  4.64it/s]\n",
      "Training mean loss: 0.8482922123124202: 100%|██████████| 96/96 [00:39<00:00,  2.41it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   217/217: 100%|██████████| 217/217 [00:25<00:00,  8.49it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3072, unlabelled size = 6928, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.63ba/s]\n",
      "100%|██████████| 6896/6896 [00:02<00:00, 2820.68ex/s]\n",
      "100%|██████████| 3104/3104 [00:01<00:00, 2745.55ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3104, unlabelled size = 6896, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8733221095861847: 100%|██████████| 97/97 [00:34<00:00,  2.47it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7511575669050217: 100%|██████████| 16/16 [00:03<00:00,  4.80it/s]\n",
      "Eval mean loss: 1.7511575669050217: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8733221095861847: 100%|██████████| 97/97 [00:37<00:00,  2.56it/s]\n",
      "Training mean loss: 1.5771607430939822: 100%|██████████| 97/97 [00:34<00:00,  2.94it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.444871336221695: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s] \n",
      "Eval mean loss: 1.444871336221695: 100%|██████████| 16/16 [00:03<00:00,  4.47it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5771607430939822: 100%|██████████| 97/97 [00:37<00:00,  2.58it/s]\n",
      "Training mean loss: 1.3013587305226277: 100%|██████████| 97/97 [00:35<00:00,  2.82it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2177244201302528: 100%|██████████| 16/16 [00:03<00:00,  4.67it/s]\n",
      "Eval mean loss: 1.2177244201302528: 100%|██████████| 16/16 [00:03<00:00,  4.68it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3013587305226277: 100%|██████████| 97/97 [00:38<00:00,  2.52it/s]\n",
      "Training mean loss: 1.090534825300433: 100%|██████████| 97/97 [00:37<00:00,  2.80it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0263825096189976: 100%|██████████| 16/16 [00:03<00:00,  4.51it/s]\n",
      "Eval mean loss: 1.0263825096189976: 100%|██████████| 16/16 [00:03<00:00,  4.53it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.090534825300433: 100%|██████████| 97/97 [00:40<00:00,  2.39it/s]\n",
      "Training mean loss: 0.8653070090972271: 100%|██████████| 97/97 [00:34<00:00,  2.88it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8954381048679352: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s]\n",
      "Eval mean loss: 0.8954381048679352: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8954381048679352: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 30   0   0   1   1  14   5]\n",
      " [  0 172  28   9  42   0   4]\n",
      " [  0   9  27   2   1   0   0]\n",
      " [  0   2   6 191   6   0  10]\n",
      " [  3  14   6  12 159   0  28]\n",
      " [  1   1   0   0   0  50   0]\n",
      " [  6   2   0   3   9  25 121]]\n",
      "{'accuracy': 0.6565}\n",
      "{'f1': 0.6683358989264325}\n",
      "{'precision': 0.705974303638808}\n",
      "{'recall': 0.6565}\n",
      "\n",
      "Test mean loss: 0.8954381048679352: 100%|██████████| 16/16 [00:03<00:00,  4.88it/s]\n",
      "Training mean loss: 0.8653070090972271: 100%|██████████| 97/97 [00:40<00:00,  2.39it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   216/216: 100%|██████████| 216/216 [00:23<00:00,  9.04it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3104, unlabelled size = 6896, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.66ba/s]\n",
      "100%|██████████| 6864/6864 [00:02<00:00, 3042.17ex/s]\n",
      "100%|██████████| 3136/3136 [00:01<00:00, 2963.14ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3136, unlabelled size = 6864, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8558510858185437: 100%|██████████| 98/98 [00:34<00:00,  2.84it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7380525842308998: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n",
      "Eval mean loss: 1.7380525842308998: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8558510858185437: 100%|██████████| 98/98 [00:38<00:00,  2.56it/s]\n",
      "Training mean loss: 1.562175377291076: 100%|██████████| 98/98 [00:33<00:00,  2.94it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4744038358330727: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "Eval mean loss: 1.4744038358330727: 100%|██████████| 16/16 [00:03<00:00,  4.81it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.562175377291076: 100%|██████████| 98/98 [00:36<00:00,  2.68it/s]\n",
      "Training mean loss: 1.3045937345952403: 100%|██████████| 98/98 [00:32<00:00,  3.01it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2360393330454826: 100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n",
      "Eval mean loss: 1.2360393330454826: 100%|██████████| 16/16 [00:03<00:00,  5.12it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.3045937345952403: 100%|██████████| 98/98 [00:35<00:00,  2.73it/s]\n",
      "Training mean loss: 1.0933622438080457: 100%|██████████| 98/98 [00:33<00:00,  2.97it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.0533506460487843: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "Eval mean loss: 1.0533506460487843: 100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0933622438080457: 100%|██████████| 98/98 [00:36<00:00,  2.67it/s]\n",
      "Training mean loss: 0.8882915699968532: 100%|██████████| 98/98 [00:35<00:00,  2.82it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.893584381788969: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s] \n",
      "Eval mean loss: 0.893584381788969: 100%|██████████| 16/16 [00:03<00:00,  4.72it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.893584381788969: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s] \n",
      "Metrics, confusion matrix\n",
      "[[ 32   0   0   3   1   8   7]\n",
      " [  0 213  12   6  23   0   1]\n",
      " [  0   9  28   1   1   0   0]\n",
      " [  1   6   5 183  14   0   6]\n",
      " [  4  30   5  12 150   0  21]\n",
      " [  5   1   0   0   0  46   0]\n",
      " [ 16   1   0   3  13  14 119]]\n",
      "{'accuracy': 0.6463333333333333}\n",
      "{'f1': 0.654953968027863}\n",
      "{'precision': 0.701974273863816}\n",
      "{'recall': 0.6463333333333333}\n",
      "\n",
      "Test mean loss: 0.893584381788969: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]\n",
      "Training mean loss: 0.8882915699968532: 100%|██████████| 98/98 [00:42<00:00,  2.33it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   215/215: 100%|██████████| 215/215 [00:24<00:00,  8.60it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3136, unlabelled size = 6864, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.84ba/s]\n",
      "100%|██████████| 6832/6832 [00:02<00:00, 3022.43ex/s]\n",
      "100%|██████████| 3168/3168 [00:01<00:00, 3014.52ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3168, unlabelled size = 6832, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration  99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.8329676341528844: 100%|██████████| 99/99 [00:38<00:00,  2.30it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.7352888956665993: 100%|██████████| 16/16 [00:03<00:00,  4.56it/s]\n",
      "Eval mean loss: 1.7352888956665993: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.8329676341528844: 100%|██████████| 99/99 [00:42<00:00,  2.35it/s]\n",
      "Training mean loss: 1.549357007248233: 100%|██████████| 99/99 [00:37<00:00,  2.77it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.4069626405835152: 100%|██████████| 16/16 [00:03<00:00,  4.29it/s]\n",
      "Eval mean loss: 1.4069626405835152: 100%|██████████| 16/16 [00:03<00:00,  4.37it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.549357007248233: 100%|██████████| 99/99 [00:41<00:00,  2.40it/s]\n",
      "Training mean loss: 1.2822840478685167: 100%|██████████| 99/99 [00:35<00:00,  2.91it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.2242566645145416: 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n",
      "Eval mean loss: 1.2242566645145416: 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.2822840478685167: 100%|██████████| 99/99 [00:38<00:00,  2.55it/s]\n",
      "Training mean loss: 1.061652456871187: 100%|██████████| 99/99 [00:33<00:00,  2.98it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.016043771058321: 100%|██████████| 16/16 [00:03<00:00,  5.21it/s] \n",
      "Eval mean loss: 1.016043771058321: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.061652456871187: 100%|██████████| 99/99 [00:36<00:00,  2.71it/s]\n",
      "Training mean loss: 0.837342736094889: 100%|██████████| 99/99 [00:35<00:00,  2.80it/s] \n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8507783822715282: 100%|██████████| 16/16 [00:03<00:00,  4.73it/s]\n",
      "Eval mean loss: 0.8507783822715282: 100%|██████████| 16/16 [00:03<00:00,  4.73it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8507783822715282: 100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 36   0   0   3   0   5   7]\n",
      " [  1 214  15   7  14   1   3]\n",
      " [  0   6  30   0   3   0   0]\n",
      " [  1   4   6 183  11   0  10]\n",
      " [  3  23   5   9 161   0  21]\n",
      " [  8   0   0   0   1  43   0]\n",
      " [ 14   0   0   2   9  13 128]]\n",
      "{'accuracy': 0.7036666666666667}\n",
      "{'f1': 0.7166434811704755}\n",
      "{'precision': 0.7503096395360648}\n",
      "{'recall': 0.7036666666666667}\n",
      "\n",
      "Test mean loss: 0.8507783822715282: 100%|██████████| 16/16 [00:03<00:00,  4.48it/s]\n",
      "Training mean loss: 0.837342736094889: 100%|██████████| 99/99 [00:42<00:00,  2.35it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   214/214: 100%|██████████| 214/214 [00:24<00:00,  8.66it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3168, unlabelled size = 6832, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.93ba/s]\n",
      "100%|██████████| 6800/6800 [00:02<00:00, 3015.97ex/s]\n",
      "100%|██████████| 3200/3200 [00:01<00:00, 2904.14ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3200, unlabelled size = 6800, sum: 10000 \n",
      "\n",
      "===========================================================\n",
      "\n",
      "AL iteration 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training mean loss: 1.817127788066864: 100%|██████████| 100/100 [00:33<00:00,  2.94it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.6549407988786697: 100%|██████████| 16/16 [00:03<00:00,  4.97it/s]\n",
      "Eval mean loss: 1.6549407988786697: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training mean loss: 1.817127788066864: 100%|██████████| 100/100 [00:36<00:00,  2.74it/s]\n",
      "Training mean loss: 1.5098282980918885: 100%|██████████| 100/100 [00:33<00:00,  2.98it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.3942479118704796: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "Eval mean loss: 1.3942479118704796: 100%|██████████| 16/16 [00:03<00:00,  4.92it/s]\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training mean loss: 1.5098282980918885: 100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n",
      "Training mean loss: 1.2763945031166077: 100%|██████████| 100/100 [00:33<00:00,  3.00it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 1.1688376665115356: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "Eval mean loss: 1.1688376665115356: 100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training mean loss: 1.2763945031166077: 100%|██████████| 100/100 [00:36<00:00,  2.70it/s]\n",
      "Training mean loss: 1.0502295452356338: 100%|██████████| 100/100 [00:34<00:00,  2.94it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.9836922995746136: 100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n",
      "Eval mean loss: 0.9836922995746136: 100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training mean loss: 1.0502295452356338: 100%|██████████| 100/100 [00:37<00:00,  2.68it/s]\n",
      "Training mean loss: 0.8305926769971848: 100%|██████████| 100/100 [00:33<00:00,  2.99it/s]\n",
      "\n",
      "Epoch finished. Evaluation:\n",
      "Running Eval mode...\n",
      "Eval mean loss: 0.8385697118937969: 100%|██████████| 16/16 [00:03<00:00,  4.99it/s]\n",
      "Eval mean loss: 0.8385697118937969: 100%|██████████| 16/16 [00:03<00:00,  4.95it/s]\n",
      "Test set evaluation:\n",
      "Running Test mode...\n",
      "Test mean loss: 0.8385697118937969: 100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n",
      "Metrics, confusion matrix\n",
      "[[ 37   0   0   0   0   8   6]\n",
      " [  0 216  12   1  20   0   6]\n",
      " [  0  11  26   0   2   0   0]\n",
      " [  1   4   6 180  12   0  12]\n",
      " [  2  31   1   6 158   1  23]\n",
      " [  6   1   0   0   0  45   0]\n",
      " [ 18   1   0   1  10  15 121]]\n",
      "{'accuracy': 0.6863333333333334}\n",
      "{'f1': 0.688923849662487}\n",
      "{'precision': 0.7227012995442526}\n",
      "{'recall': 0.6863333333333334}\n",
      "\n",
      "Test mean loss: 0.8385697118937969: 100%|██████████| 16/16 [00:03<00:00,  4.80it/s]\n",
      "Training mean loss: 0.8305926769971848: 100%|██████████| 100/100 [00:40<00:00,  2.50it/s]\n",
      "Model trained! Running AL strategy...\n",
      "AL evaluation iteration\n",
      "AL evaluation iteration. Batch   213/213: 100%|██████████| 213/213 [00:23<00:00,  9.13it/s]\n",
      "Returned 32 indices from strategy\n",
      "Before updating AL datasets: train size = 3200, unlabelled size = 6800, sum: 10000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.95ba/s]\n",
      "100%|██████████| 6768/6768 [00:02<00:00, 2603.62ex/s]\n",
      "100%|██████████| 3232/3232 [00:01<00:00, 2819.40ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated AL datasets: train size = 3232, unlabelled size = 6768, sum: 10000 \n"
     ]
    }
   ],
   "source": [
    "if parameters['full_train']:\n",
    "    trainer.full_train(\n",
    "        train_epochs=parameters['epochs'],\n",
    "        train_batch_size=parameters['train_batch_size'],\n",
    "        val_batch_size=parameters['val_batch_size'],\n",
    "        test_batch_size=parameters['test_batch_size'],\n",
    "        debug=parameters['debug']\n",
    "    )\n",
    "\n",
    "trainer.al_train(\n",
    "    al_iterations=parameters['al_iterations'],\n",
    "    init_dataset_size=parameters['init_dataset_size'],\n",
    "    add_dataset_size=parameters['add_dataset_size'],\n",
    "    train_epochs=parameters['epochs'],\n",
    "    strategy=parameters['al_strategy'],\n",
    "    train_batch_size=parameters['train_batch_size'],\n",
    "    val_batch_size=parameters['val_batch_size'],\n",
    "    test_batch_size=parameters['test_batch_size'],\n",
    "    debug=parameters['debug']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00e9d6-f44b-4c0b-991c-deeefb47dae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d5547-6dd5-4b62-a1c9-c5cd602ec5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c9938-e991-41f7-bc75-0b56e7014707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
